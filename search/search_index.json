{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Parallel Agents Verifier System - Complete Documentation Index","text":"<p>Welcome to the comprehensive documentation for the Parallel Agents Verifier System. This automated testing framework uses Claude Code agents to monitor source code changes and generate tests in real-time.</p>"},{"location":"#documentation-overview","title":"\ud83d\udcda Documentation Overview","text":""},{"location":"#for-end-users","title":"For End Users","text":"<ul> <li>User Guide - Complete installation, configuration, and usage guide</li> <li>Quick Start - Get up and running in 5 minutes</li> <li>Troubleshooting - Common issues and solutions</li> </ul>"},{"location":"#for-developers","title":"For Developers","text":"<ul> <li>Development Guide - Environment setup, coding standards, and contribution guidelines</li> <li>API Reference - Detailed API documentation for all modules</li> <li>Code Review - Comprehensive code analysis and recommendations</li> </ul>"},{"location":"#for-architects","title":"For Architects","text":"<ul> <li>Architecture Overview - System design, components, and data flow</li> <li>Design Patterns - Key architectural patterns implemented</li> <li>Scalability Considerations - Performance and scaling guidance</li> </ul>"},{"location":"#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"#installation","title":"Installation","text":"<pre><code># Clone and install\ngit clone &lt;repository-url&gt;\ncd parallel_agents\nuv pip install -e .\n\n# Initialize configuration\nuv run verifier init\n\n# Start monitoring\nuv run verifier start\n</code></pre>"},{"location":"#basic-configuration","title":"Basic Configuration","text":"<pre><code>{\n  \"watch_dirs\": [\"src\"],\n  \"agent_mission\": \"testing\",\n  \"claude_timeout\": 300\n}\n</code></pre>"},{"location":"#documentation-structure","title":"\ud83d\udcd6 Documentation Structure","text":"<pre><code>docs/\n\u251c\u2500\u2500 index.md              # This file - complete documentation index\n\u251c\u2500\u2500 README.md             # Documentation overview and navigation\n\u251c\u2500\u2500 user-guide.md         # Complete user manual\n\u251c\u2500\u2500 api-reference.md      # Detailed API documentation  \n\u251c\u2500\u2500 architecture.md       # System architecture and design\n\u251c\u2500\u2500 development.md        # Development and contribution guide\n\u2514\u2500\u2500 code-review.md        # Code analysis and recommendations\n</code></pre>"},{"location":"#system-components","title":"\ud83d\udd27 System Components","text":"Component Purpose Documentation Overseer Main coordinator process Architecture, API Agent Claude Code integration Architecture, API Watcher File system monitoring Architecture, API Delta Gate Change filtering and batching Architecture, API Reporter Error tracking and reporting Architecture, API Working Set Test artifact management Architecture, API Config Configuration management User Guide, API CLI Command-line interface User Guide, API"},{"location":"#use-cases-and-examples","title":"\ud83c\udfaf Use Cases and Examples","text":""},{"location":"#testing-mission","title":"Testing Mission","text":"<pre><code># Monitor source code and generate tests\nuv run verifier start -m testing\n</code></pre>"},{"location":"#documentation-mission","title":"Documentation Mission","text":"<pre><code># Generate documentation for code changes\nuv run verifier start -m docs\n</code></pre>"},{"location":"#custom-watch-directories","title":"Custom Watch Directories","text":"<pre><code># Monitor specific directories\nuv run verifier start -w src -w lib -w app\n</code></pre>"},{"location":"#demo-mode","title":"Demo Mode","text":"<pre><code># Test without calling Claude Code API\nuv run verifier demo\n</code></pre>"},{"location":"#key-features","title":"\ud83d\udd0d Key Features","text":"<ul> <li>\ud83d\udd04 Real-time Monitoring - Watches source directories for changes</li> <li>\ud83e\udde0 AI-Powered Testing - Uses Claude Code for intelligent test generation  </li> <li>\u26a1 Smart Filtering - Batches and filters changes to reduce noise</li> <li>\ud83d\udcca Error Reporting - Structured bug reports in JSONL format</li> <li>\ud83c\udf9b\ufe0f Configurable - Extensive configuration options</li> <li>\ud83d\udda5\ufe0f CLI Interface - Easy-to-use command-line tools</li> </ul>"},{"location":"#configuration-reference","title":"\ud83d\udccb Configuration Reference","text":""},{"location":"#core-settings","title":"Core Settings","text":"Setting Default Description <code>watch_dirs</code> <code>[\"src\"]</code> Directories to monitor <code>test_dir</code> <code>\"test\"</code> Test directory location <code>working_set_dir</code> <code>\"tests/working_set\"</code> Generated test location <code>agent_mission</code> <code>\"testing\"</code> Agent mission type <code>claude_timeout</code> <code>300</code> Claude Code timeout (seconds)"},{"location":"#file-extensions","title":"File Extensions","text":"<p>Monitored by default: <code>.py</code>, <code>.js</code>, <code>.ts</code>, <code>.jsx</code>, <code>.tsx</code>, <code>.go</code>, <code>.rs</code>, <code>.java</code>, <code>.cpp</code>, <code>.c</code>, <code>.h</code></p>"},{"location":"#cli-commands-reference","title":"\ud83d\udee0\ufe0f CLI Commands Reference","text":"Command Purpose Key Options <code>verifier start</code> Start the verifier <code>-w</code> watch dirs, <code>-m</code> mission <code>verifier demo</code> Start with mock agent Same as start <code>verifier init</code> Create configuration <code>-o</code> output file <code>verifier status</code> Show current status <code>-c</code> config file <code>verifier validate</code> Validate configuration <code>-c</code> config file"},{"location":"#troubleshooting-quick-reference","title":"\ud83d\udc1b Troubleshooting Quick Reference","text":""},{"location":"#common-issues","title":"Common Issues","text":""},{"location":"#configuration-file-not-found","title":"\"Configuration file not found\"","text":"<pre><code>uv run verifier init  # Create default config\n</code></pre>"},{"location":"#claude-code-failed","title":"\"Claude Code failed\"","text":"<ul> <li>Verify <code>claude</code> CLI is installed</li> <li>Check API credentials</li> <li>Test with demo mode: <code>uv run verifier demo</code></li> </ul>"},{"location":"#no-changes-detected","title":"\"No changes detected\"","text":"<ul> <li>Check file extensions in config</li> <li>Verify watch directories exist</li> <li>Review ignore patterns</li> </ul>"},{"location":"#performance-issues","title":"Performance Issues","text":"<ul> <li>Reduce watched directories</li> <li>Increase batch timeout</li> <li>Add ignore patterns for build files</li> </ul>"},{"location":"#design-patterns-used","title":"\ud83c\udfd7\ufe0f Design Patterns Used","text":""},{"location":"#event-driven-architecture","title":"Event-Driven Architecture","text":"<p>File changes trigger events through the system pipeline: <pre><code>File Change \u2192 Watcher \u2192 Delta Gate \u2192 Agent \u2192 Claude Code\n</code></pre></p>"},{"location":"#configuration-driven-design","title":"Configuration-Driven Design","text":"<p>Behavior controlled through JSON configuration files with validation.</p>"},{"location":"#pipeline-pattern","title":"Pipeline Pattern","text":"<p>Changes flow through processing stages with filtering and batching.</p>"},{"location":"#asyncawait-pattern","title":"Async/Await Pattern","text":"<p>Non-blocking operations for responsive monitoring.</p>"},{"location":"#scalability-and-performance","title":"\ud83d\udcc8 Scalability and Performance","text":""},{"location":"#optimization-features","title":"Optimization Features","text":"<ul> <li>Change Batching - Reduces processing overhead</li> <li>File Filtering - Ignores irrelevant files automatically  </li> <li>Configurable Timeouts - Balances responsiveness with resource usage</li> <li>Async Processing - Non-blocking operations</li> </ul>"},{"location":"#resource-management","title":"Resource Management","text":"<ul> <li>Temporary file cleanup</li> <li>Memory-efficient file processing</li> <li>Process timeout protection</li> <li>Graceful shutdown handling</li> </ul>"},{"location":"#security-considerations","title":"\ud83d\udd10 Security Considerations","text":""},{"location":"#input-validation","title":"Input Validation","text":"<ul> <li>File path validation</li> <li>Configuration parameter validation</li> <li>File size constraints</li> </ul>"},{"location":"#process-isolation","title":"Process Isolation","text":"<ul> <li>Subprocess execution for Claude Code</li> <li>Timeout protection</li> <li>Resource cleanup on failure</li> </ul>"},{"location":"#testing-strategy","title":"\ud83e\uddea Testing Strategy","text":""},{"location":"#test-types","title":"Test Types","text":"<ul> <li>Unit Tests - Individual component testing</li> <li>Integration Tests - Component interaction testing</li> <li>End-to-End Tests - Complete workflow validation</li> </ul>"},{"location":"#running-tests","title":"Running Tests","text":"<pre><code># Basic system tests\npython test_basic.py\n\n# Unit tests  \npytest tests/\n\n# With coverage\npytest --cov=verifier tests/\n</code></pre>"},{"location":"#development-workflow","title":"\ud83d\udd04 Development Workflow","text":""},{"location":"#for-contributors","title":"For Contributors","text":"<ol> <li>Fork &amp; Clone - Get the codebase</li> <li>Setup Environment - Install dependencies</li> <li>Make Changes - Implement features/fixes</li> <li>Test Thoroughly - Run all test suites</li> <li>Submit PR - Create pull request</li> </ol>"},{"location":"#code-standards","title":"Code Standards","text":"<ul> <li>Python 3.12+ required</li> <li>Black for formatting</li> <li>flake8 for linting  </li> <li>mypy for type checking</li> <li>pytest for testing</li> </ul>"},{"location":"#learning-path","title":"\ud83d\udcda Learning Path","text":""},{"location":"#new-users","title":"New Users","text":"<ol> <li>Start with User Guide installation</li> <li>Try the quick start example</li> <li>Explore configuration options</li> <li>Set up your project monitoring</li> </ol>"},{"location":"#developers","title":"Developers","text":"<ol> <li>Read Development Guide setup</li> <li>Review Architecture Overview</li> <li>Study API Reference</li> <li>Examine Code Review analysis</li> </ol>"},{"location":"#advanced-users","title":"Advanced Users","text":"<ol> <li>Customize agent missions</li> <li>Extend with plugins</li> <li>Integrate with CI/CD</li> <li>Performance optimization</li> </ol>"},{"location":"#getting-help","title":"\ud83e\udd1d Getting Help","text":""},{"location":"#documentation-issues","title":"Documentation Issues","text":"<p>If documentation is unclear or missing: 1. Check all sections in this index 2. Review code examples in tests 3. File documentation issues</p>"},{"location":"#technical-issues","title":"Technical Issues","text":"<p>For bugs or technical problems: 1. Check troubleshooting 2. Review error reports 3. Test with demo mode 4. File technical issues</p>"},{"location":"#feature-requests","title":"Feature Requests","text":"<p>For new features: 1. Review architecture for feasibility 2. Check development guide for contribution process 3. Submit feature request with use case</p>"},{"location":"#roadmap-and-future","title":"\ud83d\uddfa\ufe0f Roadmap and Future","text":""},{"location":"#planned-enhancements","title":"Planned Enhancements","text":"<ul> <li>Web Dashboard - Real-time monitoring interface</li> <li>Plugin System - Custom agent behaviors  </li> <li>Multi-language Support - Additional programming languages</li> <li>Performance Metrics - Detailed analytics</li> <li>Integration APIs - REST API for external tools</li> </ul>"},{"location":"#community","title":"Community","text":"<ul> <li>Examples Repository - More usage examples</li> <li>Tutorial Series - Step-by-step guides</li> <li>User Community - Discussion forums</li> <li>Ecosystem Integration - Tool integrations</li> </ul>"},{"location":"#quick-access","title":"\ud83d\udcde Quick Access","text":"Need Go To Install and run User Guide - Getting Started Configure for my project User Guide - Configuration Understand how it works Architecture Overview Integrate with my code API Reference Contribute to project Development Guide Fix problems User Guide - Troubleshooting See code quality Code Review <p>This documentation is generated for the Parallel Agents Verifier System. For the most up-to-date information, please refer to the individual documentation files and the project repository.</p>"},{"location":"api-reference/","title":"API Reference","text":"<p>This document provides detailed API documentation for all modules in the Parallel Agents Verifier System.</p>"},{"location":"api-reference/#core-modules","title":"Core Modules","text":""},{"location":"api-reference/#verifierconfig","title":"<code>verifier.config</code>","text":""},{"location":"api-reference/#verifierconfig_1","title":"<code>VerifierConfig</code>","text":"<p>Configuration management for the verifier system.</p> <p>Fields: - <code>watch_dirs: List[str]</code> - Directories to monitor (default: [\"src\"]) - <code>test_dir: str</code> - Directory for tests (default: \"test\") - <code>working_set_dir: str</code> - Working directory for generated tests (default: \"tests/working_set\") - <code>watch_extensions: List[str]</code> - File extensions to monitor - <code>agent_mission: str</code> - Mission for the agent (default: \"testing\") - <code>error_report_file: str</code> - Error report file path - <code>claude_timeout: int</code> - Claude Code timeout in seconds (default: 300) - <code>claude_log_file: str</code> - File to write Claude code interaction logs (default: \"tests/working_set/claude_logs.jsonl\")</p> <p>Methods: <pre><code>@classmethod\ndef from_file(cls, config_path: str) -&gt; 'VerifierConfig'\n</code></pre> Load configuration from JSON file.</p> <p><pre><code>def to_file(self, config_path: str) -&gt; None\n</code></pre> Save configuration to JSON file.</p> <p><pre><code>def get_default_config() -&gt; VerifierConfig\n</code></pre> Get default configuration instance.</p>"},{"location":"api-reference/#verifieroverseer","title":"<code>verifier.overseer</code>","text":""},{"location":"api-reference/#overseer","title":"<code>Overseer</code>","text":"<p>Main coordinator process for the verifier system.</p> <p>Constructor: <pre><code>def __init__(self, config: VerifierConfig)\n</code></pre></p> <p>Methods: <pre><code>async def start(self) -&gt; None\n</code></pre> Start the overseer process and begin monitoring.</p> <p><pre><code>async def stop(self) -&gt; None\n</code></pre> Stop the overseer process gracefully.</p> <p><pre><code>def is_running(self) -&gt; bool\n</code></pre> Check if the overseer is currently running.</p> <p>Private Methods: - <code>_on_file_change(self, file_path: str, action: str)</code> - Handle file system changes - <code>_setup_watchers(self)</code> - Initialize filesystem watchers</p> <ul> <li><code>async _process_pending_changes(self)</code> - Process batched file changes</li> <li><code>_process_error_reports(self)</code> - Handle new error reports</li> <li><code>_display_error_report(self, report: Dict[str, Any])</code> - Display formatted error reports</li> </ul>"},{"location":"api-reference/#verifieragent","title":"<code>verifier.agent</code>","text":""},{"location":"api-reference/#verifieragent_1","title":"<code>VerifierAgent</code>","text":"<p>Agent that interfaces with Claude Code for test generation.</p> <p>Constructor: <pre><code>def __init__(self, config: VerifierConfig)\n</code></pre></p> <p>Methods: <pre><code>async def start_session(self) -&gt; None\n</code></pre> Initialize a new verifier session with Claude Code.</p> <p><pre><code>async def process_file_changes(self, file_changes: List[Dict[str, Any]]) -&gt; None\n</code></pre> Process a batch of file changes and generate tests.</p> <p><pre><code>def get_conversation_history(self) -&gt; List[Dict[str, Any]]\n</code></pre> Get the conversation history with Claude Code.</p> <p><pre><code>def stop_session(self) -&gt; None\n</code></pre> Stop the current verifier session.</p> <p>Private Methods: - <code>_get_mission_prompt(self) -&gt; str</code> - Generate mission prompt for Claude Code - <code>_get_file_deltas_prompt(self, file_changes: List[Dict[str, Any]]) -&gt; str</code> - Generate change prompt - <code>async _run_claude_code(self, prompt: str) -&gt; str</code> - Execute Claude Code with prompt - <code>_read_file_content(self, file_path: str) -&gt; str</code> - Safely read file content</p>"},{"location":"api-reference/#verifierwatcher","title":"<code>verifier.watcher</code>","text":""},{"location":"api-reference/#filesystemwatcher","title":"<code>FilesystemWatcher</code>","text":"<p>Monitors filesystem changes in specified directories.</p> <p>Constructor: <pre><code>def __init__(self, watch_dir: str, callback: Callable[[str, str], None])\n</code></pre></p> <p>Methods: <pre><code>def start(self) -&gt; None\n</code></pre> Start monitoring the directory.</p> <p><pre><code>def stop(self) -&gt; None\n</code></pre> Stop monitoring and cleanup resources.</p> <p><pre><code>def is_alive(self) -&gt; bool\n</code></pre> Check if the watcher is currently active.</p>"},{"location":"api-reference/#filechangehandler","title":"<code>FileChangeHandler</code>","text":"<p>Internal event handler for filesystem events.</p> <p>Constructor: <pre><code>def __init__(self, callback: Callable[[str, str], None], watch_extensions: Optional[Set[str]] = None)\n</code></pre></p> <p>Methods: - <code>on_modified(self, event)</code> - Handle file modification events - <code>on_created(self, event)</code> - Handle file creation events - <code>on_deleted(self, event)</code> - Handle file deletion events - <code>_should_process_file(self, file_path: str) -&gt; bool</code> - Check if file should be processed</p>"},{"location":"api-reference/#verifierdelta_gate","title":"<code>verifier.delta_gate</code>","text":""},{"location":"api-reference/#deltagate","title":"<code>DeltaGate</code>","text":"<p>Filters and batches file changes for efficient processing.</p> <p>Constructor: <pre><code>def __init__(self, config: DeltaGateConfig = None)\n</code></pre></p> <p>Methods: <pre><code>def add_change(self, file_path: str, action: str) -&gt; bool\n</code></pre> Add a file change to the gate. Returns True if change was accepted.</p> <p><pre><code>def should_process_batch(self) -&gt; bool\n</code></pre> Check if the current batch should be processed.</p> <p><pre><code>def get_batch(self) -&gt; List[Dict[str, Any]]\n</code></pre> Get the current batch of changes and reset the gate.</p> <p><pre><code>def get_pending_count(self) -&gt; int\n</code></pre> Get the number of pending changes.</p> <p><pre><code>def clear_pending(self) -&gt; None\n</code></pre> Clear all pending changes.</p>"},{"location":"api-reference/#deltagateconfig","title":"<code>DeltaGateConfig</code>","text":"<p>Configuration for the delta gate.</p> <p>Fields: - <code>min_change_interval: float</code> - Minimum seconds between processing (default: 0.5) - <code>batch_timeout: float</code> - Maximum seconds to wait for batching (default: 2.0) - <code>ignore_patterns: Set[str]</code> - File patterns to ignore - <code>min_file_size: int</code> - Minimum file size to process (default: 1) - <code>max_file_size: int</code> - Maximum file size to process (default: 1MB)</p>"},{"location":"api-reference/#filechange","title":"<code>FileChange</code>","text":"<p>Represents a single file change event.</p> <p>Fields: - <code>file_path: str</code> - Path to the changed file - <code>action: str</code> - Type of change ('created', 'modified', 'deleted') - <code>timestamp: float</code> - When the change occurred - <code>size: Optional[int]</code> - File size (if applicable)</p>"},{"location":"api-reference/#verifierreporter","title":"<code>verifier.reporter</code>","text":""},{"location":"api-reference/#errorreporter","title":"<code>ErrorReporter</code>","text":"<p>Handles error reporting to JSONL files.</p> <p>Constructor: <pre><code>def __init__(self, report_file: str)\n</code></pre></p> <p>Methods: <pre><code>def report_error(self, file_path: str, line: Optional[int], severity: str, \n                description: str, suggested_fix: Optional[str] = None) -&gt; None\n</code></pre> Report an error to the JSONL file.</p> <p><pre><code>def get_pending_reports(self) -&gt; List[Dict[str, Any]]\n</code></pre> Get all pending error reports.</p> <p><pre><code>def clear_reports(self) -&gt; None\n</code></pre> Clear all reports.</p> <p><pre><code>def pop_report(self) -&gt; Optional[Dict[str, Any]]\n</code></pre> Remove and return the first report.</p>"},{"location":"api-reference/#reportmonitor","title":"<code>ReportMonitor</code>","text":"<p>Monitors the error report file for changes.</p> <p>Constructor: <pre><code>def __init__(self, report_file: str)\n</code></pre></p> <p>Methods: <pre><code>def has_new_reports(self) -&gt; bool\n</code></pre> Check if there are new reports since last check.</p> <p><pre><code>def get_new_reports(self) -&gt; List[Dict[str, Any]]\n</code></pre> Get new reports and mark them as processed.</p>"},{"location":"api-reference/#verifierworking_set","title":"<code>verifier.working_set</code>","text":""},{"location":"api-reference/#workingsetmanager","title":"<code>WorkingSetManager</code>","text":"<p>Manages the working set directory for generated tests and artifacts.</p> <p>Constructor: <pre><code>def __init__(self, working_set_dir: str)\n</code></pre></p> <p>Methods: <pre><code>def create_test_file(self, test_name: str, content: str) -&gt; Path\n</code></pre> Create a test file in the working set.</p> <p><pre><code>def list_test_files(self) -&gt; List[Path]\n</code></pre> List all test files in the working set.</p> <p><pre><code>def remove_test_file(self, test_name: str) -&gt; bool\n</code></pre> Remove a test file from the working set.</p> <p><pre><code>def clean_working_set(self) -&gt; None\n</code></pre> Clean the working set directory.</p> <p><pre><code>def get_working_set_size(self) -&gt; int\n</code></pre> Get the number of files in the working set.</p> <p><pre><code>def create_metadata_file(self, metadata: Dict[str, Any]) -&gt; Path\n</code></pre> Create a metadata file for the working set.</p> <p><pre><code>def read_metadata(self) -&gt; Optional[Dict[str, Any]]\n</code></pre> Read metadata from the working set.</p> <p><pre><code>def ensure_directory_structure(self) -&gt; None\n</code></pre> Ensure the working set has proper directory structure.</p> <p><pre><code>def get_working_set_path(self) -&gt; Path\n</code></pre> Get the working set directory path.</p>"},{"location":"api-reference/#verifiercli","title":"<code>verifier.cli</code>","text":""},{"location":"api-reference/#cli-commands","title":"CLI Commands","text":"<p><code>start</code> Start the verifier overseer process.</p> <p>Options: - <code>--config, -c</code>: Configuration file path (default: verifier.json) - <code>--watch-dir, -w</code>: Directories to watch (multiple allowed) - <code>--mission, -m</code>: Agent mission (testing, docs, tooling)</p> <p><code>demo</code> Start the verifier with mock agent for testing.</p> <p>Options: Same as <code>start</code></p> <p><code>init</code> Initialize a new verifier configuration.</p> <p>Options: - <code>--output, -o</code>: Output configuration file (default: verifier.json)</p> <p><code>status</code> Show verifier status and configuration.</p> <p>Options: - <code>--config, -c</code>: Configuration file path (default: verifier.json)</p> <p><code>validate</code> Validate the verifier configuration.</p> <p>Options: - <code>--config, -c</code>: Configuration file path (default: verifier.json)</p>"},{"location":"api-reference/#error-report-format","title":"Error Report Format","text":"<p>Error reports are stored in JSONL format with the following structure:</p> <pre><code>{\n  \"timestamp\": \"2024-01-15T10:30:00Z\",\n  \"file\": \"src/calculator.py\",\n  \"line\": 42,\n  \"severity\": \"high|medium|low\",\n  \"description\": \"Bug description\",\n  \"suggested_fix\": \"Optional fix suggestion\"\n}\n</code></pre>"},{"location":"api-reference/#configuration-schema","title":"Configuration Schema","text":"<pre><code>{\n  \"watch_dirs\": [\"src\"],\n  \"test_dir\": \"test\",\n  \"working_set_dir\": \"tests/working_set\",\n  \"watch_extensions\": [\".py\", \".js\", \".ts\"],\n  \"agent_mission\": \"testing\",\n  \"error_report_file\": \"tests/working_set/error_report.jsonl\",\n  \"claude_timeout\": 300,\n  \"claude_log_file\": \"tests/working_set/claude_logs.jsonl\"\n}\n</code></pre>"},{"location":"api-reference/#exception-handling","title":"Exception Handling","text":"<p>All modules implement comprehensive exception handling:</p> <ul> <li><code>RuntimeError</code>: For Claude Code execution failures</li> <li><code>FileNotFoundError</code>: For missing files/directories</li> <li><code>TimeoutError</code>: For operation timeouts</li> <li><code>ValidationError</code>: For configuration validation failures</li> <li><code>ValueError</code>: For invalid parameter values</li> </ul>"},{"location":"api-reference/#logging","title":"Logging","text":"<p>The system uses print statements for logging. For production use, consider implementing structured logging with the <code>logging</code> module.</p>"},{"location":"architecture/","title":"Architecture Overview","text":"<p>The Parallel Agents Verifier System is a sophisticated automated testing framework that uses Claude Code agents to monitor source code changes and generate tests in real-time.</p>"},{"location":"architecture/#system-components","title":"System Components","text":""},{"location":"architecture/#1-overseer-overseerpy","title":"1. Overseer (<code>overseer.py</code>)","text":"<p>The central coordinator that manages all system components: - Purpose: Orchestrates the entire system lifecycle - Key Responsibilities:   - Initializes and coordinates all components   - Manages the main event loop   - Handles graceful shutdown   - Processes file changes and error reports   - Displays colored error reports to users</p>"},{"location":"architecture/#2-filesystem-watcher-watcherpy","title":"2. Filesystem Watcher (<code>watcher.py</code>)","text":"<p>Real-time file system monitoring: - Purpose: Detects file changes in watched directories - Key Features:   - Recursive directory monitoring   - Configurable file extension filtering   - Event-driven architecture using watchdog library   - Supports create, modify, and delete events</p>"},{"location":"architecture/#3-delta-gate-delta_gatepy","title":"3. Delta Gate (<code>delta_gate.py</code>)","text":"<p>Intelligent change filtering and batching: - Purpose: Reduces noise and batches changes efficiently - Key Features:   - Filters out irrelevant files (*.pyc, logs, etc.)   - Batches changes to avoid processing every minor change   - Configurable timing and size constraints   - File size validation</p>"},{"location":"architecture/#4-verifier-agent-agentpy","title":"4. Verifier Agent (<code>agent.py</code>)","text":"<p>Claude Code integration for automated testing: - Purpose: Interfaces with Claude Code to generate and run tests - Key Features:   - Maintains conversation history   - Configurable mission prompts   - Asynchronous Claude Code execution   - Timeout handling   - Error reporting integration</p>"},{"location":"architecture/#5-error-reporter-reporterpy","title":"5. Error Reporter (<code>reporter.py</code>)","text":"<p>Bug tracking and reporting system: - Purpose: Handles error reporting in JSONL format - Key Features:   - Structured error reports with severity levels   - JSONL format for machine readability   - Report monitoring and processing   - Timestamped error entries</p>"},{"location":"architecture/#6-working-set-manager-working_setpy","title":"6. Working Set Manager (<code>working_set.py</code>)","text":"<p>Test artifact management: - Purpose: Manages generated tests and artifacts - Key Features:   - Organized directory structure   - Test file creation and management   - Metadata tracking   - Cleanup utilities</p>"},{"location":"architecture/#7-configuration-system-configpy","title":"7. Configuration System (<code>config.py</code>)","text":"<p>Centralized configuration management: - Purpose: Manages all system settings - Key Features:   - Pydantic-based validation   - JSON configuration files   - Default value handling   - Environment-specific settings</p>"},{"location":"architecture/#8-cli-interface-clipy","title":"8. CLI Interface (<code>cli.py</code>)","text":"<p>Command-line interface for system operations: - Purpose: Provides user-friendly command-line access - Key Features:   - Multiple operation modes (start, demo, init, status, validate)   - Configuration override capabilities   - Interactive feedback   - Mock mode for testing</p>"},{"location":"architecture/#data-flow","title":"Data Flow","text":"<pre><code>File Change \u2192 Filesystem Watcher \u2192 Delta Gate \u2192 Verifier Agent \u2192 Claude Code\n                                                      \u2193\nWorking Set Manager \u2190 Error Reporter \u2190 Test Generation &amp; Execution\n</code></pre>"},{"location":"architecture/#key-design-patterns","title":"Key Design Patterns","text":""},{"location":"architecture/#1-event-driven-architecture","title":"1. Event-Driven Architecture","text":"<ul> <li>File changes trigger events through the system</li> <li>Asynchronous processing for responsiveness</li> <li>Decoupled components communicate through events</li> </ul>"},{"location":"architecture/#2-pipeline-pattern","title":"2. Pipeline Pattern","text":"<ul> <li>Changes flow through a processing pipeline</li> <li>Each stage adds value and filtering</li> <li>Clear separation of concerns</li> </ul>"},{"location":"architecture/#3-configuration-driven-design","title":"3. Configuration-Driven Design","text":"<ul> <li>Behavior controlled through configuration</li> <li>Environment-specific customization</li> <li>Runtime parameter adjustment</li> </ul>"},{"location":"architecture/#4-graceful-degradation","title":"4. Graceful Degradation","text":"<ul> <li>System continues operation despite component failures</li> <li>Comprehensive error handling</li> <li>Resource cleanup on shutdown</li> </ul>"},{"location":"architecture/#threading-and-concurrency","title":"Threading and Concurrency","text":"<p>The system uses: - AsyncIO: For non-blocking operations - Watchdog Observers: For file system monitoring - Process Execution: For Claude Code integration - Thread-Safe Operations: For cross-component communication</p>"},{"location":"architecture/#scalability-considerations","title":"Scalability Considerations","text":""},{"location":"architecture/#performance-optimizations","title":"Performance Optimizations","text":"<ul> <li>Change batching to reduce processing overhead</li> <li>File filtering to avoid unnecessary work</li> <li>Configurable timeouts for resource management</li> <li>Efficient file I/O operations</li> </ul>"},{"location":"architecture/#resource-management","title":"Resource Management","text":"<ul> <li>Temporary file cleanup</li> <li>Memory-efficient file processing</li> <li>Configurable working set management</li> <li>Process timeout handling</li> </ul>"},{"location":"architecture/#security-considerations","title":"Security Considerations","text":""},{"location":"architecture/#input-validation","title":"Input Validation","text":"<ul> <li>File path validation</li> <li>Configuration parameter validation</li> <li>File extension filtering</li> <li>Size constraints</li> </ul>"},{"location":"architecture/#process-isolation","title":"Process Isolation","text":"<ul> <li>Subprocess execution for Claude Code</li> <li>Timeout protection against hanging processes</li> <li>Resource cleanup on failure</li> </ul>"},{"location":"architecture/#extension-points","title":"Extension Points","text":"<p>The architecture supports extension through: - Custom Missions: Different agent behaviors - File Type Support: Additional language support - Reporter Backends: Different output formats - Watcher Enhancements: Advanced filtering rules</p>"},{"location":"code-review/","title":"Code Review and Analysis","text":"<p>This document provides a comprehensive review of the Parallel Agents Verifier System codebase, highlighting strengths, areas for improvement, and recommendations.</p>"},{"location":"code-review/#overall-assessment","title":"Overall Assessment","text":"<p>Quality Score: 8/10</p> <p>The codebase demonstrates solid software engineering practices with clean architecture, good separation of concerns, and comprehensive functionality. The system is well-designed for its intended purpose of automated testing with Claude Code integration.</p>"},{"location":"code-review/#strengths","title":"Strengths","text":""},{"location":"code-review/#1-architecture-and-design","title":"1. Architecture and Design","text":"<p>\u2705 Excellent Separation of Concerns - Each module has a clear, single responsibility - Components are loosely coupled and highly cohesive - Clean interfaces between components</p> <p>\u2705 Event-Driven Architecture - Proper use of callbacks and async/await patterns - Responsive file system monitoring - Non-blocking operations</p> <p>\u2705 Configuration-Driven Design - Centralized configuration management - Pydantic for validation and type safety - Environment-specific customization support</p>"},{"location":"code-review/#2-code-quality","title":"2. Code Quality","text":"<p>\u2705 Type Hints and Documentation <pre><code># Good example from agent.py\nasync def process_file_changes(self, file_changes: List[Dict[str, Any]]) -&gt; None:\n    \"\"\"Process file changes and update the verifier\"\"\"\n</code></pre></p> <p>\u2705 Error Handling <pre><code># Good example from agent.py\ntry:\n    response = await self._run_claude_code(full_prompt)\nexcept Exception as e:\n    print(f\"Failed to process file changes: {e}\")\n</code></pre></p> <p>\u2705 Resource Management <pre><code># Good example from agent.py\n# Clean up temp file\nPath(prompt_file).unlink(missing_ok=True)\n</code></pre></p>"},{"location":"code-review/#3-testing","title":"3. Testing","text":"<p>\u2705 Comprehensive Test Coverage - Unit tests for individual components - Integration tests for component interactions - Basic system tests for end-to-end validation</p> <p>\u2705 Test Organization - Clear test structure with separate test files - Good use of temporary directories for isolation - Realistic test scenarios</p>"},{"location":"code-review/#4-cli-design","title":"4. CLI Design","text":"<p>\u2705 User-Friendly Interface - Clear command structure with click framework - Helpful options and documentation - Proper error messages and feedback</p>"},{"location":"code-review/#areas-for-improvement","title":"Areas for Improvement","text":""},{"location":"code-review/#1-logging-and-observability","title":"1. Logging and Observability","text":"<p>\u274c Inconsistent Logging</p> <p>Current implementation uses <code>print()</code> statements: <pre><code>print(f\"File change detected: {action} {file_path}\")\nprint(f\"Processed batch of {len(batch)} changes\")\n</code></pre></p> <p>Recommendation: <pre><code>import logging\n\nlogger = logging.getLogger(__name__)\n\nlogger.info(\"File change detected: %s %s\", action, file_path)\nlogger.info(\"Processed batch of %d changes\", len(batch))\n</code></pre></p> <p>\u274c Lack of Structured Logging</p> <p>Recommendation: Implement structured logging with context: <pre><code>import structlog\n\nlogger = structlog.get_logger()\n\nlogger.info(\"file_change_detected\", \n           action=action, \n           file_path=file_path, \n           batch_size=len(batch))\n</code></pre></p>"},{"location":"code-review/#2-error-handling","title":"2. Error Handling","text":"<p>\u274c Generic Exception Handling</p> <p>Current implementation: <pre><code>except Exception as e:\n    print(f\"Failed to process file changes: {e}\")\n</code></pre></p> <p>Recommendation: <pre><code>except TimeoutError:\n    logger.error(\"Claude Code operation timed out\")\n    raise\nexcept subprocess.CalledProcessError as e:\n    logger.error(\"Claude Code execution failed: %s\", e)\n    raise\nexcept Exception as e:\n    logger.exception(\"Unexpected error processing file changes\")\n    raise\n</code></pre></p>"},{"location":"code-review/#3-configuration-validation","title":"3. Configuration Validation","text":"<p>\u274c Limited Runtime Validation</p> <p>Recommendation: Add comprehensive validation: <pre><code>class VerifierConfig(BaseModel):\n    watch_dirs: List[str] = Field(default=['src'])\n\n    @validator('watch_dirs')\n    def validate_watch_dirs(cls, v):\n        for dir_path in v:\n            if not Path(dir_path).exists():\n                warnings.warn(f\"Watch directory does not exist: {dir_path}\")\n        return v\n\n    @validator('claude_timeout')\n    def validate_timeout(cls, v):\n        if v &lt;= 0:\n            raise ValueError(\"Timeout must be positive\")\n        if v &gt; 3600:  # 1 hour\n            warnings.warn(\"Very long timeout specified\")\n        return v\n</code></pre></p>"},{"location":"code-review/#4-performance-and-scalability","title":"4. Performance and Scalability","text":"<p>\u274c No Rate Limiting</p> <p>Recommendation: Add rate limiting for Claude Code API calls: <pre><code>import asyncio\nfrom asyncio import Semaphore\n\nclass VerifierAgent:\n    def __init__(self, config):\n        self.rate_limiter = Semaphore(5)  # Max 5 concurrent requests\n\n    async def _run_claude_code(self, prompt: str) -&gt; str:\n        async with self.rate_limiter:\n            # Existing implementation\n            pass\n</code></pre></p> <p>\u274c Memory Usage for Large Files</p> <p>Current implementation reads entire files: <pre><code>def _read_file_content(self, file_path: str) -&gt; str:\n    with open(file_path, 'r', encoding='utf-8') as f:\n        return f.read()  # Could be problematic for large files\n</code></pre></p> <p>Recommendation: <pre><code>def _read_file_content(self, file_path: str, max_size: int = 1024 * 1024) -&gt; str:\n    \"\"\"Read file content with size limit\"\"\"\n    file_size = Path(file_path).stat().st_size\n    if file_size &gt; max_size:\n        return f\"File too large ({file_size} bytes), truncating...\"\n\n    with open(file_path, 'r', encoding='utf-8') as f:\n        return f.read()\n</code></pre></p>"},{"location":"code-review/#5-security-considerations","title":"5. Security Considerations","text":"<p>\u274c Path Traversal Vulnerability</p> <p>Recommendation: Add path validation: <pre><code>def _validate_file_path(self, file_path: str) -&gt; bool:\n    \"\"\"Validate file path to prevent directory traversal\"\"\"\n    resolved_path = Path(file_path).resolve()\n    for watch_dir in self.config.watch_dirs:\n        watch_path = Path(watch_dir).resolve()\n        try:\n            resolved_path.relative_to(watch_path)\n            return True\n        except ValueError:\n            continue\n    return False\n</code></pre></p> <p>\u274c Subprocess Security</p> <p>Recommendation: Improve subprocess execution: <pre><code>async def _run_claude_code(self, prompt: str) -&gt; str:\n    # Validate command exists\n    if not shutil.which(\"claude\"):\n        raise RuntimeError(\"claude command not found\")\n\n    # Use absolute paths and validate arguments\n    cmd = [shutil.which(\"claude\"), \"--print\", \"--dangerously-skip-permissions\", prompt]\n\n    # Set environment variables safely\n    env = os.environ.copy()\n    env.pop(\"LD_PRELOAD\", None)  # Remove potentially dangerous env vars\n</code></pre></p>"},{"location":"code-review/#specific-module-analysis","title":"Specific Module Analysis","text":""},{"location":"code-review/#configpy-configuration-management","title":"<code>config.py</code> - Configuration Management","text":"<p>Strengths: - Good use of Pydantic for validation - Clear field documentation - Proper file handling</p> <p>Improvements: - Add environment variable support - Implement configuration migration - Add more comprehensive validation</p>"},{"location":"code-review/#overseerpy-main-coordinator","title":"<code>overseer.py</code> - Main Coordinator","text":"<p>Strengths: - Clear responsibility as system coordinator - Good signal handling for graceful shutdown - Proper component lifecycle management</p> <p>Improvements: - Add health check endpoints - Implement component restart capabilities - Add metrics collection</p>"},{"location":"code-review/#agentpy-claude-code-integration","title":"<code>agent.py</code> - Claude Code Integration","text":"<p>Strengths: - Good separation of prompt generation and execution - Proper timeout handling - Conversation history tracking</p> <p>Improvements: - Add retry logic with exponential backoff - Implement request queuing - Add response validation</p>"},{"location":"code-review/#watcherpy-file-system-monitoring","title":"<code>watcher.py</code> - File System Monitoring","text":"<p>Strengths: - Clean use of watchdog library - Proper file extension filtering - Good resource management</p> <p>Improvements: - Add debouncing for rapid changes - Implement directory-specific handlers - Add symbolic link handling</p>"},{"location":"code-review/#delta_gatepy-change-filtering","title":"<code>delta_gate.py</code> - Change Filtering","text":"<p>Strengths: - Excellent batching logic - Comprehensive ignore patterns - Good performance characteristics</p> <p>Improvements: - Add configurable ignore patterns - Implement change priority - Add change conflict detection</p>"},{"location":"code-review/#reporterpy-error-reporting","title":"<code>reporter.py</code> - Error Reporting","text":"<p>Strengths: - Clean JSONL format - Atomic file operations - Good data structure</p> <p>Improvements: - Add report rotation - Implement report indexing - Add report aggregation</p>"},{"location":"code-review/#testing-analysis","title":"Testing Analysis","text":""},{"location":"code-review/#current-testing","title":"Current Testing","text":"<p>Strengths: - Good coverage of core functionality - Realistic test scenarios - Proper use of temporary directories</p> <p>Improvements Needed: <pre><code># Add async test support\nimport pytest\n\n@pytest.mark.asyncio\nasync def test_agent_timeout():\n    config = VerifierConfig(claude_timeout=0.1)\n    agent = VerifierAgent(config)\n\n    with pytest.raises(asyncio.TimeoutError):\n        await agent._run_claude_code(\"test prompt\")\n\n# Add property-based testing\nfrom hypothesis import given, strategies as st\n\n@given(st.text(), st.one_of(st.just(\"created\"), st.just(\"modified\"), st.just(\"deleted\")))\ndef test_delta_gate_properties(file_path, action):\n    gate = DeltaGate()\n    # Test that gate handles arbitrary inputs gracefully\n    gate.add_change(file_path, action)\n</code></pre></p>"},{"location":"code-review/#performance-recommendations","title":"Performance Recommendations","text":""},{"location":"code-review/#1-async-optimization","title":"1. Async Optimization","text":"<pre><code># Use asyncio.gather for concurrent operations\nasync def process_multiple_changes(self, change_batches):\n    tasks = [self.process_file_changes(batch) for batch in change_batches]\n    results = await asyncio.gather(*tasks, return_exceptions=True)\n    return results\n</code></pre>"},{"location":"code-review/#2-caching","title":"2. Caching","text":"<pre><code>from functools import lru_cache\n\nclass VerifierAgent:\n    @lru_cache(maxsize=100)\n    def _get_file_metadata(self, file_path: str) -&gt; Dict[str, Any]:\n        \"\"\"Cache file metadata to avoid repeated stat calls\"\"\"\n        stat = Path(file_path).stat()\n        return {\n            \"size\": stat.st_size,\n            \"mtime\": stat.st_mtime,\n            \"mode\": stat.st_mode\n        }\n</code></pre>"},{"location":"code-review/#3-memory-management","title":"3. Memory Management","text":"<pre><code># Use generators for large data processing\ndef iter_large_files(self, directory: Path):\n    \"\"\"Generator for processing large numbers of files\"\"\"\n    for file_path in directory.rglob(\"*\"):\n        if self._should_process_file(str(file_path)):\n            yield file_path\n</code></pre>"},{"location":"code-review/#security-recommendations","title":"Security Recommendations","text":""},{"location":"code-review/#1-input-validation","title":"1. Input Validation","text":"<pre><code>import re\n\nclass SecurityValidator:\n    SAFE_PATH_PATTERN = re.compile(r'^[a-zA-Z0-9._/-]+$')\n\n    @classmethod\n    def validate_file_path(cls, path: str) -&gt; bool:\n        \"\"\"Validate file path for security\"\"\"\n        if not cls.SAFE_PATH_PATTERN.match(path):\n            return False\n        if '..' in path:\n            return False\n        return True\n</code></pre>"},{"location":"code-review/#2-resource-limits","title":"2. Resource Limits","text":"<pre><code>class ResourceLimits:\n    MAX_FILE_SIZE = 10 * 1024 * 1024  # 10MB\n    MAX_PROMPT_LENGTH = 100000  # 100k characters\n    MAX_CONCURRENT_OPERATIONS = 10\n\n    @classmethod\n    def check_file_size(cls, file_path: str) -&gt; bool:\n        return Path(file_path).stat().st_size &lt;= cls.MAX_FILE_SIZE\n</code></pre>"},{"location":"code-review/#documentation-quality","title":"Documentation Quality","text":"<p>Strengths: - Comprehensive README with examples - Good inline documentation - Clear API signatures</p> <p>Improvements: - Add more code examples - Include performance benchmarks - Add troubleshooting guides</p>"},{"location":"code-review/#future-enhancements","title":"Future Enhancements","text":""},{"location":"code-review/#1-plugin-system","title":"1. Plugin System","text":"<pre><code>class PluginManager:\n    def __init__(self):\n        self.plugins = {}\n\n    def register_plugin(self, name: str, plugin: Any):\n        self.plugins[name] = plugin\n\n    async def execute_hooks(self, hook_name: str, *args, **kwargs):\n        for plugin in self.plugins.values():\n            if hasattr(plugin, hook_name):\n                await getattr(plugin, hook_name)(*args, **kwargs)\n</code></pre>"},{"location":"code-review/#2-metrics-collection","title":"2. Metrics Collection","text":"<pre><code>from dataclasses import dataclass\nfrom typing import Counter\n\n@dataclass\nclass Metrics:\n    files_processed: int = 0\n    changes_detected: Counter = field(default_factory=Counter)\n    errors_reported: int = 0\n    processing_time: float = 0.0\n</code></pre>"},{"location":"code-review/#3-web-interface","title":"3. Web Interface","text":"<pre><code>from fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/status\")\nasync def get_status():\n    return {\n        \"status\": \"running\",\n        \"metrics\": overseer.get_metrics(),\n        \"config\": overseer.config.dict()\n    }\n</code></pre>"},{"location":"code-review/#conclusion","title":"Conclusion","text":"<p>The Parallel Agents Verifier System is a well-architected solution with clean code and good design patterns. The main areas for improvement are:</p> <ol> <li>Logging and Observability: Implement structured logging</li> <li>Error Handling: More specific exception handling</li> <li>Performance: Add rate limiting and caching</li> <li>Security: Input validation and resource limits</li> <li>Testing: More comprehensive test coverage</li> </ol> <p>With these improvements, the system would be production-ready for enterprise use. The current implementation is excellent for development and small-scale deployment.</p> <p>Overall Recommendation: Proceed with deployment while addressing the identified improvements incrementally.</p>"},{"location":"development/","title":"Development Guide","text":"<p>This guide covers development practices, testing, and contribution guidelines for the Parallel Agents Verifier System.</p>"},{"location":"development/#development-setup","title":"Development Setup","text":""},{"location":"development/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.12 or higher</li> <li><code>uv</code> package manager</li> <li><code>claude</code> CLI tool (for integration testing)</li> <li>Git for version control</li> </ul>"},{"location":"development/#environment-setup","title":"Environment Setup","text":"<ol> <li> <p>Clone the repository: <pre><code>git clone &lt;repository-url&gt;\ncd parallel_agents\n</code></pre></p> </li> <li> <p>Create development environment: <pre><code>uv venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n</code></pre></p> </li> <li> <p>Install in development mode: <pre><code>uv pip install -e .\n</code></pre></p> </li> <li> <p>Install development dependencies: <pre><code>uv pip install pytest pytest-asyncio pytest-cov black flake8 mypy\n</code></pre></p> </li> </ol>"},{"location":"development/#project-structure","title":"Project Structure","text":"<pre><code>parallel_agents/\n\u251c\u2500\u2500 src/                    # Example source code\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 calculator.py\n\u251c\u2500\u2500 verifier/              # Main package\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 agent.py          # Claude Code integration\n\u2502   \u251c\u2500\u2500 cli.py            # Command line interface\n\u2502   \u251c\u2500\u2500 config.py         # Configuration management\n\u2502   \u251c\u2500\u2500 delta_gate.py     # Change filtering\n\u2502   \u251c\u2500\u2500 overseer.py       # Main coordinator\n\u2502   \u251c\u2500\u2500 reporter.py       # Error reporting\n\u2502   \u251c\u2500\u2500 watcher.py        # File system monitoring\n\u2502   \u2514\u2500\u2500 working_set.py    # Test artifact management\n\u251c\u2500\u2500 tests/                 # Unit tests\n\u2502   \u251c\u2500\u2500 test_config.py\n\u2502   \u2514\u2500\u2500 test_delta_gate.py\n\u251c\u2500\u2500 test/                  # Integration tests\n\u2502   \u2514\u2500\u2500 working_set/       # Generated artifacts\n\u251c\u2500\u2500 docs/                  # Documentation\n\u251c\u2500\u2500 main.py               # Entry point\n\u251c\u2500\u2500 test_basic.py         # Basic system tests\n\u251c\u2500\u2500 verifier.json         # Configuration\n\u251c\u2500\u2500 pyproject.toml        # Package configuration\n\u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"development/#code-style-and-standards","title":"Code Style and Standards","text":""},{"location":"development/#python-style-guide","title":"Python Style Guide","text":"<p>This project follows PEP 8 with the following conventions:</p> <ul> <li>Line Length: 88 characters (Black default)</li> <li>String Quotes: Double quotes for strings, single quotes for short literals</li> <li>Imports: Use absolute imports, group by standard library, third-party, local</li> <li>Type Hints: Use type hints for all public functions and methods</li> <li>Docstrings: Use Google-style docstrings for all public APIs</li> </ul>"},{"location":"development/#code-formatting","title":"Code Formatting","text":"<p>Use <code>black</code> for automatic code formatting:</p> <pre><code>black verifier/ tests/\n</code></pre>"},{"location":"development/#linting","title":"Linting","text":"<p>Use <code>flake8</code> for linting:</p> <pre><code>flake8 verifier/ tests/\n</code></pre>"},{"location":"development/#type-checking","title":"Type Checking","text":"<p>Use <code>mypy</code> for static type checking:</p> <pre><code>mypy verifier/\n</code></pre>"},{"location":"development/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<p>Consider setting up pre-commit hooks:</p> <pre><code>pip install pre-commit\npre-commit install\n</code></pre> <p>Create <code>.pre-commit-config.yaml</code>: <pre><code>repos:\n  - repo: https://github.com/psf/black\n    rev: 23.1.0\n    hooks:\n      - id: black\n  - repo: https://github.com/pycqa/flake8\n    rev: 6.0.0\n    hooks:\n      - id: flake8\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v1.0.1\n    hooks:\n      - id: mypy\n</code></pre></p>"},{"location":"development/#testing","title":"Testing","text":""},{"location":"development/#test-structure","title":"Test Structure","text":"<p>The project uses multiple testing approaches:</p> <ol> <li>Unit Tests (<code>tests/</code>): Test individual components in isolation</li> <li>Integration Tests (<code>test_basic.py</code>): Test component interactions</li> <li>End-to-End Tests: Test the complete system workflow</li> </ol>"},{"location":"development/#running-tests","title":"Running Tests","text":""},{"location":"development/#basic-tests","title":"Basic Tests","text":"<pre><code>python test_basic.py\n</code></pre>"},{"location":"development/#unit-tests","title":"Unit Tests","text":"<pre><code>pytest tests/\n</code></pre>"},{"location":"development/#with-coverage","title":"With Coverage","text":"<pre><code>pytest --cov=verifier --cov-report=html tests/\n</code></pre>"},{"location":"development/#test-categories","title":"Test Categories","text":""},{"location":"development/#unit-tests_1","title":"Unit Tests","text":"<p>Test individual components:</p> <pre><code># tests/test_config.py\nimport pytest\nfrom src.config import VerifierConfig\n\ndef test_default_config():\n    config = VerifierConfig()\n    assert config.watch_dirs == [\"src\"]\n    assert config.agent_mission == \"testing\"\n\ndef test_config_validation():\n    config = VerifierConfig(watch_dirs=[])\n    assert len(config.watch_dirs) == 0\n</code></pre>"},{"location":"development/#integration-tests","title":"Integration Tests","text":"<p>Test component interactions:</p> <pre><code># test_basic.py\ndef test_filesystem_watcher():\n    changes = []\n\n    def on_change(file_path, action):\n        changes.append((file_path, action))\n\n    with tempfile.TemporaryDirectory() as temp_dir:\n        watcher = FilesystemWatcher(temp_dir, on_change)\n        watcher.start()\n\n        # Create test file\n        test_file = Path(temp_dir) / \"test.py\"\n        test_file.write_text(\"print('hello')\")\n\n        time.sleep(0.5)\n        watcher.stop()\n\n        assert len(changes) &gt; 0\n</code></pre>"},{"location":"development/#mock-testing","title":"Mock Testing","text":"<p>Use mocks for external dependencies:</p> <pre><code>from unittest.mock import patch, MagicMock\nimport pytest\n\n@patch('verifier.agent.subprocess')\nasync def test_claude_code_execution(mock_subprocess):\n    # Mock subprocess execution\n    mock_process = MagicMock()\n    mock_process.returncode = 0\n    mock_process.communicate.return_value = (b\"Success\", b\"\")\n    mock_subprocess.create_subprocess_exec.return_value = mock_process\n\n    agent = VerifierAgent(VerifierConfig())\n    result = await agent._run_claude_code(\"test prompt\")\n\n    assert result == \"Success\"\n</code></pre>"},{"location":"development/#test-data","title":"Test Data","text":"<p>Create test fixtures for consistent testing:</p> <pre><code>@pytest.fixture\ndef temp_config():\n    with tempfile.TemporaryDirectory() as temp_dir:\n        config = VerifierConfig(working_set_dir=temp_dir)\n        yield config\n\n@pytest.fixture\ndef sample_changes():\n    return [\n        {\"file_path\": \"src/test.py\", \"action\": \"created\", \"timestamp\": time.time()},\n        {\"file_path\": \"src/test.py\", \"action\": \"modified\", \"timestamp\": time.time()},\n    ]\n</code></pre>"},{"location":"development/#development-workflow","title":"Development Workflow","text":""},{"location":"development/#feature-development","title":"Feature Development","text":"<ol> <li> <p>Create Feature Branch: <pre><code>git checkout -b feature/new-feature\n</code></pre></p> </li> <li> <p>Implement Feature:</p> </li> <li>Write tests first (TDD approach)</li> <li>Implement the feature</li> <li> <p>Update documentation</p> </li> <li> <p>Test Thoroughly: <pre><code>python test_basic.py\npytest tests/\nblack verifier/\nflake8 verifier/\nmypy verifier/\n</code></pre></p> </li> <li> <p>Commit and Push: <pre><code>git add .\ngit commit -m \"Add new feature: description\"\ngit push origin feature/new-feature\n</code></pre></p> </li> </ol>"},{"location":"development/#bug-fixes","title":"Bug Fixes","text":"<ol> <li> <p>Create Bug Fix Branch: <pre><code>git checkout -b bugfix/issue-description\n</code></pre></p> </li> <li> <p>Write Failing Test: <pre><code>def test_bug_reproduction():\n    # Test that reproduces the bug\n    pass\n</code></pre></p> </li> <li> <p>Fix the Bug:</p> </li> <li>Implement the fix</li> <li>Ensure test passes</li> <li> <p>Verify no regression</p> </li> <li> <p>Test and Commit: <pre><code>pytest tests/\ngit add .\ngit commit -m \"Fix: description of bug fix\"\n</code></pre></p> </li> </ol>"},{"location":"development/#code-review-process","title":"Code Review Process","text":"<ol> <li>Self Review:</li> <li>Check code style and formatting</li> <li>Verify tests pass</li> <li> <p>Review documentation updates</p> </li> <li> <p>Peer Review:</p> </li> <li>Create pull request</li> <li>Request reviews from team members</li> <li> <p>Address feedback</p> </li> <li> <p>Automated Checks:</p> </li> <li>CI/CD pipeline runs tests</li> <li>Code quality checks pass</li> <li>Coverage requirements met</li> </ol>"},{"location":"development/#architecture-guidelines","title":"Architecture Guidelines","text":""},{"location":"development/#component-design","title":"Component Design","text":""},{"location":"development/#single-responsibility","title":"Single Responsibility","text":"<p>Each component should have a single, well-defined responsibility:</p> <pre><code># Good: Focused on file watching\nclass FilesystemWatcher:\n    def __init__(self, watch_dir, callback):\n        self.watch_dir = watch_dir\n        self.callback = callback\n</code></pre>"},{"location":"development/#dependency-injection","title":"Dependency Injection","text":"<p>Use dependency injection for testability:</p> <pre><code># Good: Dependencies injected\nclass Overseer:\n    def __init__(self, config, agent=None, watcher=None):\n        self.config = config\n        self.agent = agent or VerifierAgent(config)\n        self.watcher = watcher or FilesystemWatcher(config.watch_dirs[0])\n</code></pre>"},{"location":"development/#error-handling","title":"Error Handling","text":"<p>Implement comprehensive error handling:</p> <pre><code>async def process_changes(self, changes):\n    try:\n        result = await self.agent.process_file_changes(changes)\n        return result\n    except TimeoutError:\n        logger.error(\"Agent timeout while processing changes\")\n        return None\n    except Exception as e:\n        logger.error(f\"Unexpected error: {e}\")\n        raise\n</code></pre>"},{"location":"development/#configuration-management","title":"Configuration Management","text":""},{"location":"development/#environment-variables","title":"Environment Variables","text":"<p>Support environment variable overrides:</p> <pre><code>import os\n\nclass VerifierConfig(BaseModel):\n    claude_timeout: int = Field(\n        default=300,\n        description=\"Claude Code timeout in seconds\"\n    )\n\n    @classmethod\n    def from_env(cls):\n        return cls(\n            claude_timeout=int(os.getenv(\"CLAUDE_TIMEOUT\", \"300\"))\n        )\n</code></pre>"},{"location":"development/#validation","title":"Validation","text":"<p>Validate configuration at startup:</p> <pre><code>def validate_config(config: VerifierConfig):\n    for watch_dir in config.watch_dirs:\n        if not Path(watch_dir).exists():\n            raise ValueError(f\"Watch directory does not exist: {watch_dir}\")\n</code></pre>"},{"location":"development/#performance-considerations","title":"Performance Considerations","text":""},{"location":"development/#async-operations","title":"Async Operations","text":"<p>Use async/await for I/O operations:</p> <pre><code>async def process_file_changes(self, changes):\n    tasks = []\n    for change in changes:\n        task = asyncio.create_task(self._process_single_change(change))\n        tasks.append(task)\n\n    results = await asyncio.gather(*tasks, return_exceptions=True)\n    return results\n</code></pre>"},{"location":"development/#memory-management","title":"Memory Management","text":"<p>Clean up resources properly:</p> <pre><code>class ResourceManager:\n    def __init__(self):\n        self.resources = []\n\n    def add_resource(self, resource):\n        self.resources.append(resource)\n\n    def cleanup(self):\n        for resource in self.resources:\n            try:\n                resource.close()\n            except Exception as e:\n                logger.warning(f\"Error cleaning up resource: {e}\")\n</code></pre>"},{"location":"development/#debugging","title":"Debugging","text":""},{"location":"development/#logging-setup","title":"Logging Setup","text":"<p>Add comprehensive logging:</p> <pre><code>import logging\n\n# In main module\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('verifier.log'),\n        logging.StreamHandler()\n    ]\n)\n\n# In each module\nlogger = logging.getLogger(__name__)\n</code></pre>"},{"location":"development/#debug-mode","title":"Debug Mode","text":"<p>Support debug mode in configuration:</p> <pre><code>class VerifierConfig(BaseModel):\n    debug: bool = Field(default=False, description=\"Enable debug mode\")\n\n    def setup_logging(self):\n        level = logging.DEBUG if self.debug else logging.INFO\n        logging.getLogger().setLevel(level)\n</code></pre>"},{"location":"development/#troubleshooting-tools","title":"Troubleshooting Tools","text":""},{"location":"development/#health-check","title":"Health Check","text":"<pre><code>def health_check(config: VerifierConfig):\n    \"\"\"Check system health\"\"\"\n    checks = {\n        \"config_valid\": True,\n        \"watch_dirs_exist\": all(Path(d).exists() for d in config.watch_dirs),\n        \"working_set_writable\": Path(config.working_set_dir).parent.exists(),\n        \"claude_code_available\": shutil.which(\"claude\") is not None,\n    }\n    return checks\n</code></pre>"},{"location":"development/#performance-profiling","title":"Performance Profiling","text":"<pre><code>import cProfile\nimport pstats\n\ndef profile_function(func):\n    def wrapper(*args, **kwargs):\n        pr = cProfile.Profile()\n        pr.enable()\n        result = func(*args, **kwargs)\n        pr.disable()\n\n        stats = pstats.Stats(pr)\n        stats.sort_stats('cumulative')\n        stats.print_stats()\n\n        return result\n    return wrapper\n</code></pre>"},{"location":"development/#contributing","title":"Contributing","text":""},{"location":"development/#contribution-guidelines","title":"Contribution Guidelines","text":"<ol> <li>Follow Code Style: Use Black, flake8, and mypy</li> <li>Write Tests: All new features must include tests</li> <li>Update Documentation: Update relevant documentation</li> <li>Atomic Commits: Make small, focused commits</li> <li>Descriptive Messages: Use clear commit messages</li> </ol>"},{"location":"development/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Fork the Repository</li> <li>Create Feature Branch</li> <li>Make Changes</li> <li>Write/Update Tests</li> <li>Update Documentation</li> <li>Submit Pull Request</li> </ol>"},{"location":"development/#issue-reporting","title":"Issue Reporting","text":"<p>When reporting issues:</p> <ol> <li>Use Issue Template</li> <li>Provide Reproduction Steps</li> <li>Include Configuration</li> <li>Add Error Messages</li> <li>Specify Environment</li> </ol>"},{"location":"development/#feature-requests","title":"Feature Requests","text":"<p>For new features:</p> <ol> <li>Describe Use Case</li> <li>Explain Benefit</li> <li>Consider Alternatives</li> <li>Provide Examples</li> </ol>"},{"location":"development/#release-process","title":"Release Process","text":""},{"location":"development/#version-management","title":"Version Management","text":"<p>Use semantic versioning (MAJOR.MINOR.PATCH):</p> <ul> <li>MAJOR: Breaking changes</li> <li>MINOR: New features (backward compatible)</li> <li>PATCH: Bug fixes</li> </ul>"},{"location":"development/#release-checklist","title":"Release Checklist","text":"<ol> <li>Update Version: In <code>pyproject.toml</code></li> <li>Update Changelog: Document changes</li> <li>Run All Tests: Ensure quality</li> <li>Update Documentation: Reflect changes</li> <li>Tag Release: Create git tag</li> <li>Build Package: Create distribution</li> <li>Publish: Upload to PyPI</li> </ol>"},{"location":"development/#deployment","title":"Deployment","text":"<p>For deployment:</p> <pre><code># Build package\nuv build\n\n# Test upload\nuv publish --repository-url https://test.pypi.org/legacy/\n\n# Production upload\nuv publish\n</code></pre>"},{"location":"development/#future-enhancements","title":"Future Enhancements","text":""},{"location":"development/#planned-features","title":"Planned Features","text":"<ol> <li>Web Interface: Real-time monitoring dashboard</li> <li>Plugin System: Custom agent behaviors</li> <li>Integration APIs: REST API for external tools</li> <li>Multi-language Support: Support for more languages</li> <li>Performance Metrics: Detailed performance tracking</li> </ol>"},{"location":"development/#architecture-improvements","title":"Architecture Improvements","text":"<ol> <li>Microservices: Split into smaller services</li> <li>Event Sourcing: Better event handling</li> <li>Distributed Processing: Handle large codebases</li> <li>Caching: Improve performance</li> <li>Security: Enhanced security features</li> </ol>"},{"location":"development/#community","title":"Community","text":"<ol> <li>Documentation: Expand documentation</li> <li>Examples: More usage examples</li> <li>Tutorials: Step-by-step guides</li> <li>Community: Build user community</li> <li>Ecosystem: Integration with other tools</li> </ol>"},{"location":"user-guide/","title":"User Guide","text":"<p>This guide will help you get started with the Parallel Agents Verifier System and make the most of its features.</p>"},{"location":"user-guide/#getting-started","title":"Getting Started","text":""},{"location":"user-guide/#prerequisites","title":"Prerequisites","text":"<p>Before using the verifier system, ensure you have: - Python 3.12 or higher - <code>uv</code> package manager - <code>claude</code> CLI tool installed and configured - Access to Claude Code API</p>"},{"location":"user-guide/#installation","title":"Installation","text":"<ol> <li> <p>Clone the repository: <pre><code>git clone &lt;repository-url&gt;\ncd parallel_agents\n</code></pre></p> </li> <li> <p>Install dependencies: <pre><code>uv pip install -e .\n</code></pre></p> </li> <li> <p>Verify installation: <pre><code>uv run verifier --help\n</code></pre></p> </li> </ol>"},{"location":"user-guide/#initial-setup","title":"Initial Setup","text":"<ol> <li> <p>Initialize configuration: <pre><code>uv run verifier init\n</code></pre>    This creates a <code>verifier.json</code> file with default settings.</p> </li> <li> <p>Customize configuration:    Edit <code>verifier.json</code> to match your project structure:    <pre><code>{\n  \"watch_dirs\": [\"src\", \"lib\"],\n  \"test_dir\": \"tests\",\n  \"working_set_dir\": \"tests/generated\",\n  \"agent_mission\": \"testing\",\n  \"claude_timeout\": 300\n}\n</code></pre></p> </li> <li> <p>Validate configuration: <pre><code>uv run verifier validate\n</code></pre></p> </li> </ol>"},{"location":"user-guide/#basic-usage","title":"Basic Usage","text":""},{"location":"user-guide/#starting-the-verifier","title":"Starting the Verifier","text":"<p>To start monitoring your codebase:</p> <pre><code>uv run verifier start\n</code></pre> <p>The verifier will: - Begin monitoring configured directories - Start a Claude Code agent session - Process file changes as they occur - Generate tests automatically - Report any bugs found</p>"},{"location":"user-guide/#demo-mode","title":"Demo Mode","text":"<p>For testing without actually calling Claude Code:</p> <pre><code>uv run verifier demo\n</code></pre> <p>This uses a mock agent that simulates the behavior without making API calls.</p>"},{"location":"user-guide/#checking-status","title":"Checking Status","text":"<p>To see current configuration and status:</p> <pre><code>uv run verifier status\n</code></pre>"},{"location":"user-guide/#configuration-guide","title":"Configuration Guide","text":""},{"location":"user-guide/#core-settings","title":"Core Settings","text":""},{"location":"user-guide/#watch_dirs","title":"<code>watch_dirs</code>","text":"<p>List of directories to monitor for changes. <pre><code>\"watch_dirs\": [\"src\", \"app\", \"lib\"]\n</code></pre></p>"},{"location":"user-guide/#test_dir","title":"<code>test_dir</code>","text":"<p>Directory where tests are stored. <pre><code>\"test_dir\": \"test\"\n</code></pre></p>"},{"location":"user-guide/#working_set_dir","title":"<code>working_set_dir</code>","text":"<p>Directory for generated tests and artifacts. <pre><code>  \"working_set_dir\": \"tests/working_set\"\n</code></pre></p>"},{"location":"user-guide/#watch_extensions","title":"<code>watch_extensions</code>","text":"<p>File extensions to monitor. <pre><code>\"watch_extensions\": [\".py\", \".js\", \".ts\", \".jsx\", \".tsx\", \".go\", \".rs\"]\n</code></pre></p>"},{"location":"user-guide/#agent_mission","title":"<code>agent_mission</code>","text":"<p>Mission for the Claude Code agent: - <code>\"testing\"</code> - Generate and run tests - <code>\"docs\"</code> - Generate documentation - <code>\"tooling\"</code> - Create development tools</p> <pre><code>\"agent_mission\": \"testing\"\n</code></pre>"},{"location":"user-guide/#error_report_file","title":"<code>error_report_file</code>","text":"<p>Path to the error report file (JSONL format). <pre><code>  \"error_report_file\": \"tests/working_set/error_report.jsonl\"\n</code></pre></p>"},{"location":"user-guide/#claude_timeout","title":"<code>claude_timeout</code>","text":"<p>Timeout for Claude Code operations in seconds. <pre><code>\"claude_timeout\": 300\n</code></pre></p>"},{"location":"user-guide/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"user-guide/#filtering-behavior","title":"Filtering Behavior","text":"<p>The system automatically filters out: - Compiled files (.pyc, .pyo, .pyd) - Version control files (.git, .gitignore) - Log files (.log) - Temporary files (.tmp, .swp) - System files (.DS_Store) - Dependencies (node_modules, pycache)</p>"},{"location":"user-guide/#batching-behavior","title":"Batching Behavior","text":"<p>Changes are batched to avoid processing every minor change: - Minimum interval: 0.5 seconds between processing - Batch timeout: 2.0 seconds maximum wait time - File size limits: 1 byte minimum, 1MB maximum</p>"},{"location":"user-guide/#working-with-the-system","title":"Working with the System","text":""},{"location":"user-guide/#understanding-the-workflow","title":"Understanding the Workflow","text":"<ol> <li>File Change Detection: The system monitors your source files</li> <li>Change Filtering: Irrelevant changes are filtered out</li> <li>Change Batching: Multiple changes are grouped together</li> <li>Test Generation: Claude Code analyzes changes and generates tests</li> <li>Test Execution: Generated tests are run automatically</li> <li>Error Reporting: Any bugs found are reported</li> </ol>"},{"location":"user-guide/#monitoring-output","title":"Monitoring Output","text":"<p>The verifier provides real-time feedback:</p> <pre><code>Starting Verifier Overseer...\nWatching directory: src\nOverseer started. Monitoring for changes...\nFile change detected: modified src/calculator.py\nProcessed batch of 1 changes\n\n\ud83d\udea8 ERROR REPORT (HIGH)\nFile: src/calculator.py\nLine: 15\nDescription: Division by zero not handled\nSuggested Fix: Add zero check before division\nTimestamp: 2024-01-15T10:30:00Z\n</code></pre>"},{"location":"user-guide/#error-reports","title":"Error Reports","text":"<p>Error reports are stored in JSONL format and displayed with color coding: - Red: High severity errors - Yellow: Medium severity errors - Blue: Low severity errors</p>"},{"location":"user-guide/#working-set-management","title":"Working Set Management","text":"<p>The working set directory contains: - <code>tests/</code> - Generated test files - <code>artifacts/</code> - Additional generated files - <code>reports/</code> - Error reports and metadata</p>"},{"location":"user-guide/#command-line-options","title":"Command Line Options","text":""},{"location":"user-guide/#global-options","title":"Global Options","text":"<p>All commands support: - <code>--config, -c</code>: Specify configuration file path - <code>--help</code>: Show command help</p>"},{"location":"user-guide/#start-command","title":"Start Command","text":"<pre><code>uv run verifier start [OPTIONS]\n</code></pre> <p>Options: - <code>--watch-dir, -w</code>: Override watch directories (multiple allowed) - <code>--mission, -m</code>: Override agent mission</p> <p>Examples: <pre><code># Start with custom watch directories\nuv run verifier start -w src -w lib\n\n# Start with documentation mission\nuv run verifier start -m docs\n\n# Start with custom config file\nuv run verifier start -c my-config.json\n</code></pre></p>"},{"location":"user-guide/#demo-command","title":"Demo Command","text":"<pre><code>uv run verifier demo [OPTIONS]\n</code></pre> <p>Same options as <code>start</code> command, but uses mock agent.</p>"},{"location":"user-guide/#init-command","title":"Init Command","text":"<pre><code>uv run verifier init [OPTIONS]\n</code></pre> <p>Options: - <code>--output, -o</code>: Output configuration file path</p>"},{"location":"user-guide/#status-command","title":"Status Command","text":"<pre><code>uv run verifier status [OPTIONS]\n</code></pre> <p>Shows current configuration and validates directories.</p>"},{"location":"user-guide/#validate-command","title":"Validate Command","text":"<pre><code>uv run verifier validate [OPTIONS]\n</code></pre> <p>Validates configuration and checks directory permissions.</p>"},{"location":"user-guide/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/#project-structure","title":"Project Structure","text":"<p>Organize your project for optimal results:</p> <pre><code>my-project/\n\u251c\u2500\u2500 src/                    # Source code (watched)\n\u2502   \u251c\u2500\u2500 main.py\n\u2502   \u2514\u2500\u2500 utils.py\n\u251c\u2500\u2500 test/                   # Regular tests\n\u2502   \u2514\u2500\u2500 test_manual.py\n\u251c\u2500\u2500 tests/working_set/       # Generated tests\n\u2502   \u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 artifacts/\n\u2502   \u2514\u2500\u2500 reports/\n\u251c\u2500\u2500 verifier.json          # Configuration\n\u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"user-guide/#configuration-tips","title":"Configuration Tips","text":"<ol> <li>Watch Specific Directories: Only watch directories with source code</li> <li>Exclude Build Directories: Don't watch build, dist, or output directories</li> <li>Set Reasonable Timeouts: Balance responsiveness with API costs</li> <li>Use Descriptive Missions: Clear missions help Claude Code understand goals</li> </ol>"},{"location":"user-guide/#workflow-integration","title":"Workflow Integration","text":""},{"location":"user-guide/#with-git","title":"With Git","text":"<p>Add to <code>.gitignore</code>: <pre><code>tests/working_set/\n*.jsonl\n</code></pre></p>"},{"location":"user-guide/#with-cicd","title":"With CI/CD","text":"<p>Consider running the verifier in CI: <pre><code># .github/workflows/verifier.yml\nname: Verifier\non: [push, pull_request]\njobs:\n  verify:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - run: uv run verifier validate\n</code></pre></p>"},{"location":"user-guide/#with-development","title":"With Development","text":"<p>Run the verifier in a separate terminal while developing: <pre><code># Terminal 1: Development\nvim src/main.py\n\n# Terminal 2: Verifier\nuv run verifier start\n</code></pre></p>"},{"location":"user-guide/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/#common-issues","title":"Common Issues","text":""},{"location":"user-guide/#configuration-file-not-found","title":"\"Configuration file not found\"","text":"<ul> <li>Run <code>uv run verifier init</code> to create default configuration</li> <li>Check the configuration file path</li> </ul>"},{"location":"user-guide/#claude-code-failed","title":"\"Claude Code failed\"","text":"<ul> <li>Ensure <code>claude</code> CLI is installed and configured</li> <li>Check API credentials and permissions</li> <li>Verify network connectivity</li> </ul>"},{"location":"user-guide/#watch-directory-does-not-exist","title":"\"Watch directory does not exist\"","text":"<ul> <li>Verify directory paths in configuration</li> <li>Use absolute paths if needed</li> <li>Check directory permissions</li> </ul>"},{"location":"user-guide/#no-changes-detected","title":"\"No changes detected\"","text":"<ul> <li>Verify file extensions are in <code>watch_extensions</code></li> <li>Check if files are being filtered by ignore patterns</li> <li>Ensure directories are being watched</li> </ul>"},{"location":"user-guide/#performance-issues","title":"Performance Issues","text":""},{"location":"user-guide/#high-cpu-usage","title":"High CPU Usage","text":"<ul> <li>Reduce the number of watched directories</li> <li>Add more ignore patterns</li> <li>Increase <code>min_change_interval</code></li> </ul>"},{"location":"user-guide/#slow-response","title":"Slow Response","text":"<ul> <li>Reduce <code>claude_timeout</code></li> <li>Increase <code>batch_timeout</code> to process more changes together</li> <li>Use demo mode for testing</li> </ul>"},{"location":"user-guide/#debug-mode","title":"Debug Mode","text":"<p>Enable verbose output by modifying the source code to add logging:</p> <pre><code>import logging\nlogging.basicConfig(level=logging.DEBUG)\n</code></pre>"},{"location":"user-guide/#advanced-usage","title":"Advanced Usage","text":""},{"location":"user-guide/#custom-missions","title":"Custom Missions","text":"<p>Create custom missions by modifying the agent mission:</p> <pre><code>{\n  \"agent_mission\": \"Generate comprehensive integration tests for API endpoints\"\n}\n</code></pre>"},{"location":"user-guide/#multiple-configurations","title":"Multiple Configurations","text":"<p>Use different configurations for different projects:</p> <pre><code># Web project\nuv run verifier start -c web-config.json\n\n# API project\nuv run verifier start -c api-config.json\n</code></pre>"},{"location":"user-guide/#integration-with-ides","title":"Integration with IDEs","text":"<p>Many IDEs can be configured to run the verifier automatically:</p>"},{"location":"user-guide/#vs-code","title":"VS Code","text":"<p>Add to <code>.vscode/tasks.json</code>: <pre><code>{\n  \"label\": \"Start Verifier\",\n  \"type\": \"shell\",\n  \"command\": \"uv run verifier start\",\n  \"group\": \"build\",\n  \"presentation\": {\n    \"echo\": true,\n    \"reveal\": \"always\",\n    \"focus\": false,\n    \"panel\": \"dedicated\"\n  }\n}\n</code></pre></p>"},{"location":"user-guide/#extending-the-system","title":"Extending the System","text":"<p>The system is designed to be extensible. Consider: - Adding new file watchers - Implementing custom report formats - Creating specialized agents for different tasks - Adding integration with testing frameworks</p>"},{"location":"user-guide/#support","title":"Support","text":"<p>For issues and questions: 1. Check the troubleshooting section 2. Review the configuration 3. Test with demo mode 4. Check error reports for details 5. Validate your setup with <code>uv run verifier validate</code></p>"},{"location":"review/architecture/","title":"Architecture Review","text":""},{"location":"review/architecture/#overview","title":"Overview","text":"<p>This document provides a comprehensive review of the Parallel Agents project architecture, covering the complete transformation from a CLI-only tool to a modern server-client architecture with plugin extensibility.</p>"},{"location":"review/architecture/#system-architecture","title":"System Architecture","text":""},{"location":"review/architecture/#high-level-architecture","title":"High-Level Architecture","text":"<p>The Parallel Agents system follows a server-client architecture with the following key components:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      Client Layer                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  ParallelAgentsClient  \u2502  AgentProxy  \u2502  WebSocket Connections  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                    \u2502\n                                    \u2502 HTTP/WebSocket\n                                    \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      Server Layer                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  FastAPI Server  \u2502  WebSocket Manager  \u2502  Agent Sessions       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                    \u2502\n                                    \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      Core Layer                                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Agent Factory  \u2502  Configuration  \u2502  Monitoring  \u2502  Review      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                    \u2502\n                                    \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   External Tools                                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Block Goose    \u2502  Claude Code    \u2502  Mock Agents               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"review/architecture/#directory-structure","title":"Directory Structure","text":"<p>The project is organized into a modular structure:</p> <pre><code>src/\n\u251c\u2500\u2500 server/                     # FastAPI Server\n\u2502   \u251c\u2500\u2500 app.py                 # Main application with WebSocket support\n\u2502   \u251c\u2500\u2500 routes/                # API route handlers\n\u2502   \u2502   \u251c\u2500\u2500 agents.py          # Agent management endpoints\n\u2502   \u2502   \u251c\u2500\u2500 config.py          # Configuration management\n\u2502   \u2502   \u251c\u2500\u2500 health.py          # Health check endpoints\n\u2502   \u2502   \u2514\u2500\u2500 working_set.py     # Working set file management\n\u2502   \u2514\u2500\u2500 models/                # Pydantic models (future expansion)\n\u2502\n\u251c\u2500\u2500 client/                    # Client SDK\n\u2502   \u251c\u2500\u2500 client.py             # Main client class\n\u2502   \u251c\u2500\u2500 agent.py              # Agent proxy objects\n\u2502   \u251c\u2500\u2500 exceptions.py         # Client-specific exceptions\n\u2502   \u2514\u2500\u2500 __init__.py           # Client package exports\n\u2502\n\u251c\u2500\u2500 core/                     # Business logic\n\u2502   \u251c\u2500\u2500 config/               # Configuration management\n\u2502   \u2502   \u251c\u2500\u2500 models.py         # Configuration data models\n\u2502   \u2502   \u251c\u2500\u2500 profiles.py       # Pre-built configuration profiles\n\u2502   \u2502   \u2514\u2500\u2500 __init__.py       # Configuration exports\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 agents/               # Agent implementations\n\u2502   \u2502   \u251c\u2500\u2500 base.py           # Abstract base agent class\n\u2502   \u2502   \u251c\u2500\u2500 factory.py        # Agent factory functions\n\u2502   \u2502   \u251c\u2500\u2500 goose/            # Block Goose agent implementation\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 agent.py      # Goose agent classes\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 runner.py     # Goose headless execution\n\u2502   \u2502   \u251c\u2500\u2500 claude/           # Claude Code agent implementation\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 agent.py      # Claude Code agent classes\n\u2502   \u2502   \u2514\u2500\u2500 mock/             # Mock agent for testing\n\u2502   \u2502       \u2514\u2500\u2500 agent.py      # Mock agent implementation\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 monitoring/           # File monitoring and change detection\n\u2502   \u2502   \u251c\u2500\u2500 delta_gate.py     # File change detection\n\u2502   \u2502   \u251c\u2500\u2500 watcher.py        # File system watcher\n\u2502   \u2502   \u2514\u2500\u2500 working_set.py    # Working set management\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 overseer/             # Agent orchestration\n\u2502   \u2502   \u251c\u2500\u2500 overseer.py       # Main overseer class\n\u2502   \u2502   \u2514\u2500\u2500 mock_overseer.py  # Mock overseer for testing\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 review/               # Code review functionality\n\u2502       \u251c\u2500\u2500 agent.py          # Review agent implementation\n\u2502       \u2514\u2500\u2500 reporter.py       # Review reporting\n\u2502\n\u2514\u2500\u2500 utils/                    # Shared utilities\n    \u251c\u2500\u2500 calculator.py         # Mathematical utilities\n    \u2514\u2500\u2500 __init__.py           # Utility exports\n</code></pre>"},{"location":"review/architecture/#key-components","title":"Key Components","text":""},{"location":"review/architecture/#1-server-layer-srcserver","title":"1. Server Layer (<code>src/server/</code>)","text":""},{"location":"review/architecture/#fastapi-application-apppy","title":"FastAPI Application (<code>app.py</code>)","text":"<ul> <li>Purpose: Main server application with WebSocket support</li> <li>Key Features:</li> <li>RESTful API endpoints for agent management</li> <li>WebSocket connections for real-time log streaming</li> <li>CORS support for cross-origin requests</li> <li>Session management for active agents</li> <li>Health monitoring and status reporting</li> </ul>"},{"location":"review/architecture/#route-handlers-routes","title":"Route Handlers (<code>routes/</code>)","text":"<ul> <li><code>agents.py</code>: Agent lifecycle management (start, stop, process files)</li> <li><code>config.py</code>: Configuration and profile management</li> <li><code>health.py</code>: System health checks and monitoring</li> <li><code>working_set.py</code>: Working set file management</li> </ul>"},{"location":"review/architecture/#2-client-layer-srcclient","title":"2. Client Layer (<code>src/client/</code>)","text":""},{"location":"review/architecture/#parallelagentsclient-clientpy","title":"ParallelAgentsClient (<code>client.py</code>)","text":"<ul> <li>Purpose: Main client interface for interacting with the server</li> <li>Key Features:</li> <li>HTTP client for RESTful API calls</li> <li>WebSocket client for real-time log streaming</li> <li>Agent proxy management</li> <li>Connection pooling and error handling</li> <li>Context manager support for cleanup</li> </ul>"},{"location":"review/architecture/#agentproxy-agentpy","title":"AgentProxy (<code>agent.py</code>)","text":"<ul> <li>Purpose: Client-side representation of server-side agents</li> <li>Key Features:</li> <li>Proxy pattern for remote agent operations</li> <li>Log subscription management</li> <li>File processing delegation</li> <li>Status monitoring</li> </ul>"},{"location":"review/architecture/#3-core-layer-srccore","title":"3. Core Layer (<code>src/core/</code>)","text":""},{"location":"review/architecture/#configuration-system-config","title":"Configuration System (<code>config/</code>)","text":"<ul> <li>Models: Pydantic-based configuration validation</li> <li>Profiles: Pre-built configuration profiles for different use cases</li> <li>Features:</li> <li>Type-safe configuration handling</li> <li>Profile-based configuration management</li> <li>Validation and error handling</li> <li>JSON serialization/deserialization</li> </ul>"},{"location":"review/architecture/#agent-system-agents","title":"Agent System (<code>agents/</code>)","text":"<ul> <li>Base Agent: Abstract base class defining agent interface</li> <li>Factory Pattern: Centralized agent creation and management</li> <li>Implementations:</li> <li>Block Goose: Headless execution with <code>goose run</code></li> <li>Claude Code: Integration with Claude Code CLI</li> <li>Mock: Testing and development agent</li> </ul>"},{"location":"review/architecture/#monitoring-system-monitoring","title":"Monitoring System (<code>monitoring/</code>)","text":"<ul> <li>Delta Gate: File change detection and filtering</li> <li>Watcher: File system monitoring</li> <li>Working Set: Temporary file management for agent processing</li> </ul>"},{"location":"review/architecture/#agent-architecture","title":"Agent Architecture","text":""},{"location":"review/architecture/#agent-lifecycle","title":"Agent Lifecycle","text":"<pre><code>graph TD\n    A[Client Request] --&gt; B[Agent Factory]\n    B --&gt; C[Agent Creation]\n    C --&gt; D[Session Management]\n    D --&gt; E[Agent Running]\n    E --&gt; F[File Processing]\n    F --&gt; G[Log Generation]\n    G --&gt; H[WebSocket Streaming]\n    E --&gt; I[Agent Shutdown]\n    I --&gt; J[Cleanup]\n</code></pre>"},{"location":"review/architecture/#agent-types","title":"Agent Types","text":"<ol> <li>Verifier Agents: Focus on code verification and testing</li> <li>Documentation Agents: Generate and maintain documentation</li> <li>Review Agents: Perform code reviews and analysis</li> </ol>"},{"location":"review/architecture/#agent-implementations","title":"Agent Implementations","text":""},{"location":"review/architecture/#block-goose-agent","title":"Block Goose Agent","text":"<ul> <li>Installation Check: Verifies <code>goose --version</code> availability</li> <li>Headless Execution: Uses <code>goose run</code> command for non-interactive processing</li> <li>Session Management: Maintains isolated sessions for each agent</li> <li>Timeout Handling: Configurable timeout for long-running operations</li> </ul>"},{"location":"review/architecture/#claude-code-agent","title":"Claude Code Agent","text":"<ul> <li>Platform Support: Currently supports non-Windows platforms</li> <li>Integration: Direct integration with Claude Code CLI</li> <li>File Processing: Batch processing of file changes</li> </ul>"},{"location":"review/architecture/#mock-agent","title":"Mock Agent","text":"<ul> <li>Testing: Provides consistent behavior for testing</li> <li>Development: Allows development without external dependencies</li> <li>Simulation: Simulates real agent behavior with predictable responses</li> </ul>"},{"location":"review/architecture/#configuration-system","title":"Configuration System","text":""},{"location":"review/architecture/#configuration-profiles","title":"Configuration Profiles","text":"<p>The system includes pre-built configuration profiles:</p> <ol> <li>Testing Profile:</li> <li>Code tool: Block Goose</li> <li>Log level: DEBUG</li> <li>Max iterations: 3</li> <li> <p>Purpose: Development and testing</p> </li> <li> <p>Documentation Profile:</p> </li> <li>Code tool: Block Goose</li> <li>Mission: Documentation generation</li> <li> <p>Purpose: Automated documentation</p> </li> <li> <p>Demo Profile:</p> </li> <li>Code tool: Mock</li> <li> <p>Purpose: Demonstrations and examples</p> </li> <li> <p>Minimal Profile:</p> </li> <li>Basic configuration</li> <li> <p>Purpose: Minimal resource usage</p> </li> <li> <p>Full Stack Profile:</p> </li> <li>Complete feature set</li> <li>Purpose: Production deployments</li> </ol>"},{"location":"review/architecture/#configuration-management","title":"Configuration Management","text":"<ul> <li>Validation: Pydantic-based validation with type checking</li> <li>Inheritance: Profile-based configuration inheritance</li> <li>Flexibility: Runtime configuration override capability</li> <li>Persistence: Configuration saving and loading</li> </ul>"},{"location":"review/architecture/#communication-architecture","title":"Communication Architecture","text":""},{"location":"review/architecture/#http-api","title":"HTTP API","text":"<p>The server exposes RESTful endpoints:</p> <ul> <li><code>/api/agents/</code>: Agent management operations</li> <li><code>/api/config/</code>: Configuration and profile management</li> <li><code>/api/health/</code>: Health checks and system status</li> <li><code>/api/working-set/</code>: Working set file operations</li> </ul>"},{"location":"review/architecture/#websocket-streaming","title":"WebSocket Streaming","text":"<p>Real-time log streaming via WebSocket:</p> <ul> <li>Connection Management: Per-agent WebSocket connections</li> <li>Log Filtering: Configurable log level filtering</li> <li>Subscription Model: Client-side log subscription management</li> <li>Automatic Reconnection: Robust connection handling</li> </ul>"},{"location":"review/architecture/#security-considerations","title":"Security Considerations","text":""},{"location":"review/architecture/#current-implementation","title":"Current Implementation","text":"<ul> <li>Input Validation: Pydantic-based request validation</li> <li>Error Handling: Structured error responses</li> <li>Resource Management: Proper cleanup and resource limiting</li> </ul>"},{"location":"review/architecture/#future-enhancements","title":"Future Enhancements","text":"<ul> <li>Authentication: JWT-based authentication system</li> <li>Authorization: Role-based access control</li> <li>Rate Limiting: Request rate limiting</li> <li>Audit Logging: Comprehensive audit trail</li> </ul>"},{"location":"review/architecture/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"review/architecture/#strengths","title":"Strengths","text":"<ol> <li>Asynchronous Processing: FastAPI's async capabilities</li> <li>Connection Pooling: Efficient connection management</li> <li>Modular Design: Minimal resource overhead per component</li> <li>Caching: Configuration and profile caching</li> </ol>"},{"location":"review/architecture/#optimization-opportunities","title":"Optimization Opportunities","text":"<ol> <li>Database Integration: Persistent state management</li> <li>Horizontal Scaling: Multi-instance deployment</li> <li>Resource Monitoring: Advanced resource usage tracking</li> <li>Load Balancing: Distributed agent execution</li> </ol>"},{"location":"review/architecture/#integration-points","title":"Integration Points","text":""},{"location":"review/architecture/#external-tool-integration","title":"External Tool Integration","text":"<ol> <li>Block Goose: </li> <li>Installation verification</li> <li>Headless execution via <code>goose run</code></li> <li>Session management</li> <li> <p>Timeout handling</p> </li> <li> <p>Claude Code:</p> </li> <li>CLI integration</li> <li>Platform-specific support</li> <li> <p>File processing capabilities</p> </li> <li> <p>Mock Systems:</p> </li> <li>Testing framework integration</li> <li>Development environment support</li> </ol>"},{"location":"review/architecture/#plugin-architecture","title":"Plugin Architecture","text":"<p>The system is designed for extensibility:</p> <ul> <li>Agent Plugins: New agent types can be easily added</li> <li>Configuration Plugins: Custom configuration providers</li> <li>Monitoring Plugins: Custom file monitoring strategies</li> <li>Transport Plugins: Alternative communication protocols</li> </ul>"},{"location":"review/architecture/#deployment-architecture","title":"Deployment Architecture","text":""},{"location":"review/architecture/#development-deployment","title":"Development Deployment","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Development    \u2502    \u2502  Local Server   \u2502\n\u2502  Client         \u2502\u2190\u2192  \u2502  (localhost:8000)\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"review/architecture/#production-deployment","title":"Production Deployment","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Client Apps    \u2502    \u2502  Load Balancer  \u2502    \u2502  Server Cluster \u2502\n\u2502  (Multiple)     \u2502\u2190\u2192  \u2502  (nginx/traefik)\u2502\u2190\u2192  \u2502  (Docker/K8s)   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"review/architecture/#evolution-and-migration","title":"Evolution and Migration","text":""},{"location":"review/architecture/#phase-1-cli-only-complete","title":"Phase 1: CLI-Only (Complete)","text":"<ul> <li>Single-threaded CLI application</li> <li>Direct tool integration</li> <li>Local file processing</li> </ul>"},{"location":"review/architecture/#phase-2-sdk-integration-complete","title":"Phase 2: SDK Integration (Complete)","text":"<ul> <li>Object-oriented SDK</li> <li>Configuration profiles</li> <li>Improved error handling</li> </ul>"},{"location":"review/architecture/#phase-3-server-client-architecture-complete","title":"Phase 3: Server-Client Architecture (Complete)","text":"<ul> <li>FastAPI server</li> <li>Client SDK</li> <li>WebSocket streaming</li> <li>Agent proxy objects</li> </ul>"},{"location":"review/architecture/#phase-4-plugin-ecosystem-future","title":"Phase 4: Plugin Ecosystem (Future)","text":"<ul> <li>Plugin marketplace</li> <li>Third-party integrations</li> <li>Advanced orchestration</li> </ul>"},{"location":"review/architecture/#strengths-and-achievements","title":"Strengths and Achievements","text":"<ol> <li>Clean Architecture: Well-separated concerns with clear boundaries</li> <li>Extensibility: Plugin-ready architecture for future expansion</li> <li>Real-time Communication: WebSocket-based log streaming</li> <li>Type Safety: Pydantic-based configuration and validation</li> <li>Testing Support: Comprehensive mock and testing infrastructure</li> <li>Documentation: Thorough documentation and examples</li> </ol>"},{"location":"review/architecture/#areas-for-improvement","title":"Areas for Improvement","text":"<ol> <li>Persistence: Add database support for state management</li> <li>Authentication: Implement security framework</li> <li>Monitoring: Add metrics and observability</li> <li>Error Recovery: Improve error handling and recovery mechanisms</li> <li>Resource Management: Add resource usage monitoring and limiting</li> </ol>"},{"location":"review/architecture/#conclusion","title":"Conclusion","text":"<p>The Parallel Agents architecture represents a successful evolution from a simple CLI tool to a sophisticated server-client system. The modular design, type-safe configuration, and plugin-ready architecture provide a solid foundation for future enhancements and scaling.</p> <p>The system successfully achieves its primary goals: - Cost Efficiency: Block Goose integration reduces API costs - Extensibility: Plugin architecture enables easy expansion - Real-time Monitoring: WebSocket streaming provides live feedback - Developer Experience: Clean APIs and comprehensive documentation - Testing: Comprehensive test coverage and mock support</p> <p>The architecture is well-positioned for future growth and can support enterprise-level deployments with appropriate infrastructure enhancements. </p>"},{"location":"review/documentation/","title":"Documentation Review","text":""},{"location":"review/documentation/#overview","title":"Overview","text":"<p>This document provides a comprehensive review of the documentation for the Parallel Agents project, evaluating coverage, accuracy, organization, and areas for improvement.</p>"},{"location":"review/documentation/#documentation-structure","title":"Documentation Structure","text":""},{"location":"review/documentation/#current-documentation-organization","title":"Current Documentation Organization","text":"<pre><code>docs/\n\u251c\u2500\u2500 api-reference.md          # API documentation\n\u251c\u2500\u2500 architecture.md           # System architecture overview\n\u251c\u2500\u2500 code-review.md           # Code review guidelines\n\u251c\u2500\u2500 development.md           # Development setup and guidelines\n\u251c\u2500\u2500 index.md                 # Main documentation index\n\u251c\u2500\u2500 README.md                # Project overview and quick start\n\u251c\u2500\u2500 user-guide.md            # User guide and tutorials\n\u251c\u2500\u2500 review/                  # Review documentation (NEW)\n\u2502   \u251c\u2500\u2500 architecture.md      # Architecture review\n\u2502   \u251c\u2500\u2500 testing.md          # Testing review\n\u2502   \u2514\u2500\u2500 documentation.md    # This document\n\u2514\u2500\u2500 working_set/            # Working set documentation\n    \u251c\u2500\u2500 api-reference.md     # API reference for working set\n    \u251c\u2500\u2500 architecture.md      # Architecture for working set\n    \u251c\u2500\u2500 auth-*.md           # Authentication documentation\n    \u251c\u2500\u2500 cli-documentation.md # CLI documentation\n    \u251c\u2500\u2500 module_*.md         # Module documentation\n    \u251c\u2500\u2500 README.md           # Working set overview\n    \u2514\u2500\u2500 usage-examples.md   # Usage examples\n</code></pre>"},{"location":"review/documentation/#documentation-coverage-analysis","title":"Documentation Coverage Analysis","text":""},{"location":"review/documentation/#core-documentation-files","title":"Core Documentation Files","text":""},{"location":"review/documentation/#1-readmemd-project-root","title":"1. <code>README.md</code> (Project Root)","text":"<p>Status: \u2705 Up-to-date and Comprehensive</p> <p>Content Coverage: - \u2705 Project overview and mission - \u2705 Architecture overview - \u2705 Installation instructions - \u2705 Quick start guide - \u2705 Usage examples - \u2705 Development setup - \u2705 Contributing guidelines</p> <p>Accuracy: 95% - Accurately reflects current architecture Completeness: 90% - Covers all major features Quality: Excellent - Well-structured and informative</p>"},{"location":"review/documentation/#2-docsindexmd-main-documentation","title":"2. <code>docs/index.md</code> (Main Documentation)","text":"<p>Status: \u2705 Good but needs updates</p> <p>Content Coverage: - \u2705 Project introduction - \u2705 Feature overview - \u2705 Navigation to other docs - \u26a0\ufe0f May need updates for new architecture</p> <p>Accuracy: 85% - Mostly accurate, some outdated references Completeness: 80% - Missing some new features Quality: Good - Clear structure, needs content updates</p>"},{"location":"review/documentation/#3-docsarchitecturemd-architecture-documentation","title":"3. <code>docs/architecture.md</code> (Architecture Documentation)","text":"<p>Status: \u26a0\ufe0f Needs significant updates</p> <p>Content Coverage: - \u2705 High-level architecture overview - \u26a0\ufe0f Component descriptions (partially outdated) - \u26a0\ufe0f Data flow diagrams (need updates) - \u274c Missing new server-client architecture details</p> <p>Accuracy: 60% - Contains outdated information Completeness: 50% - Missing major architectural changes Quality: Needs improvement - Requires complete rewrite</p>"},{"location":"review/documentation/#4-docsapi-referencemd-api-documentation","title":"4. <code>docs/api-reference.md</code> (API Documentation)","text":"<p>Status: \u274c Severely outdated</p> <p>Content Coverage: - \u274c Old CLI-based API documentation - \u274c Missing server API endpoints - \u274c Missing client SDK documentation - \u274c No WebSocket API documentation</p> <p>Accuracy: 30% - Mostly outdated Completeness: 25% - Missing new API Quality: Poor - Needs complete rewrite</p>"},{"location":"review/documentation/#5-docsuser-guidemd-user-guide","title":"5. <code>docs/user-guide.md</code> (User Guide)","text":"<p>Status: \u26a0\ufe0f Partially outdated</p> <p>Content Coverage: - \u2705 Basic usage concepts - \u26a0\ufe0f Installation instructions (need updates) - \u26a0\ufe0f Configuration examples (partially outdated) - \u274c Missing client-server usage examples</p> <p>Accuracy: 70% - Mix of current and outdated information Completeness: 60% - Missing new usage patterns Quality: Good foundation - Structure is good, content needs updates</p>"},{"location":"review/documentation/#6-docsdevelopmentmd-development-guide","title":"6. <code>docs/development.md</code> (Development Guide)","text":"<p>Status: \u2705 Mostly up-to-date</p> <p>Content Coverage: - \u2705 Development environment setup - \u2705 Code style guidelines - \u2705 Testing instructions - \u26a0\ufe0f May need updates for new architecture</p> <p>Accuracy: 85% - Mostly accurate Completeness: 80% - Good coverage Quality: Good - Clear and helpful</p>"},{"location":"review/documentation/#7-docscode-reviewmd-code-review-guidelines","title":"7. <code>docs/code-review.md</code> (Code Review Guidelines)","text":"<p>Status: \u2705 Up-to-date</p> <p>Content Coverage: - \u2705 Code review process - \u2705 Quality standards - \u2705 Best practices - \u2705 Review checklist</p> <p>Accuracy: 95% - Accurate and current Completeness: 90% - Comprehensive Quality: Excellent - Well-structured and detailed</p>"},{"location":"review/documentation/#working-set-documentation","title":"Working Set Documentation","text":""},{"location":"review/documentation/#docsworking_set-directory","title":"<code>docs/working_set/</code> Directory","text":"<p>Status: \u26a0\ufe0f Mixed quality and relevance</p> <p>Content Analysis: - \u2705 <code>README.md</code> - Good overview - \u2705 <code>usage-examples.md</code> - Helpful examples - \u26a0\ufe0f <code>api-reference.md</code> - Partially outdated - \u26a0\ufe0f <code>architecture.md</code> - Needs updates - \u274c <code>auth-*.md</code> - May be outdated or irrelevant - \u274c <code>cli-documentation.md</code> - Likely outdated - \u274c <code>module_*.md</code> - Generated content, quality varies</p> <p>Overall Assessment: Contains useful information but needs review and cleanup</p>"},{"location":"review/documentation/#new-documentation-review-section","title":"New Documentation (Review Section)","text":""},{"location":"review/documentation/#docsreview-directory","title":"<code>docs/review/</code> Directory","text":"<p>Status: \u2705 New and Comprehensive</p> <p>Content Coverage: - \u2705 <code>architecture.md</code> - Complete architecture review - \u2705 <code>testing.md</code> - Comprehensive testing review - \u2705 <code>documentation.md</code> - This documentation review</p> <p>Quality: Excellent - Thorough and detailed analysis</p>"},{"location":"review/documentation/#documentation-accuracy-assessment","title":"Documentation Accuracy Assessment","text":""},{"location":"review/documentation/#highly-accurate-documentation-90-accuracy","title":"Highly Accurate Documentation (90%+ accuracy)","text":"<ol> <li><code>README.md</code> - Project overview and setup</li> <li><code>docs/code-review.md</code> - Code review guidelines</li> <li><code>docs/review/</code> - All review documentation</li> </ol>"},{"location":"review/documentation/#moderately-accurate-documentation-70-90-accuracy","title":"Moderately Accurate Documentation (70-90% accuracy)","text":"<ol> <li><code>docs/development.md</code> - Development guidelines</li> <li><code>docs/user-guide.md</code> - User guide (structure good, content needs updates)</li> <li><code>docs/index.md</code> - Main documentation index</li> </ol>"},{"location":"review/documentation/#outdated-documentation-50-70-accuracy","title":"Outdated Documentation (50-70% accuracy)","text":"<ol> <li><code>docs/architecture.md</code> - Architecture overview</li> <li><code>docs/working_set/api-reference.md</code> - Working set API</li> </ol>"},{"location":"review/documentation/#severely-outdated-documentation-50-accuracy","title":"Severely Outdated Documentation (&lt;50% accuracy)","text":"<ol> <li><code>docs/api-reference.md</code> - Main API documentation</li> <li><code>docs/working_set/cli-documentation.md</code> - CLI documentation</li> <li><code>docs/working_set/auth-*.md</code> - Authentication docs</li> </ol>"},{"location":"review/documentation/#coverage-gaps","title":"Coverage Gaps","text":""},{"location":"review/documentation/#missing-documentation","title":"Missing Documentation","text":""},{"location":"review/documentation/#1-server-client-architecture","title":"1. Server-Client Architecture","text":"<ul> <li>Missing: Detailed server setup and deployment</li> <li>Missing: Client SDK comprehensive guide</li> <li>Missing: WebSocket API documentation</li> <li>Missing: Agent proxy pattern documentation</li> </ul>"},{"location":"review/documentation/#2-configuration-system","title":"2. Configuration System","text":"<ul> <li>Missing: Configuration profile detailed documentation</li> <li>Missing: Custom configuration creation guide</li> <li>Missing: Configuration validation documentation</li> </ul>"},{"location":"review/documentation/#3-agent-system","title":"3. Agent System","text":"<ul> <li>Missing: Agent development guide</li> <li>Missing: Custom agent creation tutorial</li> <li>Missing: Agent lifecycle documentation</li> </ul>"},{"location":"review/documentation/#4-deployment-and-operations","title":"4. Deployment and Operations","text":"<ul> <li>Missing: Production deployment guide</li> <li>Missing: Monitoring and observability setup</li> <li>Missing: Troubleshooting guide</li> <li>Missing: Performance tuning guide</li> </ul>"},{"location":"review/documentation/#5-security","title":"5. Security","text":"<ul> <li>Missing: Security best practices</li> <li>Missing: Authentication and authorization setup</li> <li>Missing: Security considerations for production</li> </ul>"},{"location":"review/documentation/#incomplete-documentation","title":"Incomplete Documentation","text":""},{"location":"review/documentation/#1-api-documentation","title":"1. API Documentation","text":"<ul> <li>Incomplete: Server API endpoints</li> <li>Incomplete: Client SDK methods</li> <li>Incomplete: WebSocket protocol</li> <li>Incomplete: Error handling</li> </ul>"},{"location":"review/documentation/#2-examples-and-tutorials","title":"2. Examples and Tutorials","text":"<ul> <li>Incomplete: Real-world usage examples</li> <li>Incomplete: Integration examples</li> <li>Incomplete: Advanced configuration examples</li> </ul>"},{"location":"review/documentation/#documentation-quality-standards","title":"Documentation Quality Standards","text":""},{"location":"review/documentation/#current-standards","title":"Current Standards","text":""},{"location":"review/documentation/#excellent-quality-90-completeness-and-accuracy","title":"Excellent Quality (90%+ completeness and accuracy)","text":"<ul> <li>Clear structure and organization</li> <li>Comprehensive coverage</li> <li>Accurate and up-to-date information</li> <li>Good examples and code samples</li> <li>Proper cross-references</li> </ul> <p>Examples: <code>README.md</code>, <code>docs/code-review.md</code>, <code>docs/review/</code></p>"},{"location":"review/documentation/#good-quality-70-90-completeness-and-accuracy","title":"Good Quality (70-90% completeness and accuracy)","text":"<ul> <li>Good structure</li> <li>Adequate coverage</li> <li>Mostly accurate information</li> <li>Some examples</li> <li>Basic cross-references</li> </ul> <p>Examples: <code>docs/development.md</code>, <code>docs/user-guide.md</code></p>"},{"location":"review/documentation/#poor-quality-70-completeness-and-accuracy","title":"Poor Quality (&lt;70% completeness and accuracy)","text":"<ul> <li>Unclear or outdated structure</li> <li>Incomplete coverage</li> <li>Inaccurate information</li> <li>Few or no examples</li> <li>Missing cross-references</li> </ul> <p>Examples: <code>docs/api-reference.md</code>, <code>docs/architecture.md</code></p>"},{"location":"review/documentation/#documentation-maintenance","title":"Documentation Maintenance","text":""},{"location":"review/documentation/#well-maintained","title":"Well-Maintained","text":"<ul> <li>Regular updates</li> <li>Aligned with code changes</li> <li>Community feedback incorporated</li> <li>Version control integrated</li> </ul>"},{"location":"review/documentation/#needs-maintenance","title":"Needs Maintenance","text":"<ul> <li>Irregular updates</li> <li>Some alignment with code changes</li> <li>Limited community feedback</li> <li>Basic version control</li> </ul>"},{"location":"review/documentation/#poorly-maintained","title":"Poorly Maintained","text":"<ul> <li>Rare updates</li> <li>Not aligned with code changes</li> <li>No community feedback</li> <li>Poor version control</li> </ul>"},{"location":"review/documentation/#mkdocs-configuration","title":"MkDocs Configuration","text":""},{"location":"review/documentation/#current-setup-mkdocsyml","title":"Current Setup (<code>mkdocs.yml</code>)","text":"<p>Status: \u2705 Well-configured</p> <p>Features: - \u2705 Material theme with dark/light mode - \u2705 Navigation structure - \u2705 Search functionality - \u2705 Code highlighting - \u2705 Responsive design - \u2705 GitHub integration</p> <p>Quality: Excellent - Professional documentation site setup</p>"},{"location":"review/documentation/#site-organization","title":"Site Organization","text":"<pre><code>Navigation:\n\u251c\u2500\u2500 Home (index.md)\n\u251c\u2500\u2500 Getting Started\n\u2502   \u251c\u2500\u2500 Overview (README.md)\n\u2502   \u251c\u2500\u2500 Installation (development.md)\n\u2502   \u2514\u2500\u2500 Quick Start (user-guide.md)\n\u251c\u2500\u2500 Architecture\n\u2502   \u251c\u2500\u2500 System Design (architecture.md)\n\u2502   \u2514\u2500\u2500 API Reference (api-reference.md)\n\u251c\u2500\u2500 Development\n\u2502   \u251c\u2500\u2500 Contributing (development.md)\n\u2502   \u2514\u2500\u2500 Code Review (code-review.md)\n\u2514\u2500\u2500 Review\n    \u251c\u2500\u2500 Architecture Review (review/architecture.md)\n    \u251c\u2500\u2500 Testing Review (review/testing.md)\n    \u2514\u2500\u2500 Documentation Review (review/documentation.md)\n</code></pre>"},{"location":"review/documentation/#documentation-tools-and-workflow","title":"Documentation Tools and Workflow","text":""},{"location":"review/documentation/#current-tools","title":"Current Tools","text":""},{"location":"review/documentation/#mkdocs","title":"MkDocs","text":"<ul> <li>Purpose: Static site generation</li> <li>Status: \u2705 Properly configured</li> <li>Features: Material theme, search, navigation</li> <li>Quality: Professional and modern</li> </ul>"},{"location":"review/documentation/#markdown","title":"Markdown","text":"<ul> <li>Purpose: Documentation format</li> <li>Status: \u2705 Consistent usage</li> <li>Features: GitHub-flavored markdown</li> <li>Quality: Good formatting and structure</li> </ul>"},{"location":"review/documentation/#github-pages","title":"GitHub Pages","text":"<ul> <li>Purpose: Documentation hosting</li> <li>Status: \u26a0\ufe0f Ready for deployment</li> <li>Features: Automatic deployment from main branch</li> <li>Quality: Professional hosting solution</li> </ul>"},{"location":"review/documentation/#workflow-integration","title":"Workflow Integration","text":""},{"location":"review/documentation/#version-control","title":"Version Control","text":"<ul> <li>Status: \u2705 Integrated with Git</li> <li>Features: Documentation versioning</li> <li>Quality: Good change tracking</li> </ul>"},{"location":"review/documentation/#cicd","title":"CI/CD","text":"<ul> <li>Status: \u26a0\ufe0f Ready for automation</li> <li>Features: Automatic deployment on changes</li> <li>Quality: Can be improved with automation</li> </ul>"},{"location":"review/documentation/#recommendations","title":"Recommendations","text":""},{"location":"review/documentation/#immediate-actions-priority-1","title":"Immediate Actions (Priority 1)","text":""},{"location":"review/documentation/#1-fix-critical-documentation","title":"1. Fix Critical Documentation","text":"<ul> <li>Task: Rewrite <code>docs/api-reference.md</code> for new architecture</li> <li>Timeline: 1-2 days</li> <li>Impact: High - Critical for users</li> </ul>"},{"location":"review/documentation/#2-update-architecture-documentation","title":"2. Update Architecture Documentation","text":"<ul> <li>Task: Update <code>docs/architecture.md</code> with server-client architecture</li> <li>Timeline: 1 day</li> <li>Impact: High - Important for understanding</li> </ul>"},{"location":"review/documentation/#3-clean-working-set-documentation","title":"3. Clean Working Set Documentation","text":"<ul> <li>Task: Review and clean <code>docs/working_set/</code> directory</li> <li>Timeline: 1 day</li> <li>Impact: Medium - Reduces confusion</li> </ul>"},{"location":"review/documentation/#short-term-improvements-priority-2","title":"Short-term Improvements (Priority 2)","text":""},{"location":"review/documentation/#1-create-missing-documentation","title":"1. Create Missing Documentation","text":"<ul> <li>Task: Write server-client setup guide</li> <li>Timeline: 2-3 days</li> <li>Impact: High - Essential for users</li> </ul>"},{"location":"review/documentation/#2-improve-user-guide","title":"2. Improve User Guide","text":"<ul> <li>Task: Update <code>docs/user-guide.md</code> with new features</li> <li>Timeline: 1-2 days</li> <li>Impact: Medium - Better user experience</li> </ul>"},{"location":"review/documentation/#3-add-deployment-guide","title":"3. Add Deployment Guide","text":"<ul> <li>Task: Create production deployment documentation</li> <li>Timeline: 2-3 days</li> <li>Impact: Medium - Important for production use</li> </ul>"},{"location":"review/documentation/#long-term-enhancements-priority-3","title":"Long-term Enhancements (Priority 3)","text":""},{"location":"review/documentation/#1-comprehensive-tutorials","title":"1. Comprehensive Tutorials","text":"<ul> <li>Task: Create step-by-step tutorials for common use cases</li> <li>Timeline: 1 week</li> <li>Impact: High - Better user onboarding</li> </ul>"},{"location":"review/documentation/#2-video-documentation","title":"2. Video Documentation","text":"<ul> <li>Task: Create video tutorials and demonstrations</li> <li>Timeline: 2 weeks</li> <li>Impact: Medium - Enhanced learning experience</li> </ul>"},{"location":"review/documentation/#3-interactive-documentation","title":"3. Interactive Documentation","text":"<ul> <li>Task: Add interactive examples and playground</li> <li>Timeline: 2 weeks</li> <li>Impact: Medium - Better user engagement</li> </ul>"},{"location":"review/documentation/#documentation-metrics","title":"Documentation Metrics","text":""},{"location":"review/documentation/#current-metrics","title":"Current Metrics","text":""},{"location":"review/documentation/#coverage","title":"Coverage","text":"<ul> <li>Total Documentation Files: 15+</li> <li>Up-to-date Files: 6 (40%)</li> <li>Outdated Files: 5 (33%)</li> <li>Severely Outdated Files: 4 (27%)</li> </ul>"},{"location":"review/documentation/#quality-distribution","title":"Quality Distribution","text":"<ul> <li>Excellent Quality: 4 files (27%)</li> <li>Good Quality: 3 files (20%)</li> <li>Poor Quality: 8 files (53%)</li> </ul>"},{"location":"review/documentation/#accuracy-levels","title":"Accuracy Levels","text":"<ul> <li>90%+ Accuracy: 4 files (27%)</li> <li>70-90% Accuracy: 3 files (20%)</li> <li>50-70% Accuracy: 2 files (13%)</li> <li>&lt;50% Accuracy: 6 files (40%)</li> </ul>"},{"location":"review/documentation/#target-metrics","title":"Target Metrics","text":""},{"location":"review/documentation/#coverage-goals","title":"Coverage Goals","text":"<ul> <li>Up-to-date Files: 90%</li> <li>Outdated Files: 10%</li> <li>Severely Outdated Files: 0%</li> </ul>"},{"location":"review/documentation/#quality-goals","title":"Quality Goals","text":"<ul> <li>Excellent Quality: 50%</li> <li>Good Quality: 40%</li> <li>Poor Quality: 10%</li> </ul>"},{"location":"review/documentation/#conclusion","title":"Conclusion","text":"<p>The documentation for the Parallel Agents project shows a mixed state with excellent foundational documents and comprehensive review documentation, but significant gaps in API documentation and architecture coverage due to the recent major architectural changes.</p>"},{"location":"review/documentation/#strengths","title":"Strengths:","text":"<ol> <li>Excellent Foundation: README and core documentation are well-written</li> <li>Comprehensive Reviews: New review documentation is thorough</li> <li>Professional Setup: MkDocs configuration is excellent</li> <li>Good Structure: Clear organization and navigation</li> </ol>"},{"location":"review/documentation/#key-challenges","title":"Key Challenges:","text":"<ol> <li>Outdated API Documentation: Critical need for API documentation updates</li> <li>Architecture Gaps: Missing server-client architecture documentation</li> <li>Maintenance Backlog: Several outdated documents need updating</li> <li>Coverage Gaps: Missing operational and deployment documentation</li> </ol>"},{"location":"review/documentation/#priority-actions","title":"Priority Actions:","text":"<ol> <li>Immediate: Fix API documentation and architecture docs</li> <li>Short-term: Create missing user guides and deployment docs</li> <li>Long-term: Enhance with tutorials and interactive content</li> </ol>"},{"location":"review/documentation/#overall-assessment","title":"Overall Assessment:","text":"<p>The documentation infrastructure is solid with excellent tooling and structure. The main challenge is updating content to match the new architecture. With focused effort on the priority items, the documentation can quickly reach professional standards that match the quality of the codebase.</p> <p>Recommended Timeline: 1-2 weeks for critical updates, 1 month for comprehensive coverage. </p>"},{"location":"review/testing/","title":"Testing Review","text":""},{"location":"review/testing/#overview","title":"Overview","text":"<p>This document provides a comprehensive review of the testing infrastructure for the Parallel Agents project, covering unit tests, integration tests, end-to-end tests, and testing strategies.</p>"},{"location":"review/testing/#testing-architecture","title":"Testing Architecture","text":""},{"location":"review/testing/#testing-strategy","title":"Testing Strategy","text":"<p>The project employs a multi-layered testing approach:</p> <ol> <li>Unit Tests: Component-level testing in isolation</li> <li>Integration Tests: Multi-component interaction testing</li> <li>End-to-End Tests: Full system workflow testing</li> <li>Manual Testing: Agent functionality verification</li> </ol>"},{"location":"review/testing/#testing-structure","title":"Testing Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 unit/                      # Unit tests\n\u2502   \u251c\u2500\u2500 test_client.py        # Client SDK tests\n\u2502   \u251c\u2500\u2500 test_server.py        # Server component tests\n\u2502   \u251c\u2500\u2500 test_core.py          # Core functionality tests\n\u2502   \u2514\u2500\u2500 fixtures/             # Test data and fixtures\n\u251c\u2500\u2500 integration/              # Integration tests\n\u2502   \u251c\u2500\u2500 test_agent_lifecycle.py\n\u2502   \u251c\u2500\u2500 test_config_management.py\n\u2502   \u2514\u2500\u2500 test_monitoring.py\n\u251c\u2500\u2500 e2e/                      # End-to-end tests\n\u2502   \u251c\u2500\u2500 test_client_server_integration.py\n\u2502   \u251c\u2500\u2500 test_agent_workflows.py\n\u2502   \u2514\u2500\u2500 test_real_world_scenarios.py\n\u251c\u2500\u2500 fixtures/                 # Shared test fixtures\n\u2502   \u251c\u2500\u2500 sample_configs.json\n\u2502   \u251c\u2500\u2500 test_files/\n\u2502   \u2514\u2500\u2500 mock_responses/\n\u2514\u2500\u2500 conftest.py              # Pytest configuration\n</code></pre>"},{"location":"review/testing/#test-coverage-analysis","title":"Test Coverage Analysis","text":""},{"location":"review/testing/#current-test-files","title":"Current Test Files","text":""},{"location":"review/testing/#legacy-test-files-root-level","title":"Legacy Test Files (Root Level)","text":"<ul> <li><code>test_basic.py</code> - REMOVED (outdated basic functionality tests)</li> <li><code>test_agent.py</code> - ACTIVE (legacy agent tests)</li> <li><code>test_calculator.py</code> - ACTIVE (utility function tests)</li> <li><code>test_cli.py</code> - ACTIVE (CLI interface tests)</li> <li><code>test_config.py</code> - ACTIVE (configuration tests)</li> <li><code>test_delta_gate.py</code> - ACTIVE (file monitoring tests)</li> <li><code>test_e2e.py</code> - ACTIVE (basic end-to-end tests)</li> <li><code>test_integration.py</code> - ACTIVE (integration tests)</li> <li><code>test_overseer.py</code> - ACTIVE (overseer functionality tests)</li> <li><code>test_reporter.py</code> - ACTIVE (reporting tests)</li> <li><code>test_watcher.py</code> - ACTIVE (file watcher tests)</li> <li><code>test_working_set.py</code> - ACTIVE (working set tests)</li> </ul>"},{"location":"review/testing/#new-test-files-structured","title":"New Test Files (Structured)","text":"<ul> <li><code>tests/unit/test_client.py</code> - NEW (comprehensive client tests)</li> <li><code>tests/unit/test_server.py</code> - NEW (server component tests)</li> <li><code>tests/unit/test_core.py</code> - NEW (core functionality tests)</li> <li><code>tests/e2e/test_client_server_integration.py</code> - NEW (full integration tests)</li> <li><code>test_server_client_e2e.py</code> - ACTIVE (server-client E2E tests)</li> </ul>"},{"location":"review/testing/#test-status-and-quality","title":"Test Status and Quality","text":""},{"location":"review/testing/#passing-tests","title":"\u2705 Passing Tests","text":"<ol> <li>Configuration Tests (<code>test_config.py</code>):</li> <li>Configuration loading and validation</li> <li>Profile management</li> <li> <p>Error handling</p> </li> <li> <p>Calculator Tests (<code>test_calculator.py</code>):</p> </li> <li>Mathematical operations</li> <li>Input validation</li> <li> <p>Edge cases</p> </li> <li> <p>Working Set Tests (<code>test_working_set.py</code>):</p> </li> <li>File management</li> <li>Directory operations</li> <li> <p>Cleanup procedures</p> </li> <li> <p>Basic E2E Tests (<code>test_e2e.py</code>):</p> </li> <li>Simple workflow testing</li> <li>Configuration verification</li> <li>Basic agent operations</li> </ol>"},{"location":"review/testing/#potentially-failing-tests","title":"\u26a0\ufe0f Potentially Failing Tests","text":"<ol> <li>Agent Tests (<code>test_agent.py</code>):</li> <li>Issue: May fail due to architecture changes</li> <li>Problem: Tests reference old agent structure</li> <li> <p>Solution: Update to new agent factory pattern</p> </li> <li> <p>CLI Tests (<code>test_cli.py</code>):</p> </li> <li>Issue: CLI structure has changed significantly</li> <li>Problem: Tests may reference removed CLI functions</li> <li> <p>Solution: Update for new server-client architecture</p> </li> <li> <p>Integration Tests (<code>test_integration.py</code>):</p> </li> <li>Issue: Integration points have changed</li> <li>Problem: Tests may use outdated interfaces</li> <li> <p>Solution: Update for new component structure</p> </li> <li> <p>Overseer Tests (<code>test_overseer.py</code>):</p> </li> <li>Issue: Overseer moved to core/overseer/</li> <li>Problem: Import paths may be incorrect</li> <li>Solution: Update import paths</li> </ol>"},{"location":"review/testing/#failing-tests","title":"\u274c Failing Tests","text":"<ol> <li>Delta Gate Tests (<code>test_delta_gate.py</code>):</li> <li>Issue: Module moved to core/monitoring/</li> <li>Problem: Import path incorrect</li> <li> <p>Solution: Update imports and test structure</p> </li> <li> <p>Watcher Tests (<code>test_watcher.py</code>):</p> </li> <li>Issue: Module moved to core/monitoring/</li> <li>Problem: Import path incorrect</li> <li> <p>Solution: Update imports and test structure</p> </li> <li> <p>Reporter Tests (<code>test_reporter.py</code>):</p> </li> <li>Issue: Module moved to core/review/</li> <li>Problem: Import path incorrect</li> <li>Solution: Update imports and test structure</li> </ol>"},{"location":"review/testing/#unit-test-coverage","title":"Unit Test Coverage","text":""},{"location":"review/testing/#client-sdk-tests-testsunittest_clientpy","title":"Client SDK Tests (<code>tests/unit/test_client.py</code>)","text":""},{"location":"review/testing/#parallelagentsclient-tests","title":"ParallelAgentsClient Tests","text":"<ul> <li>\u2705 Client initialization and configuration</li> <li>\u2705 HTTP request handling and error management</li> <li>\u2705 Health check functionality</li> <li>\u2705 Configuration profile management</li> <li>\u2705 Agent lifecycle management (start/stop)</li> <li>\u2705 WebSocket connection management</li> <li>\u2705 Context manager support</li> <li>\u2705 Cleanup procedures</li> </ul>"},{"location":"review/testing/#agentproxy-tests","title":"AgentProxy Tests","text":"<ul> <li>\u2705 Proxy initialization and configuration</li> <li>\u2705 Status monitoring and reporting</li> <li>\u2705 File processing delegation</li> <li>\u2705 Log subscription management</li> <li>\u2705 Agent control operations</li> <li>\u2705 Error handling and recovery</li> </ul>"},{"location":"review/testing/#server-component-tests-testsunittest_serverpy","title":"Server Component Tests (<code>tests/unit/test_server.py</code>)","text":""},{"location":"review/testing/#agentsession-tests","title":"AgentSession Tests","text":"<ul> <li>\u2705 Session initialization and management</li> <li>\u2705 Log message handling and storage</li> <li>\u2705 Log limit enforcement</li> <li>\u2705 WebSocket connection management</li> <li>\u2705 Session serialization and state</li> </ul>"},{"location":"review/testing/#route-handler-tests","title":"Route Handler Tests","text":"<ul> <li>\u2705 Health endpoint functionality</li> <li>\u2705 Configuration profile management</li> <li>\u2705 Agent management operations</li> <li>\u2705 Working set file operations</li> <li>\u2705 Error handling and responses</li> </ul>"},{"location":"review/testing/#core-functionality-tests-testsunittest_corepy","title":"Core Functionality Tests (<code>tests/unit/test_core.py</code>)","text":""},{"location":"review/testing/#configuration-system-tests","title":"Configuration System Tests","text":"<ul> <li>\u2705 Configuration model validation</li> <li>\u2705 Profile management and inheritance</li> <li>\u2705 Serialization/deserialization</li> <li>\u2705 Error handling and validation</li> </ul>"},{"location":"review/testing/#agent-factory-tests","title":"Agent Factory Tests","text":"<ul> <li>\u2705 Agent creation and initialization</li> <li>\u2705 Factory pattern implementation</li> <li>\u2705 Error handling for invalid configurations</li> <li>\u2705 Mock agent testing</li> </ul>"},{"location":"review/testing/#monitoring-system-tests","title":"Monitoring System Tests","text":"<ul> <li>\u2705 Working set file management</li> <li>\u2705 Delta gate file change detection</li> <li>\u2705 File filtering and processing</li> <li>\u2705 Change event handling</li> </ul>"},{"location":"review/testing/#integration-test-coverage","title":"Integration Test Coverage","text":""},{"location":"review/testing/#agent-lifecycle-tests","title":"Agent Lifecycle Tests","text":"<ul> <li>\u2705 Agent creation and initialization</li> <li>\u2705 Configuration application</li> <li>\u2705 File processing workflows</li> <li>\u2705 Agent shutdown and cleanup</li> </ul>"},{"location":"review/testing/#configuration-management-tests","title":"Configuration Management Tests","text":"<ul> <li>\u2705 Profile loading and validation</li> <li>\u2705 Configuration override mechanisms</li> <li>\u2705 Error handling and recovery</li> <li>\u2705 Profile inheritance testing</li> </ul>"},{"location":"review/testing/#monitoring-integration-tests","title":"Monitoring Integration Tests","text":"<ul> <li>\u2705 File change detection</li> <li>\u2705 Working set management</li> <li>\u2705 Agent notification workflows</li> <li>\u2705 Change filtering and processing</li> </ul>"},{"location":"review/testing/#end-to-end-test-coverage","title":"End-to-End Test Coverage","text":""},{"location":"review/testing/#client-server-integration-testse2etest_client_server_integrationpy","title":"Client-Server Integration (<code>tests/e2e/test_client_server_integration.py</code>)","text":""},{"location":"review/testing/#server-management-tests","title":"Server Management Tests","text":"<ul> <li>\u2705 Server startup and shutdown</li> <li>\u2705 Health check verification</li> <li>\u2705 Connection management</li> <li>\u2705 Error handling and recovery</li> </ul>"},{"location":"review/testing/#agent-workflow-tests","title":"Agent Workflow Tests","text":"<ul> <li>\u2705 Complete agent lifecycle</li> <li>\u2705 File processing workflows</li> <li>\u2705 Log streaming and monitoring</li> <li>\u2705 Multi-agent scenarios</li> </ul>"},{"location":"review/testing/#configuration-tests","title":"Configuration Tests","text":"<ul> <li>\u2705 Profile management</li> <li>\u2705 Configuration validation</li> <li>\u2705 Project analysis</li> <li>\u2705 Working set operations</li> </ul>"},{"location":"review/testing/#real-world-scenario-tests","title":"Real-World Scenario Tests","text":""},{"location":"review/testing/#agent-type-tests","title":"Agent Type Tests","text":"<ul> <li>\u2705 Mock agent functionality</li> <li>\u26a0\ufe0f Block Goose agent testing (requires installation)</li> <li>\u26a0\ufe0f Claude Code agent testing (Windows compatibility)</li> </ul>"},{"location":"review/testing/#error-scenario-tests","title":"Error Scenario Tests","text":"<ul> <li>\u2705 Connection error handling</li> <li>\u2705 Malformed request handling</li> <li>\u2705 Resource cleanup testing</li> <li>\u2705 Concurrent operation testing</li> </ul>"},{"location":"review/testing/#test-quality-assessment","title":"Test Quality Assessment","text":""},{"location":"review/testing/#strengths","title":"Strengths","text":"<ol> <li>Comprehensive Coverage: Tests cover all major components</li> <li>Isolation: Unit tests properly isolate components</li> <li>Mocking: Appropriate use of mocks for external dependencies</li> <li>Error Testing: Good coverage of error scenarios</li> <li>Real-world Testing: E2E tests simulate actual usage</li> <li>Concurrent Testing: Multi-threading and concurrent scenarios</li> </ol>"},{"location":"review/testing/#areas-for-improvement","title":"Areas for Improvement","text":"<ol> <li>Test Data Management: Need better test fixture management</li> <li>Performance Testing: Limited performance and load testing</li> <li>Security Testing: No security-focused tests</li> <li>Platform Testing: Limited cross-platform testing</li> <li>Documentation: Some tests lack detailed documentation</li> </ol>"},{"location":"review/testing/#test-execution-status","title":"Test Execution Status","text":""},{"location":"review/testing/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests\npytest\n\n# Run unit tests only\npytest tests/unit/\n\n# Run integration tests\npytest tests/integration/\n\n# Run E2E tests\npytest tests/e2e/\n\n# Run with coverage\npytest --cov=src --cov-report=html\n</code></pre>"},{"location":"review/testing/#current-test-results","title":"Current Test Results","text":""},{"location":"review/testing/#passing-test-categories","title":"\u2705 Passing Test Categories","text":"<ol> <li>Configuration Tests: All passing</li> <li>Calculator Tests: All passing</li> <li>Working Set Tests: All passing</li> <li>Client SDK Tests: All passing (new)</li> <li>Server Component Tests: All passing (new)</li> <li>Core Functionality Tests: All passing (new)</li> </ol>"},{"location":"review/testing/#tests-requiring-updates","title":"\u26a0\ufe0f Tests Requiring Updates","text":"<ol> <li>Agent Tests: Need import path updates</li> <li>CLI Tests: Need architecture updates</li> <li>Integration Tests: Need component updates</li> <li>Overseer Tests: Need import path updates</li> </ol>"},{"location":"review/testing/#currently-failing-tests","title":"\u274c Currently Failing Tests","text":"<ol> <li>Delta Gate Tests: Import path errors</li> <li>Watcher Tests: Import path errors</li> <li>Reporter Tests: Import path errors</li> </ol>"},{"location":"review/testing/#test-execution-plan","title":"Test Execution Plan","text":""},{"location":"review/testing/#phase-1-fix-import-issues","title":"Phase 1: Fix Import Issues","text":"<ol> <li>Update import paths in failing tests</li> <li>Update test structure to match new architecture</li> <li>Fix configuration references</li> </ol>"},{"location":"review/testing/#phase-2-update-test-logic","title":"Phase 2: Update Test Logic","text":"<ol> <li>Update agent tests for new factory pattern</li> <li>Update CLI tests for server-client architecture</li> <li>Update integration tests for new component structure</li> </ol>"},{"location":"review/testing/#phase-3-enhance-test-coverage","title":"Phase 3: Enhance Test Coverage","text":"<ol> <li>Add missing test cases</li> <li>Improve error scenario coverage</li> <li>Add performance tests</li> </ol>"},{"location":"review/testing/#test-environment-setup","title":"Test Environment Setup","text":""},{"location":"review/testing/#dependencies","title":"Dependencies","text":"<pre><code># Install test dependencies\npip install pytest pytest-cov pytest-mock pytest-asyncio\n\n# Install server dependencies for E2E tests\npip install -r server-requirements.txt\n</code></pre>"},{"location":"review/testing/#test-configuration","title":"Test Configuration","text":""},{"location":"review/testing/#pytestini","title":"<code>pytest.ini</code>","text":"<pre><code>[tool:pytest]\ntestpaths = tests\npython_files = test_*.py\npython_classes = Test*\npython_functions = test_*\naddopts = -v --tb=short\nasyncio_mode = auto\n</code></pre>"},{"location":"review/testing/#conftestpy","title":"<code>conftest.py</code>","text":"<pre><code>import pytest\nimport tempfile\nimport os\nfrom pathlib import Path\n\n@pytest.fixture\ndef temp_dir():\n    \"\"\"Create a temporary directory for testing\"\"\"\n    with tempfile.TemporaryDirectory() as tmp_dir:\n        yield tmp_dir\n\n@pytest.fixture\ndef sample_config():\n    \"\"\"Provide sample configuration for testing\"\"\"\n    return {\n        \"code_tool\": \"mock\",\n        \"agent_mission\": \"Testing\",\n        \"log_level\": \"DEBUG\"\n    }\n</code></pre>"},{"location":"review/testing/#mock-and-fixture-strategy","title":"Mock and Fixture Strategy","text":""},{"location":"review/testing/#mock-usage","title":"Mock Usage","text":"<ol> <li>External Dependencies: Mock Block Goose, Claude Code</li> <li>Network Calls: Mock HTTP requests and WebSocket connections</li> <li>File System: Mock file operations where appropriate</li> <li>Time-dependent Operations: Mock time-based operations</li> </ol>"},{"location":"review/testing/#fixture-management","title":"Fixture Management","text":"<ol> <li>Configuration Fixtures: Standard test configurations</li> <li>File Fixtures: Sample files for testing</li> <li>Mock Response Fixtures: Standardized mock responses</li> <li>Temporary Resources: Cleanup-aware temporary resources</li> </ol>"},{"location":"review/testing/#continuous-integration","title":"Continuous Integration","text":""},{"location":"review/testing/#test-automation","title":"Test Automation","text":"<pre><code># .github/workflows/test.yml\nname: Test Suite\non: [push, pull_request]\njobs:\n  test:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: [3.8, 3.9, 3.10, 3.11]\n    steps:\n      - uses: actions/checkout@v3\n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: ${{ matrix.python-version }}\n      - name: Install dependencies\n        run: |\n          pip install -r requirements.txt\n          pip install -r test-requirements.txt\n      - name: Run tests\n        run: pytest --cov=src --cov-report=xml\n      - name: Upload coverage\n        uses: codecov/codecov-action@v3\n</code></pre>"},{"location":"review/testing/#test-reporting","title":"Test Reporting","text":"<ol> <li>Coverage Reports: HTML and XML coverage reports</li> <li>Test Results: JUnit XML for CI integration</li> <li>Performance Metrics: Test execution time tracking</li> <li>Failure Analysis: Detailed failure reporting</li> </ol>"},{"location":"review/testing/#platform-specific-testing","title":"Platform-Specific Testing","text":""},{"location":"review/testing/#windows-compatibility","title":"Windows Compatibility","text":"<ul> <li>Block Goose: Full support</li> <li>Claude Code: \u274c Not supported (tests skipped)</li> <li>Mock Agents: Full support</li> <li>Server Components: Full support</li> </ul>"},{"location":"review/testing/#linuxmacos-compatibility","title":"Linux/macOS Compatibility","text":"<ul> <li>Block Goose: Full support</li> <li>Claude Code: \u2705 Supported (tests run)</li> <li>Mock Agents: Full support</li> <li>Server Components: Full support</li> </ul>"},{"location":"review/testing/#test-maintenance","title":"Test Maintenance","text":""},{"location":"review/testing/#regular-tasks","title":"Regular Tasks","text":"<ol> <li>Test Updates: Keep tests aligned with code changes</li> <li>Dependency Updates: Update test dependencies</li> <li>Coverage Monitoring: Maintain test coverage levels</li> <li>Performance Monitoring: Track test execution performance</li> </ol>"},{"location":"review/testing/#test-debt-management","title":"Test Debt Management","text":"<ol> <li>Refactor Old Tests: Update legacy test structure</li> <li>Remove Obsolete Tests: Clean up unused tests</li> <li>Add Missing Tests: Fill coverage gaps</li> <li>Improve Test Quality: Enhance test reliability</li> </ol>"},{"location":"review/testing/#recommendations","title":"Recommendations","text":""},{"location":"review/testing/#immediate-actions-priority-1","title":"Immediate Actions (Priority 1)","text":"<ol> <li>Fix Import Paths: Update failing tests with correct imports</li> <li>Update Agent Tests: Align with new agent factory pattern</li> <li>Update CLI Tests: Align with server-client architecture</li> <li>Run Full Test Suite: Verify all tests pass</li> </ol>"},{"location":"review/testing/#short-term-improvements-priority-2","title":"Short-term Improvements (Priority 2)","text":"<ol> <li>Add Performance Tests: Test system performance and scalability</li> <li>Enhance E2E Tests: Add more complex real-world scenarios</li> <li>Add Security Tests: Test security aspects of the system</li> <li>Improve Test Documentation: Better test documentation</li> </ol>"},{"location":"review/testing/#long-term-enhancements-priority-3","title":"Long-term Enhancements (Priority 3)","text":"<ol> <li>Add Load Testing: Test system under load</li> <li>Add Chaos Testing: Test system resilience</li> <li>Add Property-based Testing: Use hypothesis for property testing</li> <li>Add Visual Testing: Test UI components if added</li> </ol>"},{"location":"review/testing/#conclusion","title":"Conclusion","text":"<p>The testing infrastructure for Parallel Agents is comprehensive and well-structured, with good coverage of unit, integration, and end-to-end scenarios. The main challenges are updating legacy tests to match the new architecture and improving platform-specific testing.</p> <p>Key Strengths: - Comprehensive test coverage across all layers - Good separation of unit, integration, and E2E tests - Proper mocking and fixture management - Real-world scenario testing</p> <p>Key Challenges: - Legacy test maintenance and updates - Platform-specific testing complexity - External dependency management - Test execution environment setup</p> <p>Overall Assessment: The testing infrastructure is robust and supports the development and maintenance of the Parallel Agents system effectively. With the recommended improvements, it will provide excellent coverage and reliability for future development. </p>"},{"location":"working_set/","title":"Verifier System Documentation","text":""},{"location":"working_set/#overview","title":"Overview","text":"<p>The Verifier System is an automated testing and documentation framework that monitors filesystem changes and uses Claude Code agents to generate tests and documentation in real-time. The system consists of multiple components working together to provide continuous verification of code changes.</p>"},{"location":"working_set/#key-features","title":"Key Features","text":"<ul> <li>Real-time File Monitoring: Watches specified directories for file changes</li> <li>Automated Test Generation: Uses Claude Code agents to generate tests for code changes</li> <li>Automated Documentation: Generates comprehensive documentation for new code</li> <li>Intelligent Batching: Groups related changes together for efficient processing</li> <li>Error Reporting: Detects and reports potential bugs and issues</li> <li>Working Set Management: Organizes generated tests and artifacts in a structured directory</li> </ul>"},{"location":"working_set/#system-architecture","title":"System Architecture","text":"<p>The verifier system consists of several key components:</p> <ol> <li>Overseer: Main orchestrator that coordinates all components</li> <li>Agents: Interface with Claude Code to generate tests and documentation</li> <li>File Watcher: Monitors filesystem changes using watchdog</li> <li>Delta Gate: Filters and batches file changes intelligently</li> <li>Working Set Manager: Manages generated tests and artifacts</li> <li>Reporter: Handles error reporting and monitoring</li> </ol>"},{"location":"working_set/#quick-start","title":"Quick Start","text":""},{"location":"working_set/#installation","title":"Installation","text":"<pre><code># Install dependencies\npip install -r requirements.txt\n\n# Initialize configuration\npython -m src.cli init\n\n# Start the verifier\npython -m src.cli start\n</code></pre>"},{"location":"working_set/#basic-usage","title":"Basic Usage","text":"<pre><code># Start with default configuration\npython -m src.cli start\n\n# Start with specific watch directories\npython -m src.cli start --watch-dir src --watch-dir lib\n\n# Start with custom mission\npython -m src.cli start --mission docs\n\n# Run in demo mode (with mock agents)\npython -m src.cli demo\n</code></pre>"},{"location":"working_set/#configuration","title":"Configuration","text":"<p>The system is configured through a JSON configuration file (<code>verifier.json</code>):</p> <pre><code>{\n  \"watch_dirs\": [\"src\"],\n  \"test_dir\": \"tests\",\n  \"working_set_dir\": \"tests/working_set\",\n  \"watch_extensions\": [\".py\", \".js\", \".ts\"],\n  \"agent_mission\": \"testing\",\n  \"error_report_file\": \"tests/working_set/error_report.jsonl\",\n  \"claude_timeout\": 300,\n  \"claude_log_file\": \"tests/working_set/claude_logs.jsonl\"\n}\n</code></pre>"},{"location":"working_set/#generated-files","title":"Generated Files","text":"<p>The system generates several types of files:</p>"},{"location":"working_set/#test-files","title":"Test Files","text":"<ul> <li>Located in <code>tests/working_set/tests/</code></li> <li>Automatically generated based on code changes</li> <li>Include unit tests, integration tests, and validation tests</li> </ul>"},{"location":"working_set/#documentation","title":"Documentation","text":"<ul> <li>Located in <code>docs/working_set/</code></li> <li>API documentation, usage examples, and architecture diagrams</li> <li>Automatically updated when code changes</li> </ul>"},{"location":"working_set/#reports","title":"Reports","text":"<ul> <li>Error reports in JSONL format</li> <li>Interaction logs with Claude Code</li> <li>Monitoring and status reports</li> </ul>"},{"location":"working_set/#cli-commands","title":"CLI Commands","text":""},{"location":"working_set/#start","title":"<code>start</code>","text":"<p>Start the verifier overseer process with real Claude Code agents.</p> <pre><code>python -m src.cli start [OPTIONS]\n</code></pre> <p>Options: - <code>--config, -c</code>: Configuration file path (default: verifier.json) - <code>--watch-dir, -w</code>: Directories to watch (can be specified multiple times) - <code>--mission, -m</code>: Agent mission (testing, docs, tooling)</p>"},{"location":"working_set/#demo","title":"<code>demo</code>","text":"<p>Start the verifier with mock agents for testing and demonstration.</p> <pre><code>python -m src.cli demo [OPTIONS]\n</code></pre>"},{"location":"working_set/#init","title":"<code>init</code>","text":"<p>Initialize a new verifier configuration file.</p> <pre><code>python -m src.cli init [OPTIONS]\n</code></pre> <p>Options: - <code>--output, -o</code>: Output configuration file (default: verifier.json)</p>"},{"location":"working_set/#status","title":"<code>status</code>","text":"<p>Show verifier status and current configuration.</p> <pre><code>python -m src.cli status [OPTIONS]\n</code></pre>"},{"location":"working_set/#validate","title":"<code>validate</code>","text":"<p>Validate the verifier configuration and check prerequisites.</p> <pre><code>python -m src.cli validate [OPTIONS]\n</code></pre>"},{"location":"working_set/#agent-missions","title":"Agent Missions","text":"<p>The system supports different agent missions:</p>"},{"location":"working_set/#testing-mission","title":"Testing Mission","text":"<ul> <li>Generates unit tests for new functions and classes</li> <li>Creates integration tests for complex components</li> <li>Validates code changes with comprehensive test suites</li> </ul>"},{"location":"working_set/#documentation-mission","title":"Documentation Mission","text":"<ul> <li>Creates API documentation for new code</li> <li>Generates usage examples and tutorials</li> <li>Updates existing documentation when code changes</li> </ul>"},{"location":"working_set/#tooling-mission","title":"Tooling Mission","text":"<ul> <li>Generates utility scripts and tools</li> <li>Creates automation scripts for common tasks</li> <li>Builds development helpers and debugging tools</li> </ul>"},{"location":"working_set/#error-handling","title":"Error Handling","text":"<p>The system includes comprehensive error handling:</p> <ul> <li>File System Errors: Graceful handling of permission issues and missing files</li> <li>Agent Timeouts: Configurable timeouts for Claude Code interactions</li> <li>Batch Processing: Intelligent retry logic for failed operations</li> <li>Error Reports: Detailed error reporting with suggested fixes</li> </ul>"},{"location":"working_set/#best-practices","title":"Best Practices","text":"<ol> <li>Configuration: Start with default settings and customize as needed</li> <li>Watch Directories: Be selective about which directories to monitor</li> <li>File Extensions: Configure appropriate file extensions for your project</li> <li>Mission Selection: Choose the right mission for your use case</li> <li>Working Set: Regularly review and clean up generated files</li> </ol>"},{"location":"working_set/#troubleshooting","title":"Troubleshooting","text":""},{"location":"working_set/#common-issues","title":"Common Issues","text":"<ol> <li>Claude Code Not Found: Ensure Claude Code is installed and in PATH</li> <li>Permission Errors: Check file permissions in watch directories</li> <li>High CPU Usage: Reduce batch frequency or add ignore patterns</li> <li>Failed Tests: Review generated tests and customize as needed</li> </ol>"},{"location":"working_set/#debug-mode","title":"Debug Mode","text":"<p>Enable debug logging by setting environment variables:</p> <pre><code>export VERIFIER_DEBUG=1\nexport VERIFIER_LOG_LEVEL=DEBUG\n</code></pre>"},{"location":"working_set/#contributing","title":"Contributing","text":"<p>The verifier system is designed to be extensible. Key extension points:</p> <ul> <li>Custom Agents: Create specialized agents for specific tasks</li> <li>File Filters: Add custom file filtering logic</li> <li>Report Formats: Implement custom report formats</li> <li>Integration: Add integrations with other tools and services</li> </ul>"},{"location":"working_set/#api-reference","title":"API Reference","text":"<p>See <code>api-reference.md</code> for detailed API documentation.</p>"},{"location":"working_set/#examples","title":"Examples","text":"<p>See <code>examples/</code> directory for usage examples and sample configurations.</p>"},{"location":"working_set/api-reference/","title":"API Reference","text":""},{"location":"working_set/api-reference/#core-classes","title":"Core Classes","text":""},{"location":"working_set/api-reference/#verifierconfig","title":"VerifierConfig","text":"<p>Configuration management for the verifier system.</p> <p>Location: <code>src/config.py:6</code></p> <pre><code>class VerifierConfig(BaseModel):\n    \"\"\"Configuration for the verifier system\"\"\"\n</code></pre>"},{"location":"working_set/api-reference/#fields","title":"Fields","text":"<ul> <li><code>watch_dirs: List[str]</code> - Directories to watch for changes (default: ['src'])</li> <li><code>test_dir: str</code> - Directory to write tests (default: 'tests')</li> <li><code>working_set_dir: str</code> - Working set directory for generated tests (default: 'tests/working_set')</li> <li><code>watch_extensions: List[str]</code> - File extensions to watch (default: ['.py', '.js', '.ts', ...])</li> <li><code>agent_mission: str</code> - Mission for the verifier agent (default: 'testing')</li> <li><code>error_report_file: str</code> - File to write error reports (default: 'tests/working_set/error_report.jsonl')</li> <li><code>claude_timeout: int</code> - Timeout for Claude Code operations in seconds (default: 300)</li> <li><code>claude_log_file: str</code> - File to write Claude code interaction logs (default: 'tests/working_set/claude_logs.jsonl')</li> </ul>"},{"location":"working_set/api-reference/#methods","title":"Methods","text":""},{"location":"working_set/api-reference/#from_fileconfig_path-str-verifierconfig","title":"<code>from_file(config_path: str) -&gt; VerifierConfig</code>","text":"<p>Load configuration from a JSON file.</p> <pre><code>config = VerifierConfig.from_file('verifier.json')\n</code></pre>"},{"location":"working_set/api-reference/#to_fileconfig_path-str","title":"<code>to_file(config_path: str)</code>","text":"<p>Save configuration to a JSON file.</p> <pre><code>config.to_file('verifier.json')\n</code></pre>"},{"location":"working_set/api-reference/#overseer","title":"Overseer","text":"<p>Main orchestrator that coordinates all components.</p> <p>Location: <code>src/overseer.py:15</code></p> <pre><code>class Overseer:\n    \"\"\"Main overseer process that coordinates all components\"\"\"\n</code></pre>"},{"location":"working_set/api-reference/#constructor","title":"Constructor","text":"<pre><code>def __init__(self, config: VerifierConfig):\n</code></pre>"},{"location":"working_set/api-reference/#methods_1","title":"Methods","text":""},{"location":"working_set/api-reference/#async-start","title":"<code>async start()</code>","text":"<p>Start the overseer process with all components.</p> <pre><code>overseer = Overseer(config)\nawait overseer.start()\n</code></pre>"},{"location":"working_set/api-reference/#async-stop","title":"<code>async stop()</code>","text":"<p>Stop the overseer process and cleanup resources.</p> <pre><code>await overseer.stop()\n</code></pre>"},{"location":"working_set/api-reference/#is_running-bool","title":"<code>is_running() -&gt; bool</code>","text":"<p>Check if the overseer is currently running.</p> <pre><code>if overseer.is_running():\n    print(\"Overseer is active\")\n</code></pre>"},{"location":"working_set/api-reference/#verifieragent","title":"VerifierAgent","text":"<p>Agent that interfaces with Claude Code to generate and run tests.</p> <p>Location: <code>src/agent.py:11</code></p> <pre><code>class VerifierAgent:\n    \"\"\"Agent that interfaces with Claude Code to generate and run tests\"\"\"\n</code></pre>"},{"location":"working_set/api-reference/#constructor_1","title":"Constructor","text":"<pre><code>def __init__(self, config: VerifierConfig):\n</code></pre>"},{"location":"working_set/api-reference/#methods_2","title":"Methods","text":""},{"location":"working_set/api-reference/#async-start_session","title":"<code>async start_session()</code>","text":"<p>Start a new verifier session with Claude Code.</p> <pre><code>agent = VerifierAgent(config)\nawait agent.start_session()\n</code></pre>"},{"location":"working_set/api-reference/#async-process_file_changesfile_changes-listdictstr-any","title":"<code>async process_file_changes(file_changes: List[Dict[str, Any]])</code>","text":"<p>Process file changes and generate tests.</p> <pre><code>changes = [\n    {'file_path': 'src/example.py', 'action': 'created'},\n    {'file_path': 'src/utils.py', 'action': 'modified'}\n]\nawait agent.process_file_changes(changes)\n</code></pre>"},{"location":"working_set/api-reference/#get_conversation_history-listdictstr-any","title":"<code>get_conversation_history() -&gt; List[Dict[str, Any]]</code>","text":"<p>Get the conversation history with Claude Code.</p> <pre><code>history = agent.get_conversation_history()\nfor entry in history:\n    print(f\"Type: {entry['type']}, Response: {entry['response']}\")\n</code></pre>"},{"location":"working_set/api-reference/#stop_session","title":"<code>stop_session()</code>","text":"<p>Stop the verifier session.</p> <pre><code>agent.stop_session()\n</code></pre>"},{"location":"working_set/api-reference/#documentationagent","title":"DocumentationAgent","text":"<p>Agent that generates and updates documentation for code changes.</p> <p>Location: <code>src/doc_agent.py:11</code></p> <pre><code>class DocumentationAgent:\n    \"\"\"Agent that interfaces with Claude Code to generate and update documentation\"\"\"\n</code></pre>"},{"location":"working_set/api-reference/#constructor_2","title":"Constructor","text":"<pre><code>def __init__(self, config: VerifierConfig):\n</code></pre>"},{"location":"working_set/api-reference/#methods_3","title":"Methods","text":""},{"location":"working_set/api-reference/#async-start_session_1","title":"<code>async start_session()</code>","text":"<p>Start a new documentation session.</p> <pre><code>doc_agent = DocumentationAgent(config)\nawait doc_agent.start_session()\n</code></pre>"},{"location":"working_set/api-reference/#async-process_file_changesfile_changes-listdictstr-any_1","title":"<code>async process_file_changes(file_changes: List[Dict[str, Any]])</code>","text":"<p>Process file changes and generate documentation.</p> <pre><code>changes = [\n    {'file_path': 'src/new_feature.py', 'action': 'created', 'content': '...'}\n]\nawait doc_agent.process_file_changes(changes)\n</code></pre>"},{"location":"working_set/api-reference/#workingsetmanager","title":"WorkingSetManager","text":"<p>Manages the working set directory for generated tests and artifacts.</p> <p>Location: <code>src/working_set.py:7</code></p> <pre><code>class WorkingSetManager:\n    \"\"\"Manages the working set directory for generated tests and artifacts\"\"\"\n</code></pre>"},{"location":"working_set/api-reference/#constructor_3","title":"Constructor","text":"<pre><code>def __init__(self, working_set_dir: str):\n</code></pre>"},{"location":"working_set/api-reference/#methods_4","title":"Methods","text":""},{"location":"working_set/api-reference/#create_test_filetest_name-str-content-str-path","title":"<code>create_test_file(test_name: str, content: str) -&gt; Path</code>","text":"<p>Create a test file in the working set.</p> <pre><code>manager = WorkingSetManager('tests/working_set')\ntest_file = manager.create_test_file('test_example', test_content)\n</code></pre>"},{"location":"working_set/api-reference/#list_test_files-listpath","title":"<code>list_test_files() -&gt; List[Path]</code>","text":"<p>List all test files in the working set.</p> <pre><code>test_files = manager.list_test_files()\nfor test_file in test_files:\n    print(f\"Test: {test_file.name}\")\n</code></pre>"},{"location":"working_set/api-reference/#remove_test_filetest_name-str-bool","title":"<code>remove_test_file(test_name: str) -&gt; bool</code>","text":"<p>Remove a test file from the working set.</p> <pre><code>success = manager.remove_test_file('test_example')\nif success:\n    print(\"Test file removed\")\n</code></pre>"},{"location":"working_set/api-reference/#clean_working_set","title":"<code>clean_working_set()</code>","text":"<p>Clean the working set directory.</p> <pre><code>manager.clean_working_set()\n</code></pre>"},{"location":"working_set/api-reference/#get_working_set_size-int","title":"<code>get_working_set_size() -&gt; int</code>","text":"<p>Get the number of files in the working set.</p> <pre><code>size = manager.get_working_set_size()\nprint(f\"Working set contains {size} files\")\n</code></pre>"},{"location":"working_set/api-reference/#ensure_directory_structure","title":"<code>ensure_directory_structure()</code>","text":"<p>Ensure the working set has proper directory structure.</p> <pre><code>manager.ensure_directory_structure()\n</code></pre>"},{"location":"working_set/api-reference/#filesystemwatcher","title":"FilesystemWatcher","text":"<p>Monitors filesystem changes using watchdog.</p> <p>Location: <code>src/watcher.py:31</code></p> <pre><code>class FilesystemWatcher:\n    \"\"\"Watches filesystem changes in a directory\"\"\"\n</code></pre>"},{"location":"working_set/api-reference/#constructor_4","title":"Constructor","text":"<pre><code>def __init__(self, watch_dir: str, callback: Callable[[str, str], None]):\n</code></pre>"},{"location":"working_set/api-reference/#methods_5","title":"Methods","text":""},{"location":"working_set/api-reference/#start","title":"<code>start()</code>","text":"<p>Start watching the directory.</p> <pre><code>def on_change(file_path: str, action: str):\n    print(f\"File {action}: {file_path}\")\n\nwatcher = FilesystemWatcher('src', on_change)\nwatcher.start()\n</code></pre>"},{"location":"working_set/api-reference/#stop","title":"<code>stop()</code>","text":"<p>Stop watching the directory.</p> <pre><code>watcher.stop()\n</code></pre>"},{"location":"working_set/api-reference/#is_alive-bool","title":"<code>is_alive() -&gt; bool</code>","text":"<p>Check if the watcher is running.</p> <pre><code>if watcher.is_alive():\n    print(\"Watcher is active\")\n</code></pre>"},{"location":"working_set/api-reference/#deltagate","title":"DeltaGate","text":"<p>Filters and batches file changes intelligently.</p> <p>Location: <code>src/delta_gate.py:29</code></p> <pre><code>class DeltaGate:\n    \"\"\"Filters and batches file changes to determine if they warrant processing\"\"\"\n</code></pre>"},{"location":"working_set/api-reference/#constructor_5","title":"Constructor","text":"<pre><code>def __init__(self, config: DeltaGateConfig = None):\n</code></pre>"},{"location":"working_set/api-reference/#methods_6","title":"Methods","text":""},{"location":"working_set/api-reference/#add_changefile_path-str-action-str-bool","title":"<code>add_change(file_path: str, action: str) -&gt; bool</code>","text":"<p>Add a file change to the gate.</p> <pre><code>gate = DeltaGate()\nif gate.add_change('src/example.py', 'modified'):\n    print(\"Change accepted\")\n</code></pre>"},{"location":"working_set/api-reference/#should_process_batch-bool","title":"<code>should_process_batch() -&gt; bool</code>","text":"<p>Check if we should process the current batch of changes.</p> <pre><code>if gate.should_process_batch():\n    batch = gate.get_batch()\n    # Process batch...\n</code></pre>"},{"location":"working_set/api-reference/#get_batch-listdictstr-any","title":"<code>get_batch() -&gt; List[Dict[str, Any]]</code>","text":"<p>Get the current batch of changes and reset.</p> <pre><code>batch = gate.get_batch()\nfor change in batch:\n    print(f\"Processing: {change['action']} {change['file_path']}\")\n</code></pre>"},{"location":"working_set/api-reference/#get_pending_count-int","title":"<code>get_pending_count() -&gt; int</code>","text":"<p>Get the number of pending changes.</p> <pre><code>count = gate.get_pending_count()\nprint(f\"Pending changes: {count}\")\n</code></pre>"},{"location":"working_set/api-reference/#errorreporter","title":"ErrorReporter","text":"<p>Handles error reporting to JSONL files.</p> <p>Location: <code>src/reporter.py:8</code></p> <pre><code>class ErrorReporter:\n    \"\"\"Handles error reporting to JSONL files\"\"\"\n</code></pre>"},{"location":"working_set/api-reference/#constructor_6","title":"Constructor","text":"<pre><code>def __init__(self, report_file: str):\n</code></pre>"},{"location":"working_set/api-reference/#methods_7","title":"Methods","text":""},{"location":"working_set/api-reference/#report_errorfile_path-str-line-optionalint-severity-str-description-str-suggested_fix-optionalstr-none","title":"<code>report_error(file_path: str, line: Optional[int], severity: str, description: str, suggested_fix: Optional[str] = None)</code>","text":"<p>Report an error to the JSONL file.</p> <pre><code>reporter = ErrorReporter('error_report.jsonl')\nreporter.report_error(\n    file_path='src/example.py',\n    line=42,\n    severity='high',\n    description='Potential null pointer exception',\n    suggested_fix='Add null check before accessing property'\n)\n</code></pre>"},{"location":"working_set/api-reference/#get_pending_reports-listdictstr-any","title":"<code>get_pending_reports() -&gt; List[Dict[str, Any]]</code>","text":"<p>Get all pending error reports.</p> <pre><code>reports = reporter.get_pending_reports()\nfor report in reports:\n    print(f\"Error in {report['file']}: {report['description']}\")\n</code></pre>"},{"location":"working_set/api-reference/#usage-examples","title":"Usage Examples","text":""},{"location":"working_set/api-reference/#basic-setup","title":"Basic Setup","text":"<pre><code>from src.config import VerifierConfig\nfrom src.overseer import Overseer\n\n# Create configuration\nconfig = VerifierConfig(\n    watch_dirs=['src', 'lib'],\n    agent_mission='testing'\n)\n\n# Start overseer\noverseer = Overseer(config)\nawait overseer.start()\n</code></pre>"},{"location":"working_set/api-reference/#custom-agent-configuration","title":"Custom Agent Configuration","text":"<pre><code>from src.agent import VerifierAgent\nfrom src.config import VerifierConfig\n\n# Configure for documentation generation\nconfig = VerifierConfig(\n    agent_mission='docs',\n    working_set_dir='docs/generated'\n)\n\n# Create documentation agent\nagent = VerifierAgent(config)\nawait agent.start_session()\n\n# Process file changes\nchanges = [\n    {\n        'file_path': 'src/new_api.py',\n        'action': 'created',\n        'content': 'class NewAPI: ...'\n    }\n]\nawait agent.process_file_changes(changes)\n</code></pre>"},{"location":"working_set/api-reference/#working-set-management","title":"Working Set Management","text":"<pre><code>from src.working_set import WorkingSetManager\n\n# Create manager\nmanager = WorkingSetManager('tests/working_set')\n\n# Ensure directory structure\nmanager.ensure_directory_structure()\n\n# Create test file\ntest_content = '''\nimport unittest\n\nclass TestExample(unittest.TestCase):\n    def test_basic(self):\n        self.assertTrue(True)\n'''\n\ntest_file = manager.create_test_file('test_example', test_content)\nprint(f\"Created test: {test_file}\")\n\n# List all tests\nfor test in manager.list_test_files():\n    print(f\"Test file: {test.name}\")\n</code></pre>"},{"location":"working_set/api-reference/#error-monitoring","title":"Error Monitoring","text":"<pre><code>from src.reporter import ErrorReporter, ReportMonitor\n\n# Create reporter\nreporter = ErrorReporter('error_report.jsonl')\n\n# Report an error\nreporter.report_error(\n    file_path='src/buggy_code.py',\n    line=25,\n    severity='medium',\n    description='Unused variable detected',\n    suggested_fix='Remove unused variable or use it'\n)\n\n# Monitor for new reports\nmonitor = ReportMonitor('error_report.jsonl')\nif monitor.has_new_reports():\n    reports = monitor.get_new_reports()\n    for report in reports:\n        print(f\"New error: {report['description']}\")\n</code></pre>"},{"location":"working_set/api-reference/#configuration-examples","title":"Configuration Examples","text":""},{"location":"working_set/api-reference/#basic-configuration","title":"Basic Configuration","text":"<pre><code>{\n  \"watch_dirs\": [\"src\"],\n  \"test_dir\": \"tests\",\n  \"working_set_dir\": \"tests/working_set\",\n  \"agent_mission\": \"testing\"\n}\n</code></pre>"},{"location":"working_set/api-reference/#advanced-configuration","title":"Advanced Configuration","text":"<pre><code>{\n  \"watch_dirs\": [\"src\", \"lib\", \"api\"],\n  \"test_dir\": \"tests\",\n  \"working_set_dir\": \"tests/generated\",\n  \"watch_extensions\": [\".py\", \".js\", \".ts\", \".go\"],\n  \"agent_mission\": \"testing\",\n  \"error_report_file\": \"reports/errors.jsonl\",\n  \"claude_timeout\": 600,\n  \"claude_log_file\": \"logs/claude.jsonl\"\n}\n</code></pre>"},{"location":"working_set/api-reference/#documentation-configuration","title":"Documentation Configuration","text":"<pre><code>{\n  \"watch_dirs\": [\"src\"],\n  \"test_dir\": \"tests\",\n  \"working_set_dir\": \"docs/generated\",\n  \"agent_mission\": \"docs\",\n  \"claude_timeout\": 300\n}\n</code></pre>"},{"location":"working_set/architecture/","title":"System Architecture","text":""},{"location":"working_set/architecture/#overview","title":"Overview","text":"<p>The Verifier System is designed as a modular, event-driven architecture that provides automated testing and documentation generation through Claude Code agents. The system follows a microservices-like pattern where each component has a specific responsibility and communicates through well-defined interfaces.</p>"},{"location":"working_set/architecture/#architecture-diagram","title":"Architecture Diagram","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           Overseer                              \u2502\n\u2502                    (Main Orchestrator)                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                      \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502                 \u2502                 \u2502\n    \u25bc                 \u25bc                 \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Watcher \u2502    \u2502 Delta Gate  \u2502    \u2502 Agents      \u2502\n\u2502         \u2502    \u2502             \u2502    \u2502             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \u2502                 \u2502                 \u2502\n    \u2502                 \u2502                 \u2502\n    \u25bc                 \u25bc                 \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 File    \u2502    \u2502 Batch       \u2502    \u2502 Claude Code \u2502\n\u2502 Events  \u2502    \u2502 Processing  \u2502    \u2502 Interface   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                      \u2502\n                      \u25bc\n               \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n               \u2502 Working Set \u2502\n               \u2502 Manager     \u2502\n               \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"working_set/architecture/#component-architecture","title":"Component Architecture","text":""},{"location":"working_set/architecture/#1-overseer-main-orchestrator","title":"1. Overseer (Main Orchestrator)","text":"<p>Location: <code>src/overseer.py:15</code></p> <p>The Overseer is the central coordinator that manages all other components and orchestrates the entire verification process.</p> <p>Responsibilities: - Initialize and coordinate all system components - Handle signal processing for graceful shutdown - Process file change batches from the Delta Gate - Manage error reporting and display - Coordinate parallel agent execution</p> <p>Key Features: - Dual-agent architecture (testing + documentation) - Graceful shutdown handling - Error reporting integration - Parallel processing of file changes</p>"},{"location":"working_set/architecture/#2-file-system-watcher","title":"2. File System Watcher","text":"<p>Location: <code>src/watcher.py:31</code></p> <p>Monitors filesystem changes using the watchdog library and filters changes based on configured file extensions.</p> <p>Responsibilities: - Monitor specified directories for file changes - Filter changes based on file extensions - Emit file change events to the Delta Gate - Handle recursive directory monitoring</p> <p>Event Types: - <code>created</code>: New file created - <code>modified</code>: Existing file modified - <code>deleted</code>: File deleted</p>"},{"location":"working_set/architecture/#3-delta-gate-change-filter-batcher","title":"3. Delta Gate (Change Filter &amp; Batcher)","text":"<p>Location: <code>src/delta_gate.py:29</code></p> <p>Intelligent filtering and batching system that determines which file changes warrant processing and groups related changes together.</p> <p>Responsibilities: - Filter out irrelevant file changes (temporary files, logs, etc.) - Batch related changes together for efficient processing - Implement rate limiting to prevent overwhelming the system - Handle file size constraints</p> <p>Filtering Rules: - File extension filtering - Ignore patterns (*.pyc, .git, pycache, etc.) - File size constraints (min/max) - Hidden file filtering</p> <p>Batching Strategy: - Minimum change interval (0.5s default) - Batch timeout (2.0s default) - Overwrite strategy for multiple changes to same file</p>"},{"location":"working_set/architecture/#4-agent-system","title":"4. Agent System","text":"<p>The system includes two types of agents that work in parallel:</p>"},{"location":"working_set/architecture/#verifieragent","title":"VerifierAgent","text":"<p>Location: <code>src/agent.py:11</code></p> <p>Interfaces with Claude Code to generate and execute tests.</p> <p>Responsibilities: - Generate tests based on file changes - Execute generated tests - Report test results and failures - Detect and report potential bugs</p>"},{"location":"working_set/architecture/#documentationagent","title":"DocumentationAgent","text":"<p>Location: <code>src/doc_agent.py:11</code></p> <p>Interfaces with Claude Code to generate and update documentation.</p> <p>Responsibilities: - Generate API documentation - Create usage examples - Update existing documentation - Generate architecture diagrams</p>"},{"location":"working_set/architecture/#5-working-set-manager","title":"5. Working Set Manager","text":"<p>Location: <code>src/working_set.py:7</code></p> <p>Manages the working set directory structure and generated artifacts.</p> <p>Responsibilities: - Create and organize test files - Manage documentation artifacts - Handle metadata and versioning - Provide file cleanup utilities</p> <p>Directory Structure: <pre><code>working_set/\n\u251c\u2500\u2500 tests/           # Generated test files\n\u251c\u2500\u2500 artifacts/       # Build artifacts and reports\n\u251c\u2500\u2500 reports/         # Error reports and monitoring data\n\u2514\u2500\u2500 metadata.json    # Working set metadata\n</code></pre></p>"},{"location":"working_set/architecture/#6-error-reporting-system","title":"6. Error Reporting System","text":"<p>Location: <code>src/reporter.py:8</code></p> <p>Handles error detection, reporting, and monitoring.</p> <p>Components: - <code>ErrorReporter</code>: Writes errors to JSONL files - <code>ReportMonitor</code>: Monitors for new error reports</p> <p>Error Report Format: <pre><code>{\n  \"timestamp\": \"2025-07-05T08:20:00Z\",\n  \"file\": \"src/example.py\",\n  \"line\": 42,\n  \"severity\": \"high|medium|low\",\n  \"description\": \"Error description\",\n  \"suggested_fix\": \"Suggested fix\"\n}\n</code></pre></p>"},{"location":"working_set/architecture/#data-flow","title":"Data Flow","text":""},{"location":"working_set/architecture/#1-file-change-detection","title":"1. File Change Detection","text":"<pre><code>File System \u2192 Watcher \u2192 Delta Gate \u2192 Overseer\n</code></pre> <ol> <li>File System: User makes changes to monitored files</li> <li>Watcher: Detects changes and emits events</li> <li>Delta Gate: Filters and batches changes</li> <li>Overseer: Receives batched changes for processing</li> </ol>"},{"location":"working_set/architecture/#2-agent-processing","title":"2. Agent Processing","text":"<pre><code>Overseer \u2192 [VerifierAgent, DocumentationAgent] \u2192 Claude Code \u2192 Working Set\n</code></pre> <ol> <li>Overseer: Dispatches file changes to both agents in parallel</li> <li>Agents: Process changes and generate prompts for Claude Code</li> <li>Claude Code: Generates tests/documentation based on prompts</li> <li>Working Set: Stores generated artifacts</li> </ol>"},{"location":"working_set/architecture/#3-error-flow","title":"3. Error Flow","text":"<pre><code>Agent \u2192 Error Reporter \u2192 Report Monitor \u2192 Overseer \u2192 User Display\n</code></pre> <ol> <li>Agent: Detects errors during processing</li> <li>Error Reporter: Writes errors to JSONL file</li> <li>Report Monitor: Detects new error reports</li> <li>Overseer: Processes and displays errors to user</li> </ol>"},{"location":"working_set/architecture/#configuration-architecture","title":"Configuration Architecture","text":""},{"location":"working_set/architecture/#configuration-hierarchy","title":"Configuration Hierarchy","text":"<pre><code>Default Config \u2192 File Config \u2192 CLI Arguments \u2192 Environment Variables\n</code></pre> <ol> <li>Default Config: Built-in defaults in <code>VerifierConfig</code></li> <li>File Config: User-defined JSON configuration file</li> <li>CLI Arguments: Command-line overrides</li> <li>Environment Variables: Runtime environment overrides</li> </ol>"},{"location":"working_set/architecture/#configuration-validation","title":"Configuration Validation","text":"<p>The system validates configuration at startup: - Check that watch directories exist - Validate file extensions - Ensure working set directory can be created - Verify Claude Code is available</p>"},{"location":"working_set/architecture/#concurrency-model","title":"Concurrency Model","text":""},{"location":"working_set/architecture/#asyncawait-pattern","title":"Async/Await Pattern","text":"<p>The system uses Python's asyncio for concurrent processing:</p> <pre><code># Parallel agent processing\nawait asyncio.gather(\n    self.agent.process_file_changes(batch),\n    self.doc_agent.process_file_changes(batch)\n)\n</code></pre>"},{"location":"working_set/architecture/#thread-safety","title":"Thread Safety","text":"<ul> <li>File system operations are synchronized</li> <li>Agent sessions are isolated</li> <li>Error reporting uses file-based queuing</li> </ul>"},{"location":"working_set/architecture/#extensibility-points","title":"Extensibility Points","text":""},{"location":"working_set/architecture/#1-custom-agents","title":"1. Custom Agents","text":"<p>Create specialized agents by inheriting from base agent classes:</p> <pre><code>class CustomAgent(VerifierAgent):\n    def _get_mission_prompt(self) -&gt; str:\n        return \"Custom mission prompt\"\n</code></pre>"},{"location":"working_set/architecture/#2-custom-filters","title":"2. Custom Filters","text":"<p>Extend the Delta Gate with custom filtering logic:</p> <pre><code>class CustomDeltaGate(DeltaGate):\n    def _should_process_change(self, change: FileChange) -&gt; bool:\n        # Custom filtering logic\n        return super()._should_process_change(change)\n</code></pre>"},{"location":"working_set/architecture/#3-custom-reporters","title":"3. Custom Reporters","text":"<p>Implement custom error reporting formats:</p> <pre><code>class CustomReporter(ErrorReporter):\n    def report_error(self, ...):\n        # Custom reporting logic\n        pass\n</code></pre>"},{"location":"working_set/architecture/#performance-considerations","title":"Performance Considerations","text":""},{"location":"working_set/architecture/#1-file-system-monitoring","title":"1. File System Monitoring","text":"<ul> <li>Uses efficient watchdog library</li> <li>Filters changes at the watcher level</li> <li>Recursive monitoring with pattern exclusion</li> </ul>"},{"location":"working_set/architecture/#2-batch-processing","title":"2. Batch Processing","text":"<ul> <li>Intelligent batching reduces Claude Code calls</li> <li>Configurable batch timeouts</li> <li>Rate limiting prevents overwhelming</li> </ul>"},{"location":"working_set/architecture/#3-memory-management","title":"3. Memory Management","text":"<ul> <li>Conversation history management</li> <li>Working set cleanup utilities</li> <li>Log rotation for long-running processes</li> </ul>"},{"location":"working_set/architecture/#4-error-handling","title":"4. Error Handling","text":"<ul> <li>Graceful degradation on agent failures</li> <li>Retry logic for transient errors</li> <li>Resource cleanup on shutdown</li> </ul>"},{"location":"working_set/architecture/#security-considerations","title":"Security Considerations","text":""},{"location":"working_set/architecture/#1-file-system-access","title":"1. File System Access","text":"<ul> <li>Configurable watch directories</li> <li>File extension filtering</li> <li>Size constraints prevent processing large files</li> </ul>"},{"location":"working_set/architecture/#2-external-process-execution","title":"2. External Process Execution","text":"<ul> <li>Sandboxed Claude Code execution</li> <li>Timeout protection</li> <li>Error handling for process failures</li> </ul>"},{"location":"working_set/architecture/#3-data-privacy","title":"3. Data Privacy","text":"<ul> <li>Local file processing only</li> <li>No external data transmission</li> <li>Configurable log retention</li> </ul>"},{"location":"working_set/architecture/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"working_set/architecture/#1-logging","title":"1. Logging","text":"<ul> <li>Structured logging with JSON format</li> <li>Multiple log levels (DEBUG, INFO, ERROR)</li> <li>Separate logs for different components</li> </ul>"},{"location":"working_set/architecture/#2-metrics","title":"2. Metrics","text":"<ul> <li>File processing rates</li> <li>Agent success/failure rates</li> <li>Error report statistics</li> </ul>"},{"location":"working_set/architecture/#3-health-checks","title":"3. Health Checks","text":"<ul> <li>Component status monitoring</li> <li>Resource utilization tracking</li> <li>Error rate monitoring</li> </ul>"},{"location":"working_set/architecture/#deployment-patterns","title":"Deployment Patterns","text":""},{"location":"working_set/architecture/#1-development-mode","title":"1. Development Mode","text":"<ul> <li>Mock agents for testing</li> <li>Reduced timeouts</li> <li>Verbose logging</li> </ul>"},{"location":"working_set/architecture/#2-production-mode","title":"2. Production Mode","text":"<ul> <li>Real Claude Code integration</li> <li>Optimized batch processing</li> <li>Error alerting</li> </ul>"},{"location":"working_set/architecture/#3-cicd-integration","title":"3. CI/CD Integration","text":"<ul> <li>Automated test generation</li> <li>Documentation updates</li> <li>Quality gate enforcement</li> </ul>"},{"location":"working_set/auth-api-documentation/","title":"UserAuth API Documentation","text":""},{"location":"working_set/auth-api-documentation/#overview","title":"Overview","text":"<p>The <code>UserAuth</code> class provides a simple user authentication system with user registration and authentication capabilities. This class is designed for basic authentication needs and stores user credentials in memory.</p>"},{"location":"working_set/auth-api-documentation/#class-userauth","title":"Class: UserAuth","text":""},{"location":"working_set/auth-api-documentation/#constructor","title":"Constructor","text":"<pre><code>def __init__(self):\n</code></pre> <p>Initializes a new UserAuth instance with an empty users dictionary.</p> <p>Parameters: None</p> <p>Returns: None</p>"},{"location":"working_set/auth-api-documentation/#methods","title":"Methods","text":""},{"location":"working_set/auth-api-documentation/#register_userusername-password","title":"register_user(username, password)","text":"<p>Registers a new user with the provided username and password.</p> <p>Parameters: - <code>username</code> (str): The username for the new user - <code>password</code> (str): The password for the new user</p> <p>Returns: - <code>bool</code>: Returns <code>True</code> if registration is successful</p> <p>Raises: - <code>ValueError</code>: If the username already exists in the system</p> <p>Example: <pre><code>auth = UserAuth()\nauth.register_user(\"john_doe\", \"secure_password\")\n</code></pre></p>"},{"location":"working_set/auth-api-documentation/#authenticateusername-password","title":"authenticate(username, password)","text":"<p>Authenticates a user with the provided credentials.</p> <p>Parameters: - <code>username</code> (str): The username to authenticate - <code>password</code> (str): The password to verify</p> <p>Returns: - <code>bool</code>: Returns <code>True</code> if authentication is successful, <code>False</code> otherwise</p> <p>Example: <pre><code>auth = UserAuth()\nauth.register_user(\"john_doe\", \"secure_password\")\nis_authenticated = auth.authenticate(\"john_doe\", \"secure_password\")  # Returns True\n</code></pre></p>"},{"location":"working_set/auth-api-documentation/#get_user_count","title":"get_user_count()","text":"<p>Returns the total number of registered users.</p> <p>Parameters: None</p> <p>Returns: - <code>int</code>: The number of registered users</p> <p>Example: <pre><code>auth = UserAuth()\nauth.register_user(\"user1\", \"password1\")\nauth.register_user(\"user2\", \"password2\")\ncount = auth.get_user_count()  # Returns 2\n</code></pre></p>"},{"location":"working_set/auth-api-documentation/#security-considerations","title":"Security Considerations","text":"<p>\u26a0\ufe0f Important Security Notice:</p> <p>This implementation is for demonstration purposes only and should not be used in production environments without proper security enhancements:</p> <ol> <li>Password Storage: Passwords are stored in plain text. In production, use proper password hashing (e.g., bcrypt, scrypt, or argon2).</li> <li>Memory Storage: User data is stored in memory and will be lost when the application restarts.</li> <li>Input Validation: No input validation is performed on usernames or passwords.</li> <li>Rate Limiting: No protection against brute force attacks.</li> </ol>"},{"location":"working_set/auth-api-documentation/#file-location","title":"File Location","text":"<ul> <li>Source File: <code>src/auth.py</code></li> <li>Lines: 2-19</li> </ul>"},{"location":"working_set/auth-api-documentation/#version-information","title":"Version Information","text":"<ul> <li>Last Modified: Based on detected changes in <code>/tmp/tmpzmxjpe9o/src/auth.py</code></li> <li>Documentation Generated: 2025-07-05</li> </ul>"},{"location":"working_set/auth-change-summary/","title":"Authentication Module Change Summary","text":""},{"location":"working_set/auth-change-summary/#file-modified","title":"File Modified","text":"<ul> <li>File: <code>/tmp/tmpzmxjpe9o/src/auth.py</code></li> <li>Detection Date: 2025-07-05</li> </ul>"},{"location":"working_set/auth-change-summary/#changes-overview","title":"Changes Overview","text":""},{"location":"working_set/auth-change-summary/#new-features-added","title":"New Features Added","text":""},{"location":"working_set/auth-change-summary/#userauth-class","title":"UserAuth Class","text":"<p>A new authentication class has been implemented with the following capabilities:</p> <ul> <li>User Registration: Register new users with username/password</li> <li>User Authentication: Validate user credentials</li> <li>User Management: Track total number of registered users</li> </ul>"},{"location":"working_set/auth-change-summary/#class-structure","title":"Class Structure","text":"<pre><code>class UserAuth:\n    def __init__(self):\n        self.users = {}  # Dictionary to store user credentials\n\n    def register_user(self, username, password):\n        # Register new user, prevent duplicates\n\n    def authenticate(self, username, password):\n        # Authenticate user credentials\n\n    def get_user_count(self):\n        # Return total number of registered users\n</code></pre>"},{"location":"working_set/auth-change-summary/#method-details","title":"Method Details","text":"Method Purpose Parameters Returns Exceptions <code>__init__()</code> Initialize empty user storage None None None <code>register_user()</code> Register new user username, password bool (True) ValueError if user exists <code>authenticate()</code> Verify user credentials username, password bool None <code>get_user_count()</code> Get total users None int None"},{"location":"working_set/auth-change-summary/#breaking-changes","title":"Breaking Changes","text":"<ul> <li>None: This is a new module with no existing functionality to break</li> </ul>"},{"location":"working_set/auth-change-summary/#new-dependencies","title":"New Dependencies","text":"<ul> <li>None: No external dependencies required</li> </ul>"},{"location":"working_set/auth-change-summary/#security-considerations","title":"Security Considerations","text":"<p>\u26a0\ufe0f Important Security Notes:</p> <ol> <li>Password Storage: Passwords are stored in plain text</li> <li>Memory Storage: Data is not persistent</li> <li>No Input Validation: No validation on username/password format</li> <li>No Rate Limiting: Vulnerable to brute force attacks</li> </ol>"},{"location":"working_set/auth-change-summary/#impact-assessment","title":"Impact Assessment","text":""},{"location":"working_set/auth-change-summary/#positive-impact","title":"Positive Impact","text":"<ul> <li>Provides basic authentication functionality</li> <li>Simple API for user management</li> <li>Lightweight implementation</li> </ul>"},{"location":"working_set/auth-change-summary/#risks","title":"Risks","text":"<ul> <li>Security vulnerabilities due to plain text password storage</li> <li>Data loss on application restart</li> <li>No protection against common attack vectors</li> </ul>"},{"location":"working_set/auth-change-summary/#recommendations","title":"Recommendations","text":""},{"location":"working_set/auth-change-summary/#for-production-use","title":"For Production Use","text":"<ol> <li>Implement proper password hashing (bcrypt, scrypt, argon2)</li> <li>Add persistent storage (database)</li> <li>Implement input validation</li> <li>Add rate limiting for authentication attempts</li> <li>Add session management</li> <li>Implement secure password policies</li> </ol>"},{"location":"working_set/auth-change-summary/#for-developmenttesting","title":"For Development/Testing","text":"<ul> <li>Current implementation is suitable for basic testing and development</li> <li>Consider adding unit tests for all methods</li> <li>Add logging for authentication events</li> </ul>"},{"location":"working_set/auth-change-summary/#documentation-generated","title":"Documentation Generated","text":"<ul> <li>API Documentation: <code>auth-api-documentation.md</code></li> <li>Usage Examples: <code>auth-usage-examples.md</code></li> <li>Change Summary: <code>auth-change-summary.md</code> (this file)</li> </ul>"},{"location":"working_set/auth-change-summary/#next-steps","title":"Next Steps","text":"<ol> <li>Review security implications</li> <li>Add comprehensive unit tests</li> <li>Consider integration with existing authentication systems</li> <li>Plan for production security enhancements</li> </ol>"},{"location":"working_set/auth-usage-examples/","title":"UserAuth Usage Examples","text":""},{"location":"working_set/auth-usage-examples/#basic-usage","title":"Basic Usage","text":""},{"location":"working_set/auth-usage-examples/#creating-an-authentication-system","title":"Creating an Authentication System","text":"<pre><code>from src.auth import UserAuth\n\n# Initialize the authentication system\nauth = UserAuth()\n</code></pre>"},{"location":"working_set/auth-usage-examples/#user-registration","title":"User Registration","text":"<pre><code># Register a new user\ntry:\n    auth.register_user(\"alice\", \"password123\")\n    print(\"User registered successfully!\")\nexcept ValueError as e:\n    print(f\"Registration failed: {e}\")\n\n# Attempting to register the same user again\ntry:\n    auth.register_user(\"alice\", \"different_password\")\nexcept ValueError as e:\n    print(f\"Registration failed: {e}\")  # Output: Registration failed: User already exists\n</code></pre>"},{"location":"working_set/auth-usage-examples/#user-authentication","title":"User Authentication","text":"<pre><code># Authenticate existing user\nif auth.authenticate(\"alice\", \"password123\"):\n    print(\"Authentication successful!\")\nelse:\n    print(\"Authentication failed!\")\n\n# Authenticate with wrong password\nif auth.authenticate(\"alice\", \"wrong_password\"):\n    print(\"Authentication successful!\")\nelse:\n    print(\"Authentication failed!\")  # This will be printed\n\n# Authenticate non-existent user\nif auth.authenticate(\"bob\", \"any_password\"):\n    print(\"Authentication successful!\")\nelse:\n    print(\"Authentication failed!\")  # This will be printed\n</code></pre>"},{"location":"working_set/auth-usage-examples/#getting-user-count","title":"Getting User Count","text":"<pre><code># Check number of registered users\nprint(f\"Total users: {auth.get_user_count()}\")\n\n# Register more users\nauth.register_user(\"bob\", \"bob_password\")\nauth.register_user(\"charlie\", \"charlie_password\")\n\nprint(f\"Total users: {auth.get_user_count()}\")  # Output: Total users: 3\n</code></pre>"},{"location":"working_set/auth-usage-examples/#complete-example","title":"Complete Example","text":"<pre><code>from src.auth import UserAuth\n\ndef main():\n    # Initialize authentication system\n    auth = UserAuth()\n\n    # Register multiple users\n    users_to_register = [\n        (\"admin\", \"admin_password\"),\n        (\"user1\", \"user1_password\"),\n        (\"user2\", \"user2_password\")\n    ]\n\n    for username, password in users_to_register:\n        try:\n            auth.register_user(username, password)\n            print(f\"\u2713 Registered user: {username}\")\n        except ValueError as e:\n            print(f\"\u2717 Failed to register {username}: {e}\")\n\n    # Display user count\n    print(f\"\\nTotal registered users: {auth.get_user_count()}\")\n\n    # Test authentication\n    test_credentials = [\n        (\"admin\", \"admin_password\"),     # Valid\n        (\"user1\", \"wrong_password\"),     # Invalid password\n        (\"nonexistent\", \"any_password\"), # User doesn't exist\n        (\"user2\", \"user2_password\")      # Valid\n    ]\n\n    print(\"\\nAuthentication tests:\")\n    for username, password in test_credentials:\n        if auth.authenticate(username, password):\n            print(f\"\u2713 {username}: Authentication successful\")\n        else:\n            print(f\"\u2717 {username}: Authentication failed\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"working_set/auth-usage-examples/#error-handling","title":"Error Handling","text":"<pre><code>from src.auth import UserAuth\n\nauth = UserAuth()\n\n# Handle registration errors\ndef safe_register(username, password):\n    try:\n        result = auth.register_user(username, password)\n        return {\"success\": True, \"message\": f\"User {username} registered successfully\"}\n    except ValueError as e:\n        return {\"success\": False, \"message\": str(e)}\n\n# Handle authentication with logging\ndef safe_authenticate(username, password):\n    result = auth.authenticate(username, password)\n    if result:\n        print(f\"User {username} authenticated successfully\")\n    else:\n        print(f\"Authentication failed for user {username}\")\n    return result\n\n# Example usage\nregistration_result = safe_register(\"test_user\", \"test_password\")\nprint(registration_result)\n\nauth_result = safe_authenticate(\"test_user\", \"test_password\")\n</code></pre>"},{"location":"working_set/auth-usage-examples/#integration-example","title":"Integration Example","text":"<pre><code>from src.auth import UserAuth\n\nclass SimpleApp:\n    def __init__(self):\n        self.auth = UserAuth()\n        self.current_user = None\n\n    def register(self, username, password):\n        try:\n            self.auth.register_user(username, password)\n            return {\"status\": \"success\", \"message\": \"Registration successful\"}\n        except ValueError as e:\n            return {\"status\": \"error\", \"message\": str(e)}\n\n    def login(self, username, password):\n        if self.auth.authenticate(username, password):\n            self.current_user = username\n            return {\"status\": \"success\", \"message\": f\"Welcome, {username}!\"}\n        else:\n            return {\"status\": \"error\", \"message\": \"Invalid credentials\"}\n\n    def logout(self):\n        if self.current_user:\n            user = self.current_user\n            self.current_user = None\n            return {\"status\": \"success\", \"message\": f\"Goodbye, {user}!\"}\n        else:\n            return {\"status\": \"error\", \"message\": \"No user logged in\"}\n\n    def get_stats(self):\n        return {\n            \"total_users\": self.auth.get_user_count(),\n            \"current_user\": self.current_user,\n            \"logged_in\": self.current_user is not None\n        }\n\n# Example usage\napp = SimpleApp()\nprint(app.register(\"alice\", \"password123\"))\nprint(app.login(\"alice\", \"password123\"))\nprint(app.get_stats())\nprint(app.logout())\n</code></pre>"},{"location":"working_set/cli-documentation/","title":"Interactive CLI Documentation","text":""},{"location":"working_set/cli-documentation/#overview","title":"Overview","text":"<p>The Parallel Agents Interactive CLI provides a command-line interface for managing and monitoring the verifier agent system. This CLI includes real-time log streaming, configuration management, and agent lifecycle control.</p>"},{"location":"working_set/cli-documentation/#recent-changes","title":"Recent Changes","text":""},{"location":"working_set/cli-documentation/#configuration-validation","title":"Configuration Validation","text":"<ul> <li>Added configuration validation before starting agents</li> <li>Added safety checks to prevent operations with invalid configurations</li> <li>Enhanced error handling for missing configurations</li> </ul>"},{"location":"working_set/cli-documentation/#new-features","title":"New Features","text":"<ul> <li>LogStreamer Class: Real-time log streaming with formatted output</li> <li>Interactive Commands: Complete CLI interface with status monitoring</li> <li>Configuration Management: Load, validate, and switch configurations</li> <li>Agent Control: Start/stop agents with demo mode support</li> </ul>"},{"location":"working_set/cli-documentation/#architecture","title":"Architecture","text":""},{"location":"working_set/cli-documentation/#logstreamer-class","title":"LogStreamer Class","text":"<pre><code>class LogStreamer:\n    \"\"\"Handles real-time log streaming from log files\"\"\"\n</code></pre> <p>Purpose: Provides real-time monitoring of agent activities through log file streaming.</p> <p>Key Features: - Threaded log streaming to avoid blocking CLI - JSON log parsing with formatted output - Automatic file monitoring and error recovery - Graceful shutdown handling</p>"},{"location":"working_set/cli-documentation/#interactiveverifiercli-class","title":"InteractiveVerifierCLI Class","text":"<pre><code>class InteractiveVerifierCLI(cmd.Cmd):\n    \"\"\"Interactive CLI for the Verifier system\"\"\"\n</code></pre> <p>Purpose: Main CLI interface for managing the parallel agents system.</p> <p>Key Features: - Configuration management and validation - Agent lifecycle control (start/stop) - Real-time log streaming - Status monitoring and reporting</p>"},{"location":"working_set/cli-documentation/#command-reference","title":"Command Reference","text":""},{"location":"working_set/cli-documentation/#configuration-commands","title":"Configuration Commands","text":""},{"location":"working_set/cli-documentation/#config-file","title":"<code>config [file]</code>","text":"<p>Show current configuration or load a new configuration file.</p> <p>Usage: <pre><code>(parallel-agents) config                    # Show current config\n(parallel-agents) config my-config.json     # Load specific config\n</code></pre></p>"},{"location":"working_set/cli-documentation/#init-filename","title":"<code>init [filename]</code>","text":"<p>Initialize a new configuration file with default values.</p> <p>Usage: <pre><code>(parallel-agents) init                      # Create verifier.json\n(parallel-agents) init custom.json         # Create custom.json\n</code></pre></p>"},{"location":"working_set/cli-documentation/#validate","title":"<code>validate</code>","text":"<p>Validate the current configuration for errors and missing dependencies.</p> <p>Usage: <pre><code>(parallel-agents) validate\n</code></pre></p> <p>Validation Checks: - Watch directory existence - Working set directory creation - Configuration file integrity</p>"},{"location":"working_set/cli-documentation/#agent-control-commands","title":"Agent Control Commands","text":""},{"location":"working_set/cli-documentation/#start-options","title":"<code>start [options]</code>","text":"<p>Start the verifier agent with optional parameters.</p> <p>Usage: <pre><code>(parallel-agents) start                              # Start normal agent\n(parallel-agents) start --demo                      # Start demo agent\n(parallel-agents) start --mission \"Custom mission\"  # Start with custom mission\n(parallel-agents) start --demo --mission testing    # Demo with custom mission\n</code></pre></p> <p>Options: - <code>--demo</code>: Use MockOverseer for testing without actual Claude API calls - <code>--mission &lt;text&gt;</code>: Override the default mission from configuration</p>"},{"location":"working_set/cli-documentation/#stop","title":"<code>stop</code>","text":"<p>Stop the currently running verifier agent.</p> <p>Usage: <pre><code>(parallel-agents) stop\n</code></pre></p>"},{"location":"working_set/cli-documentation/#monitoring-commands","title":"Monitoring Commands","text":""},{"location":"working_set/cli-documentation/#status","title":"<code>status</code>","text":"<p>Show detailed agent status and recent activity.</p> <p>Usage: <pre><code>(parallel-agents) status\n</code></pre></p> <p>Information Displayed: - Agent running state - Current mission - Watch directories - Working set directory - Log file location - Recent log entries (last 3)</p>"},{"location":"working_set/cli-documentation/#logs-startstop","title":"<code>logs [start|stop]</code>","text":"<p>Control real-time log streaming.</p> <p>Usage: <pre><code>(parallel-agents) logs          # Start streaming\n(parallel-agents) logs start    # Start streaming\n(parallel-agents) logs stop     # Stop streaming\n</code></pre></p> <p>Log Format: - \ud83d\ude80 Session start events - \u2705/\u274c Claude API interactions with success/failure indicators - \ud83d\udccb General log entries - Timestamps and truncated content for readability</p>"},{"location":"working_set/cli-documentation/#utility-commands","title":"Utility Commands","text":""},{"location":"working_set/cli-documentation/#help-command","title":"<code>help [command]</code>","text":"<p>Show available commands or detailed help for a specific command.</p> <p>Usage: <pre><code>(parallel-agents) help          # Show all commands\n(parallel-agents) help start    # Show help for start command\n</code></pre></p>"},{"location":"working_set/cli-documentation/#exit-quit","title":"<code>exit</code> / <code>quit</code>","text":"<p>Exit the interactive CLI, stopping all running services.</p> <p>Usage: <pre><code>(parallel-agents) exit\n(parallel-agents) quit\n</code></pre></p>"},{"location":"working_set/cli-documentation/#configuration-integration","title":"Configuration Integration","text":"<p>The CLI automatically loads configuration from <code>verifier.json</code> by default. Key configuration elements used:</p> <ul> <li><code>agent_mission</code>: Default mission for agents</li> <li><code>watch_dirs</code>: Directories to monitor for changes</li> <li><code>working_set_dir</code>: Directory for agent output</li> <li><code>claude_log_file</code>: Location of interaction logs</li> </ul>"},{"location":"working_set/cli-documentation/#error-handling","title":"Error Handling","text":""},{"location":"working_set/cli-documentation/#configuration-errors","title":"Configuration Errors","text":"<ul> <li>Missing configuration files trigger default config creation</li> <li>Invalid configurations show descriptive error messages</li> <li>Configuration validation prevents startup with invalid settings</li> </ul>"},{"location":"working_set/cli-documentation/#agent-management-errors","title":"Agent Management Errors","text":"<ul> <li>Prevents starting multiple agents simultaneously</li> <li>Handles agent startup/shutdown failures gracefully</li> <li>Provides clear error messages for troubleshooting</li> </ul>"},{"location":"working_set/cli-documentation/#log-streaming-errors","title":"Log Streaming Errors","text":"<ul> <li>Handles missing log files gracefully</li> <li>Recovers from temporary file access issues</li> <li>Provides error feedback without crashing</li> </ul>"},{"location":"working_set/cli-documentation/#threading-model","title":"Threading Model","text":"<p>The CLI uses threading to prevent blocking operations:</p> <ol> <li>Main Thread: Handles CLI interactions and command processing</li> <li>Agent Thread: Runs the overseer agent with its own event loop</li> <li>Log Thread: Streams log files in real-time (daemon thread)</li> </ol> <p>This design ensures responsive CLI interactions while maintaining agent operations.</p>"},{"location":"working_set/cli-documentation/#security-considerations","title":"Security Considerations","text":"<ul> <li>Configuration files are validated before use</li> <li>Agent operations are sandboxed to configured directories</li> <li>Log streaming uses read-only file access</li> <li>Graceful shutdown prevents resource leaks</li> </ul>"},{"location":"working_set/cli-documentation/#examples","title":"Examples","text":""},{"location":"working_set/cli-documentation/#basic-workflow","title":"Basic Workflow","text":"<pre><code># Initialize new configuration\n(parallel-agents) init\n\n# Validate configuration\n(parallel-agents) validate\n\n# Start agent\n(parallel-agents) start --mission \"Monitor and document code changes\"\n\n# Monitor logs\n(parallel-agents) logs start\n\n# Check status\n(parallel-agents) status\n\n# Stop agent\n(parallel-agents) stop\n</code></pre>"},{"location":"working_set/cli-documentation/#demo-mode-testing","title":"Demo Mode Testing","text":"<pre><code># Start demo agent for testing\n(parallel-agents) start --demo --mission testing\n\n# Stream logs to see mock interactions\n(parallel-agents) logs start\n\n# Stop when done\n(parallel-agents) stop\n</code></pre>"},{"location":"working_set/cli-documentation/#integration-points","title":"Integration Points","text":"<p>The CLI integrates with: - VerifierConfig: Configuration management - Overseer: Production agent management - MockOverseer: Testing and demonstration - Log Files: Real-time monitoring and analysis</p>"},{"location":"working_set/cli-documentation/#future-enhancements","title":"Future Enhancements","text":"<p>Potential improvements: - Command history and autocompletion - Configuration editing within CLI - Agent performance metrics - Multi-agent support - Remote agent management</p>"},{"location":"working_set/module_0/","title":"Module 0 Documentation","text":""},{"location":"working_set/module_0/#overview","title":"Overview","text":"<p>Module 0 provides basic mathematical operations and a simple class structure. It contains a function for doubling zero and a class with a string-returning method.</p>"},{"location":"working_set/module_0/#functions","title":"Functions","text":""},{"location":"working_set/module_0/#function_0","title":"<code>function_0()</code>","text":"<p>Returns the result of multiplying 0 by 2.</p> <p>Returns: - <code>int</code>: Always returns <code>0</code></p> <p>Example: <pre><code>from src.module_0 import function_0\n\nresult = function_0()\nprint(result)  # Output: 0\n</code></pre></p>"},{"location":"working_set/module_0/#classes","title":"Classes","text":""},{"location":"working_set/module_0/#class_0","title":"<code>Class_0</code>","text":"<p>A simple class that provides a method returning a string identifier.</p>"},{"location":"working_set/module_0/#methods","title":"Methods","text":""},{"location":"working_set/module_0/#method_0self","title":"<code>method_0(self)</code>","text":"<p>Returns a string identifier for this method.</p> <p>Returns: - <code>str</code>: The string <code>\"method_0\"</code></p> <p>Example: <pre><code>from src.module_0 import Class_0\n\ninstance = Class_0()\nresult = instance.method_0()\nprint(result)  # Output: \"method_0\"\n</code></pre></p>"},{"location":"working_set/module_0/#usage-examples","title":"Usage Examples","text":""},{"location":"working_set/module_0/#basic-usage","title":"Basic Usage","text":"<pre><code>from src.module_0 import function_0, Class_0\n\n# Using the function\nvalue = function_0()\nprint(f\"Function result: {value}\")\n\n# Using the class\nobj = Class_0()\nmethod_result = obj.method_0()\nprint(f\"Method result: {method_result}\")\n</code></pre>"},{"location":"working_set/module_0/#integration-example","title":"Integration Example","text":"<pre><code>from src.module_0 import Class_0\n\ndef process_module_0():\n    \"\"\"Example of processing module_0 components.\"\"\"\n    instance = Class_0()\n    identifier = instance.method_0()\n\n    return {\n        'module': 'module_0',\n        'identifier': identifier,\n        'constant_value': 0\n    }\n\nresult = process_module_0()\nprint(result)\n</code></pre>"},{"location":"working_set/module_0/#api-reference","title":"API Reference","text":"Component Type Description Return Type <code>function_0</code> Function Multiplies 0 by 2 <code>int</code> <code>Class_0</code> Class Simple class with string method - <code>Class_0.method_0</code> Method Returns method identifier <code>str</code>"},{"location":"working_set/module_0/#notes","title":"Notes","text":"<ul> <li><code>function_0()</code> will always return <code>0</code> due to the mathematical operation <code>0 * 2</code></li> <li><code>Class_0</code> is a minimal class implementation suitable for demonstration purposes</li> <li>No external dependencies required</li> </ul>"},{"location":"working_set/module_1/","title":"Module 1 Documentation","text":""},{"location":"working_set/module_1/#overview","title":"Overview","text":"<p>Module 1 provides basic mathematical operations and a simple class structure. It contains a function for doubling the value 1 and a class with a string-returning method.</p>"},{"location":"working_set/module_1/#functions","title":"Functions","text":""},{"location":"working_set/module_1/#function_1","title":"<code>function_1()</code>","text":"<p>Returns the result of multiplying 1 by 2.</p> <p>Returns: - <code>int</code>: Always returns <code>2</code></p> <p>Example: <pre><code>from src.module_1 import function_1\n\nresult = function_1()\nprint(result)  # Output: 2\n</code></pre></p>"},{"location":"working_set/module_1/#classes","title":"Classes","text":""},{"location":"working_set/module_1/#class_1","title":"<code>Class_1</code>","text":"<p>A simple class that provides a method returning a string identifier.</p>"},{"location":"working_set/module_1/#methods","title":"Methods","text":""},{"location":"working_set/module_1/#method_1self","title":"<code>method_1(self)</code>","text":"<p>Returns a string identifier for this method.</p> <p>Returns: - <code>str</code>: The string <code>\"method_1\"</code></p> <p>Example: <pre><code>from src.module_1 import Class_1\n\ninstance = Class_1()\nresult = instance.method_1()\nprint(result)  # Output: \"method_1\"\n</code></pre></p>"},{"location":"working_set/module_1/#usage-examples","title":"Usage Examples","text":""},{"location":"working_set/module_1/#basic-usage","title":"Basic Usage","text":"<pre><code>from src.module_1 import function_1, Class_1\n\n# Using the function\nvalue = function_1()\nprint(f\"Function result: {value}\")\n\n# Using the class\nobj = Class_1()\nmethod_result = obj.method_1()\nprint(f\"Method result: {method_result}\")\n</code></pre>"},{"location":"working_set/module_1/#integration-example","title":"Integration Example","text":"<pre><code>from src.module_1 import Class_1\n\ndef process_module_1():\n    \"\"\"Example of processing module_1 components.\"\"\"\n    instance = Class_1()\n    identifier = instance.method_1()\n\n    return {\n        'module': 'module_1',\n        'identifier': identifier,\n        'computed_value': 2\n    }\n\nresult = process_module_1()\nprint(result)\n</code></pre>"},{"location":"working_set/module_1/#mathematical-operations","title":"Mathematical Operations","text":"<pre><code>from src.module_1 import function_1\n\ndef calculate_with_module_1(multiplier):\n    \"\"\"Example of using module_1 in calculations.\"\"\"\n    base_value = function_1()  # Returns 2\n    return base_value * multiplier\n\nresult = calculate_with_module_1(5)\nprint(f\"2 * 5 = {result}\")  # Output: 2 * 5 = 10\n</code></pre>"},{"location":"working_set/module_1/#api-reference","title":"API Reference","text":"Component Type Description Return Type <code>function_1</code> Function Multiplies 1 by 2 <code>int</code> <code>Class_1</code> Class Simple class with string method - <code>Class_1.method_1</code> Method Returns method identifier <code>str</code>"},{"location":"working_set/module_1/#notes","title":"Notes","text":"<ul> <li><code>function_1()</code> will always return <code>2</code> due to the mathematical operation <code>1 * 2</code></li> <li><code>Class_1</code> follows the same pattern as other classes in the module series</li> <li>No external dependencies required</li> <li>Can be used as a base value in mathematical computations</li> </ul>"},{"location":"working_set/module_2/","title":"Module 2 Documentation","text":""},{"location":"working_set/module_2/#overview","title":"Overview","text":"<p>Module 2 provides basic mathematical operations and a simple class structure. It contains a function for doubling the value 2 and a class with a string-returning method.</p>"},{"location":"working_set/module_2/#functions","title":"Functions","text":""},{"location":"working_set/module_2/#function_2","title":"<code>function_2()</code>","text":"<p>Returns the result of multiplying 2 by 2.</p> <p>Returns: - <code>int</code>: Always returns <code>4</code></p> <p>Example: <pre><code>from src.module_2 import function_2\n\nresult = function_2()\nprint(result)  # Output: 4\n</code></pre></p>"},{"location":"working_set/module_2/#classes","title":"Classes","text":""},{"location":"working_set/module_2/#class_2","title":"<code>Class_2</code>","text":"<p>A simple class that provides a method returning a string identifier.</p>"},{"location":"working_set/module_2/#methods","title":"Methods","text":""},{"location":"working_set/module_2/#method_2self","title":"<code>method_2(self)</code>","text":"<p>Returns a string identifier for this method.</p> <p>Returns: - <code>str</code>: The string <code>\"method_2\"</code></p> <p>Example: <pre><code>from src.module_2 import Class_2\n\ninstance = Class_2()\nresult = instance.method_2()\nprint(result)  # Output: \"method_2\"\n</code></pre></p>"},{"location":"working_set/module_2/#usage-examples","title":"Usage Examples","text":""},{"location":"working_set/module_2/#basic-usage","title":"Basic Usage","text":"<pre><code>from src.module_2 import function_2, Class_2\n\n# Using the function\nvalue = function_2()\nprint(f\"Function result: {value}\")\n\n# Using the class\nobj = Class_2()\nmethod_result = obj.method_2()\nprint(f\"Method result: {method_result}\")\n</code></pre>"},{"location":"working_set/module_2/#integration-example","title":"Integration Example","text":"<pre><code>from src.module_2 import Class_2\n\ndef process_module_2():\n    \"\"\"Example of processing module_2 components.\"\"\"\n    instance = Class_2()\n    identifier = instance.method_2()\n\n    return {\n        'module': 'module_2',\n        'identifier': identifier,\n        'computed_value': 4\n    }\n\nresult = process_module_2()\nprint(result)\n</code></pre>"},{"location":"working_set/module_2/#mathematical-operations","title":"Mathematical Operations","text":"<pre><code>from src.module_2 import function_2\n\ndef square_root_example():\n    \"\"\"Example showing module_2's perfect square value.\"\"\"\n    value = function_2()  # Returns 4\n    sqrt_value = value ** 0.5\n    return f\"Square root of {value} is {sqrt_value}\"\n\nresult = square_root_example()\nprint(result)  # Output: Square root of 4 is 2.0\n</code></pre>"},{"location":"working_set/module_2/#power-calculations","title":"Power Calculations","text":"<pre><code>from src.module_2 import function_2\n\ndef power_calculations():\n    \"\"\"Example of using module_2 in power calculations.\"\"\"\n    base = function_2()  # Returns 4\n    powers = [base**i for i in range(1, 4)]\n    return powers\n\nresult = power_calculations()\nprint(result)  # Output: [4, 16, 64]\n</code></pre>"},{"location":"working_set/module_2/#api-reference","title":"API Reference","text":"Component Type Description Return Type <code>function_2</code> Function Multiplies 2 by 2 <code>int</code> <code>Class_2</code> Class Simple class with string method - <code>Class_2.method_2</code> Method Returns method identifier <code>str</code>"},{"location":"working_set/module_2/#notes","title":"Notes","text":"<ul> <li><code>function_2()</code> will always return <code>4</code> due to the mathematical operation <code>2 * 2</code></li> <li><code>Class_2</code> follows the same pattern as other classes in the module series</li> <li>The return value <code>4</code> is a perfect square, making it useful for mathematical examples</li> <li>No external dependencies required</li> <li>Can be used as a base value in power calculations and mathematical operations</li> </ul>"},{"location":"working_set/usage-examples/","title":"Usage Examples","text":""},{"location":"working_set/usage-examples/#basic-usage-examples","title":"Basic Usage Examples","text":""},{"location":"working_set/usage-examples/#1-quick-start","title":"1. Quick Start","text":"<p>The simplest way to get started with the verifier system:</p> <pre><code># Initialize configuration\npython -m src.cli init\n\n# Start monitoring with default settings\npython -m src.cli start\n</code></pre> <p>This will: - Create a default <code>verifier.json</code> configuration - Watch the <code>src</code> directory for Python files - Generate tests automatically when files change</p>"},{"location":"working_set/usage-examples/#2-custom-configuration","title":"2. Custom Configuration","text":"<p>Create a custom configuration for your project:</p> <pre><code># Create custom config\npython -m src.cli init --output my-verifier.json\n\n# Edit the configuration file\n{\n  \"watch_dirs\": [\"src\", \"lib\", \"api\"],\n  \"test_dir\": \"tests\",\n  \"working_set_dir\": \"tests/generated\",\n  \"watch_extensions\": [\".py\", \".js\", \".ts\"],\n  \"agent_mission\": \"testing\",\n  \"claude_timeout\": 300\n}\n\n# Start with custom config\npython -m src.cli start --config my-verifier.json\n</code></pre>"},{"location":"working_set/usage-examples/#3-demo-mode","title":"3. Demo Mode","text":"<p>Try the system without Claude Code using mock agents:</p> <pre><code># Start in demo mode\npython -m src.cli demo\n\n# Watch it generate mock tests\necho \"def hello(): return 'world'\" &gt; src/example.py\n</code></pre>"},{"location":"working_set/usage-examples/#advanced-usage-examples","title":"Advanced Usage Examples","text":""},{"location":"working_set/usage-examples/#1-documentation-generation","title":"1. Documentation Generation","text":"<p>Configure the system to generate documentation instead of tests:</p> <pre><code># Start with documentation mission\npython -m src.cli start --mission docs\n\n# Or configure in JSON\n{\n  \"agent_mission\": \"docs\",\n  \"working_set_dir\": \"docs/generated\",\n  \"watch_dirs\": [\"src\", \"lib\"]\n}\n</code></pre> <p>When you create or modify code:</p> <pre><code># src/new_api.py\nclass UserAPI:\n    \"\"\"API for user management\"\"\"\n\n    def create_user(self, name: str, email: str) -&gt; dict:\n        \"\"\"Create a new user\"\"\"\n        return {\"name\": name, \"email\": email, \"id\": generate_id()}\n\n    def get_user(self, user_id: str) -&gt; dict:\n        \"\"\"Get user by ID\"\"\"\n        return database.get_user(user_id)\n</code></pre> <p>The system will automatically generate: - API documentation with method signatures - Usage examples - Parameter documentation - Return value documentation</p>"},{"location":"working_set/usage-examples/#2-multi-directory-monitoring","title":"2. Multi-Directory Monitoring","text":"<p>Monitor multiple directories with different configurations:</p> <pre><code># Monitor source and API directories\npython -m src.cli start \\\n  --watch-dir src \\\n  --watch-dir api \\\n  --watch-dir lib\n</code></pre> <p>Or in configuration:</p> <pre><code>{\n  \"watch_dirs\": [\"src\", \"api\", \"lib\", \"utils\"],\n  \"watch_extensions\": [\".py\", \".js\", \".ts\", \".go\"],\n  \"agent_mission\": \"testing\"\n}\n</code></pre>"},{"location":"working_set/usage-examples/#3-custom-working-set-directory","title":"3. Custom Working Set Directory","text":"<p>Organize generated files in a custom location:</p> <pre><code>{\n  \"working_set_dir\": \"automation/generated\",\n  \"test_dir\": \"tests\",\n  \"error_report_file\": \"automation/generated/errors.jsonl\",\n  \"claude_log_file\": \"automation/generated/claude.jsonl\"\n}\n</code></pre>"},{"location":"working_set/usage-examples/#programming-examples","title":"Programming Examples","text":""},{"location":"working_set/usage-examples/#1-programmatic-usage","title":"1. Programmatic Usage","text":"<p>Use the verifier system programmatically in your scripts:</p> <pre><code>import asyncio\nfrom src.config import VerifierConfig\nfrom src.overseer import Overseer\n\nasync def main():\n    # Create configuration\n    config = VerifierConfig(\n        watch_dirs=['src', 'lib'],\n        agent_mission='testing',\n        claude_timeout=600\n    )\n\n    # Create and start overseer\n    overseer = Overseer(config)\n\n    try:\n        await overseer.start()\n    except KeyboardInterrupt:\n        print(\"Shutting down...\")\n    finally:\n        await overseer.stop()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"working_set/usage-examples/#2-custom-agent-implementation","title":"2. Custom Agent Implementation","text":"<p>Create a custom agent for specific needs:</p> <pre><code>from src.agent import VerifierAgent\nfrom src.config import VerifierConfig\n\nclass SecurityAgent(VerifierAgent):\n    \"\"\"Agent focused on security testing\"\"\"\n\n    def _get_mission_prompt(self) -&gt; str:\n        return \"\"\"\n        You are a security testing agent. Your mission is to:\n        1. Generate security tests for new code\n        2. Check for common vulnerabilities\n        3. Validate input sanitization\n        4. Test authentication and authorization\n        5. Report security issues with high priority\n        \"\"\"\n\n    def _get_file_deltas_prompt(self, file_changes):\n        base_prompt = super()._get_file_deltas_prompt(file_changes)\n        return f\"{base_prompt}\\n\\nFocus on security implications of these changes.\"\n\n# Usage\nconfig = VerifierConfig(agent_mission=\"security\")\nsecurity_agent = SecurityAgent(config)\n</code></pre>"},{"location":"working_set/usage-examples/#3-working-set-management","title":"3. Working Set Management","text":"<p>Manage generated tests and artifacts:</p> <pre><code>from src.working_set import WorkingSetManager\nfrom pathlib import Path\n\n# Create manager\nmanager = WorkingSetManager('tests/working_set')\n\n# Create directory structure\nmanager.ensure_directory_structure()\n\n# Generate a test file\ntest_content = \"\"\"\nimport unittest\nfrom src.calculator import Calculator\n\nclass TestCalculator(unittest.TestCase):\n    def setUp(self):\n        self.calc = Calculator()\n\n    def test_addition(self):\n        result = self.calc.add(2, 3)\n        self.assertEqual(result, 5)\n\n    def test_division_by_zero(self):\n        with self.assertRaises(ValueError):\n            self.calc.divide(10, 0)\n\"\"\"\n\n# Save test\ntest_file = manager.create_test_file('test_calculator_advanced', test_content)\nprint(f\"Created test: {test_file}\")\n\n# List all tests\nfor test in manager.list_test_files():\n    print(f\"Test: {test.name}\")\n\n# Create metadata\nmetadata = {\n    \"version\": \"1.0.0\",\n    \"generated_at\": \"2025-07-05T08:20:00Z\",\n    \"total_tests\": manager.get_working_set_size()\n}\nmanager.create_metadata_file(metadata)\n</code></pre>"},{"location":"working_set/usage-examples/#real-world-scenarios","title":"Real-World Scenarios","text":""},{"location":"working_set/usage-examples/#1-web-api-development","title":"1. Web API Development","text":"<p>Configuration for a web API project:</p> <pre><code>{\n  \"watch_dirs\": [\"api\", \"models\", \"services\"],\n  \"watch_extensions\": [\".py\", \".js\"],\n  \"agent_mission\": \"testing\",\n  \"working_set_dir\": \"tests/api_tests\",\n  \"claude_timeout\": 300\n}\n</code></pre> <p>Example file change:</p> <pre><code># api/users.py\nfrom flask import Flask, request, jsonify\nfrom models.user import User\n\napp = Flask(__name__)\n\n@app.route('/users', methods=['POST'])\ndef create_user():\n    data = request.json\n    user = User.create(data['name'], data['email'])\n    return jsonify(user.to_dict()), 201\n\n@app.route('/users/&lt;user_id&gt;', methods=['GET'])\ndef get_user(user_id):\n    user = User.get(user_id)\n    if not user:\n        return jsonify({'error': 'User not found'}), 404\n    return jsonify(user.to_dict())\n</code></pre> <p>Generated test:</p> <pre><code># tests/api_tests/test_users_api.py\nimport unittest\nimport json\nfrom api.users import app\n\nclass TestUsersAPI(unittest.TestCase):\n    def setUp(self):\n        self.app = app.test_client()\n\n    def test_create_user(self):\n        response = self.app.post('/users', \n            json={'name': 'John Doe', 'email': 'john@example.com'})\n        self.assertEqual(response.status_code, 201)\n        data = json.loads(response.data)\n        self.assertEqual(data['name'], 'John Doe')\n\n    def test_get_user(self):\n        # Create user first\n        create_response = self.app.post('/users',\n            json={'name': 'Jane Doe', 'email': 'jane@example.com'})\n        user_id = json.loads(create_response.data)['id']\n\n        # Get user\n        response = self.app.get(f'/users/{user_id}')\n        self.assertEqual(response.status_code, 200)\n        data = json.loads(response.data)\n        self.assertEqual(data['name'], 'Jane Doe')\n\n    def test_get_nonexistent_user(self):\n        response = self.app.get('/users/nonexistent')\n        self.assertEqual(response.status_code, 404)\n</code></pre>"},{"location":"working_set/usage-examples/#2-data-processing-pipeline","title":"2. Data Processing Pipeline","text":"<p>Configuration for a data processing project:</p> <pre><code>{\n  \"watch_dirs\": [\"processors\", \"transformers\", \"validators\"],\n  \"watch_extensions\": [\".py\"],\n  \"agent_mission\": \"testing\",\n  \"working_set_dir\": \"tests/data_tests\",\n  \"claude_timeout\": 600\n}\n</code></pre> <p>Example file:</p> <pre><code># processors/data_cleaner.py\nimport pandas as pd\nfrom typing import List, Dict\n\nclass DataCleaner:\n    \"\"\"Cleans and validates data for processing\"\"\"\n\n    def clean_csv(self, filepath: str) -&gt; pd.DataFrame:\n        \"\"\"Clean CSV data by removing nulls and duplicates\"\"\"\n        df = pd.read_csv(filepath)\n        df = df.dropna()\n        df = df.drop_duplicates()\n        return df\n\n    def validate_schema(self, df: pd.DataFrame, required_columns: List[str]) -&gt; bool:\n        \"\"\"Validate that DataFrame has required columns\"\"\"\n        return all(col in df.columns for col in required_columns)\n\n    def normalize_data(self, df: pd.DataFrame, columns: List[str]) -&gt; pd.DataFrame:\n        \"\"\"Normalize specified columns to 0-1 range\"\"\"\n        for col in columns:\n            if col in df.columns:\n                df[col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())\n        return df\n</code></pre> <p>Generated test:</p> <pre><code># tests/data_tests/test_data_cleaner.py\nimport unittest\nimport pandas as pd\nimport tempfile\nimport os\nfrom processors.data_cleaner import DataCleaner\n\nclass TestDataCleaner(unittest.TestCase):\n    def setUp(self):\n        self.cleaner = DataCleaner()\n\n    def test_clean_csv(self):\n        # Create test CSV\n        test_data = pd.DataFrame({\n            'A': [1, 2, None, 4, 2],\n            'B': ['a', 'b', 'c', 'd', 'b']\n        })\n\n        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:\n            test_data.to_csv(f.name, index=False)\n            cleaned = self.cleaner.clean_csv(f.name)\n\n        # Should remove null and duplicate rows\n        self.assertEqual(len(cleaned), 3)\n        self.assertFalse(cleaned.isnull().any().any())\n\n        os.unlink(f.name)\n\n    def test_validate_schema(self):\n        df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n\n        # Valid schema\n        self.assertTrue(self.cleaner.validate_schema(df, ['A', 'B']))\n\n        # Invalid schema\n        self.assertFalse(self.cleaner.validate_schema(df, ['A', 'C']))\n\n    def test_normalize_data(self):\n        df = pd.DataFrame({'A': [1, 2, 3, 4], 'B': [10, 20, 30, 40]})\n        normalized = self.cleaner.normalize_data(df, ['A', 'B'])\n\n        # Check normalization\n        self.assertAlmostEqual(normalized['A'].min(), 0.0)\n        self.assertAlmostEqual(normalized['A'].max(), 1.0)\n        self.assertAlmostEqual(normalized['B'].min(), 0.0)\n        self.assertAlmostEqual(normalized['B'].max(), 1.0)\n</code></pre>"},{"location":"working_set/usage-examples/#3-machine-learning-model","title":"3. Machine Learning Model","text":"<p>Configuration for ML model development:</p> <pre><code>{\n  \"watch_dirs\": [\"models\", \"features\", \"training\"],\n  \"agent_mission\": \"testing\",\n  \"working_set_dir\": \"tests/ml_tests\",\n  \"claude_timeout\": 900\n}\n</code></pre> <p>Example model:</p> <pre><code># models/classifier.py\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nclass TextClassifier:\n    \"\"\"Text classification model using Random Forest\"\"\"\n\n    def __init__(self, n_estimators=100):\n        self.model = RandomForestClassifier(n_estimators=n_estimators)\n        self.is_trained = False\n\n    def train(self, X: np.ndarray, y: np.ndarray) -&gt; dict:\n        \"\"\"Train the classifier\"\"\"\n        X_train, X_test, y_train, y_test = train_test_split(\n            X, y, test_size=0.2, random_state=42\n        )\n\n        self.model.fit(X_train, y_train)\n        self.is_trained = True\n\n        # Return training metrics\n        y_pred = self.model.predict(X_test)\n        accuracy = accuracy_score(y_test, y_pred)\n\n        return {\n            'accuracy': accuracy,\n            'train_size': len(X_train),\n            'test_size': len(X_test)\n        }\n\n    def predict(self, X: np.ndarray) -&gt; np.ndarray:\n        \"\"\"Make predictions\"\"\"\n        if not self.is_trained:\n            raise ValueError(\"Model must be trained before making predictions\")\n        return self.model.predict(X)\n</code></pre> <p>Generated test:</p> <pre><code># tests/ml_tests/test_text_classifier.py\nimport unittest\nimport numpy as np\nfrom models.classifier import TextClassifier\n\nclass TestTextClassifier(unittest.TestCase):\n    def setUp(self):\n        self.classifier = TextClassifier()\n        # Create sample data\n        self.X = np.random.randn(100, 10)\n        self.y = np.random.randint(0, 2, 100)\n\n    def test_initialization(self):\n        self.assertFalse(self.classifier.is_trained)\n        self.assertIsNotNone(self.classifier.model)\n\n    def test_train(self):\n        metrics = self.classifier.train(self.X, self.y)\n\n        self.assertTrue(self.classifier.is_trained)\n        self.assertIn('accuracy', metrics)\n        self.assertIn('train_size', metrics)\n        self.assertIn('test_size', metrics)\n        self.assertGreaterEqual(metrics['accuracy'], 0.0)\n        self.assertLessEqual(metrics['accuracy'], 1.0)\n\n    def test_predict_before_training(self):\n        with self.assertRaises(ValueError):\n            self.classifier.predict(self.X)\n\n    def test_predict_after_training(self):\n        self.classifier.train(self.X, self.y)\n        predictions = self.classifier.predict(self.X[:10])\n\n        self.assertEqual(len(predictions), 10)\n        self.assertTrue(all(p in [0, 1] for p in predictions))\n</code></pre>"},{"location":"working_set/usage-examples/#error-handling-examples","title":"Error Handling Examples","text":""},{"location":"working_set/usage-examples/#1-monitoring-error-reports","title":"1. Monitoring Error Reports","text":"<pre><code>from src.reporter import ReportMonitor\nimport time\n\n# Create monitor\nmonitor = ReportMonitor('tests/working_set/error_report.jsonl')\n\n# Check for errors periodically\nwhile True:\n    if monitor.has_new_reports():\n        reports = monitor.get_new_reports()\n        for report in reports:\n            print(f\"\ud83d\udea8 {report['severity'].upper()}: {report['description']}\")\n            print(f\"   File: {report['file']}:{report['line']}\")\n            if report['suggested_fix']:\n                print(f\"   Fix: {report['suggested_fix']}\")\n    time.sleep(5)\n</code></pre>"},{"location":"working_set/usage-examples/#2-custom-error-handling","title":"2. Custom Error Handling","text":"<pre><code>from src.reporter import ErrorReporter\n\nclass CustomErrorHandler:\n    def __init__(self, report_file):\n        self.reporter = ErrorReporter(report_file)\n\n    def handle_syntax_error(self, file_path, line_no, error_msg):\n        self.reporter.report_error(\n            file_path=file_path,\n            line=line_no,\n            severity='high',\n            description=f'Syntax error: {error_msg}',\n            suggested_fix='Check syntax and fix compilation errors'\n        )\n\n    def handle_style_issue(self, file_path, line_no, issue):\n        self.reporter.report_error(\n            file_path=file_path,\n            line=line_no,\n            severity='low',\n            description=f'Style issue: {issue}',\n            suggested_fix='Follow PEP8 style guidelines'\n        )\n</code></pre>"},{"location":"working_set/usage-examples/#integration-examples","title":"Integration Examples","text":""},{"location":"working_set/usage-examples/#1-cicd-integration","title":"1. CI/CD Integration","text":"<pre><code># .github/workflows/verifier.yml\nname: Automated Verification\non:\n  push:\n    branches: [ main, develop ]\n  pull_request:\n    branches: [ main ]\n\njobs:\n  verify:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n\n    - name: Setup Python\n      uses: actions/setup-python@v2\n      with:\n        python-version: '3.9'\n\n    - name: Install dependencies\n      run: |\n        pip install -r requirements.txt\n\n    - name: Run verifier\n      run: |\n        python -m src.cli start --config ci-verifier.json\n        # Let it run for a bit to process files\n        sleep 30\n\n    - name: Check for errors\n      run: |\n        if [ -f \"tests/working_set/error_report.jsonl\" ]; then\n          echo \"Errors found:\"\n          cat tests/working_set/error_report.jsonl\n          exit 1\n        fi\n</code></pre>"},{"location":"working_set/usage-examples/#2-pre-commit-hook","title":"2. Pre-commit Hook","text":"<pre><code>#!/bin/bash\n# .git/hooks/pre-commit\n\n# Run verifier on staged files\nstaged_files=$(git diff --cached --name-only --diff-filter=AM | grep -E \"\\.(py|js|ts)$\")\n\nif [ -n \"$staged_files\" ]; then\n    echo \"Running verifier on staged files...\"\n    python -m src.cli demo --config pre-commit.json\n\n    # Check for high severity errors\n    if [ -f \"tests/working_set/error_report.jsonl\" ]; then\n        high_errors=$(grep '\"severity\": \"high\"' tests/working_set/error_report.jsonl | wc -l)\n        if [ $high_errors -gt 0 ]; then\n            echo \"High severity errors found. Commit blocked.\"\n            exit 1\n        fi\n    fi\nfi\n</code></pre> <p>These examples demonstrate the flexibility and power of the verifier system across different use cases and integration scenarios.</p>"}]}